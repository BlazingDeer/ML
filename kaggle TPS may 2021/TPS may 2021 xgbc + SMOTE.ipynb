{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c54385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ea0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf_train=pd.read_csv(\"./data/train.csv\",index_col=0)\n",
    "for column in newdf_train.columns[:-1]:\n",
    "    temp_column=newdf_train[column].to_numpy()\n",
    "    temp_column=np.log(np.log(np.log(np.exp(temp_column)+1)+1)+1)\n",
    "    newdf_train[column]=temp_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e50ee4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "      <th>feature_46</th>\n",
       "      <th>feature_47</th>\n",
       "      <th>feature_48</th>\n",
       "      <th>feature_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.609036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.609036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>1.408800</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.760830</td>\n",
       "      <td>0.609036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.760830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.609036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>1.291725</td>\n",
       "      <td>0.760830</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.874789</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.609036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>Class_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>0.609036</td>\n",
       "      <td>0.423036</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "id                                                                     \n",
       "0    0.423036   0.423036   0.609036   0.423036   0.609036   0.423036   \n",
       "1    0.423036   0.423036   0.423036   0.423036   0.760830   0.609036   \n",
       "2    0.423036   0.423036   0.423036   0.423036   0.423036   0.423036   \n",
       "3    0.423036   0.423036   0.423036   0.423036   0.423036   0.423036   \n",
       "4    0.423036   0.423036   0.423036   0.423036   0.423036   0.423036   \n",
       "\n",
       "    feature_6  feature_7  feature_8  feature_9  ...  feature_41  feature_42  \\\n",
       "id                                              ...                           \n",
       "0    0.423036   0.423036   0.423036   0.423036  ...    0.423036    0.423036   \n",
       "1    0.423036   0.423036   0.423036   0.423036  ...    0.423036    0.423036   \n",
       "2    0.423036   0.423036   0.423036   0.760830  ...    0.423036    0.609036   \n",
       "3    0.423036   0.874789   0.423036   0.423036  ...    0.423036    0.423036   \n",
       "4    0.423036   0.423036   0.423036   0.423036  ...    0.423036    0.423036   \n",
       "\n",
       "    feature_43  feature_44  feature_45  feature_46  feature_47  feature_48  \\\n",
       "id                                                                           \n",
       "0     1.408800    0.423036    0.423036    0.423036    0.423036    0.423036   \n",
       "1     0.423036    0.423036    0.423036    0.423036    0.423036    0.423036   \n",
       "2     0.423036    0.423036    0.423036    0.423036    1.291725    0.760830   \n",
       "3     0.423036    0.423036    0.423036    0.423036    0.423036    0.609036   \n",
       "4     0.423036    0.423036    0.423036    0.423036    0.423036    0.609036   \n",
       "\n",
       "    feature_49   target  \n",
       "id                       \n",
       "0     0.423036  Class_2  \n",
       "1     0.423036  Class_1  \n",
       "2     0.423036  Class_1  \n",
       "3     0.423036  Class_4  \n",
       "4     0.423036  Class_2  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace99c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=newdf_train[newdf_train.columns[:-1]].to_numpy()\n",
    "y=newdf_train[newdf_train.columns[-1]].to_numpy().reshape(-1,1)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c9c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, X_train, y_train, X_test, y_test, \n",
    "             useTrainCV=True, cv_folds=5, early_stopping_rounds=20):\n",
    "    sm=SMOTE(random_state=42)\n",
    "    X_train_smote,y_train_smote=sm.fit_resample(X_train,y_train)\n",
    "    X_test_smote,y_test_smote=sm.fit_resample(X_test,y_test)\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgb_param['num_class'] = len(np.unique(X_train))\n",
    "        xgtrain = xgb.DMatrix(X_train_smote, label=y_train_smote)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'],\n",
    "                          nfold=cv_folds, metrics='mlogloss', \n",
    "                          early_stopping_rounds=early_stopping_rounds)\n",
    "        new_n_estimators=cvresult.shape[0]\n",
    "        alg.set_params(n_estimators=new_n_estimators)\n",
    "    \n",
    "    #refit algo on full dataset\n",
    "    alg.fit(X_train_smote, y_train_smote,eval_metric='mlogloss')\n",
    "        \n",
    "    dtrain_predprob = alg.predict_proba(X_train)\n",
    "    dtrain_smote_predprob=alg.predict_proba(X_train_smote)\n",
    "    dtest_predprob=alg.predict_proba(X_test)\n",
    "    dtest_smote_predprob=alg.predict_proba(X_test_smote)\n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"New n_estimators: {}\".format(new_n_estimators))\n",
    "    print(\"log loss (Train): %f\" % log_loss(y_train, dtrain_predprob))\n",
    "    print(\"log loss (Train SMOTE): %f\" % log_loss(y_train_smote, dtrain_smote_predprob))\n",
    "    print(\"log loss (Test): %f\" % log_loss(y_test, dtest_predprob))\n",
    "    print(\"log loss (Test SMOTE): %f\" % log_loss(y_test_smote, dtest_smote_predprob))\n",
    "    return cvresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b701229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "New n_estimators: 1000\n",
      "log loss (Train): 0.740535\n",
      "log loss (Train SMOTE): 0.623940\n",
      "log loss (Test): 1.138817\n",
      "log loss (Test SMOTE): 1.126269\n"
     ]
    }
   ],
   "source": [
    "#finding optimal n_estimators with 0.1 learning rate\n",
    "ordenc=OrdinalEncoder().fit(y_train)\n",
    "y_train_ord=ordenc.transform(y_train)\n",
    "y_test_ord=ordenc.transform(y_test)\n",
    "predictors=newdf_train.columns[:-1]\n",
    "xgb1=XGBClassifier(learning_rate=0.1, n_estimators=250, max_depth=6,\n",
    "                  min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                  objective=\"multi:softprob\", seed=42,tree_method=\"gpu_hist\",booster=\"gbtree\")\n",
    "cvresult=modelfit(xgb1, X_train, y_train_ord, X_test, y_test_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1c1f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvresult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9985e9e5d1d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m plt.plot(range(len(cvresult[\"train-mlogloss-mean\"])),cvresult[\"train-mlogloss-mean\"].values,\n\u001b[0m\u001b[0;32m      3\u001b[0m         label=\"Train\")\n\u001b[0;32m      4\u001b[0m plt.plot(range(len(cvresult[\"test-mlogloss-mean\"])),cvresult[\"test-mlogloss-mean\"].values,\n\u001b[0;32m      5\u001b[0m         label=\"Test\")\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cvresult' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SMOTE significantly increased training time\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(range(len(cvresult[\"train-mlogloss-mean\"])),cvresult[\"train-mlogloss-mean\"].values,\n",
    "        label=\"Train\")\n",
    "plt.plot(range(len(cvresult[\"test-mlogloss-mean\"])),cvresult[\"test-mlogloss-mean\"].values,\n",
    "        label=\"Test\")\n",
    "plt.ylabel(\"logloss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b14541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pipe_smote_gridsearchcv(pipe,param_grid,X_train,y_train,X_test,y_test):\n",
    "    grid=GridSearchCV(pipe,param_grid=param_grid,cv=4,scoring=\"neg_log_loss\")\n",
    "    grid.fit(X_train,y_train)\n",
    "    print(\"Best params: {}\".format(grid.best_params_))\n",
    "    print(\"Best score (Train SMOTE): {}\".format(grid.best_score_))\n",
    "    print(\"Test score (Test SMOTE): {}\".format(grid.score(X_test,y_test)))\n",
    "    scaler=grid.best_estimator_.named_steps[\"scaler\"]\n",
    "    est=grid.best_estimator_.named_steps[\"classifier\"]\n",
    "    train_predictproba=est.predict_proba(scaler.transform(X_train))\n",
    "    test_predictproba=est.predict_proba(scaler.transform(X_test))\n",
    "    print(\"Train logloss (Train): {}\".format(log_loss(y_train,train_predictproba)))\n",
    "    print(\"Test logloss (Test): {}\".format(log_loss(y_test,test_predictproba)))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9754b96f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e91f299dadaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m              \u001b[1;34m\"classifier__booster\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"gbtree\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m              \"classifier__eval_metric\":[\"mlogloss\"]}\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipe_smote_gridsearchcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-7dae70618c94>\u001b[0m in \u001b[0;36mpipe_smote_gridsearchcv\u001b[1;34m(pipe, param_grid, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpipe_smote_gridsearchcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mgrid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"neg_log_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best params: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best score (Train SMOTE): {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \"\"\"\n\u001b[0;32m    261\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    224\u001b[0m                     \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                     \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m                 )\n\u001b[0;32m    228\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_resample_one\u001b[1;34m(sampler, X, y, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_fit_resample_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m         \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[0;32m    311\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 **kwds))\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ball_tree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kd_tree'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1633\u001b[1;33m             \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1634\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[1;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \"\"\"\n\u001b[0;32m    581\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margpartition\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m     \"\"\"\n\u001b[1;32m--> 837\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argpartition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#looks like the more n_estimators the better but my computer is old\n",
    "#so I have to cut down to decrease training time besides it looks like it's prone to overfitting\n",
    "#finding max_depth and min_child_weight\n",
    "pipe=Pipeline([(\"scaler\",StandardScaler()),(\"SMOTE\", SMOTE(random_state=42)),\n",
    "               (\"classifier\",XGBClassifier())])\n",
    "param_grid1={\"classifier__learning_rate\":[0.1],\n",
    "             \"classifier__n_estimators\":[250],\n",
    "             \"classifier__max_depth\":[4,6,8],\n",
    "             \"classifier__min_child_weight\":[1,3,5],\n",
    "             \"classifier__gamma\":[0],\n",
    "             \"classifier__subsample\":[0.8],\n",
    "             \"classifier__colsample_bytree\":[0.8],\n",
    "             \"classifier__objective\":[\"multi:softprob\"],\n",
    "             \"classifier__random_state\":[42],\n",
    "             \"classifier__tree_method\":[\"gpu_hist\"],\n",
    "             \"classifier__booster\":[\"gbtree\"],\n",
    "             \"classifier__eval_metric\":[\"mlogloss\"]}\n",
    "grid=pipe_smote_gridsearchcv(pipe,param_grid1,X_train,y_train,X_test,y_test)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7ae1665",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__booster</th>\n",
       "      <th>param_classifier__colsample_bytree</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_child_weight</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__objective</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__subsample</th>\n",
       "      <th>param_classifier__tree_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.385573</td>\n",
       "      <td>0.748931</td>\n",
       "      <td>0.183687</td>\n",
       "      <td>0.032834</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101976</td>\n",
       "      <td>-1.105130</td>\n",
       "      <td>-1.102769</td>\n",
       "      <td>-1.099442</td>\n",
       "      <td>-1.102329</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.576520</td>\n",
       "      <td>0.274528</td>\n",
       "      <td>0.177692</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102508</td>\n",
       "      <td>-1.105616</td>\n",
       "      <td>-1.102075</td>\n",
       "      <td>-1.099885</td>\n",
       "      <td>-1.102521</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.319000</td>\n",
       "      <td>0.144631</td>\n",
       "      <td>0.156196</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102353</td>\n",
       "      <td>-1.105455</td>\n",
       "      <td>-1.102390</td>\n",
       "      <td>-1.099547</td>\n",
       "      <td>-1.102436</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.111388</td>\n",
       "      <td>0.720206</td>\n",
       "      <td>0.203428</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.107873</td>\n",
       "      <td>-1.109726</td>\n",
       "      <td>-1.107696</td>\n",
       "      <td>-1.105344</td>\n",
       "      <td>-1.107660</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.459125</td>\n",
       "      <td>0.542578</td>\n",
       "      <td>0.207425</td>\n",
       "      <td>0.010007</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.108702</td>\n",
       "      <td>-1.109577</td>\n",
       "      <td>-1.106403</td>\n",
       "      <td>-1.104313</td>\n",
       "      <td>-1.107249</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.724268</td>\n",
       "      <td>0.143219</td>\n",
       "      <td>0.213919</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.107057</td>\n",
       "      <td>-1.109837</td>\n",
       "      <td>-1.106586</td>\n",
       "      <td>-1.104019</td>\n",
       "      <td>-1.106875</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.343284</td>\n",
       "      <td>0.372472</td>\n",
       "      <td>0.309149</td>\n",
       "      <td>0.013456</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.120757</td>\n",
       "      <td>-1.119381</td>\n",
       "      <td>-1.117790</td>\n",
       "      <td>-1.114599</td>\n",
       "      <td>-1.118132</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.360627</td>\n",
       "      <td>0.602937</td>\n",
       "      <td>0.269162</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.120763</td>\n",
       "      <td>-1.119898</td>\n",
       "      <td>-1.116679</td>\n",
       "      <td>-1.113733</td>\n",
       "      <td>-1.117769</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.170027</td>\n",
       "      <td>0.144076</td>\n",
       "      <td>0.258410</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.119422</td>\n",
       "      <td>-1.119297</td>\n",
       "      <td>-1.115510</td>\n",
       "      <td>-1.114402</td>\n",
       "      <td>-1.117158</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      13.385573      0.748931         0.183687        0.032834   \n",
       "1      12.576520      0.274528         0.177692        0.024501   \n",
       "2      12.319000      0.144631         0.156196        0.004325   \n",
       "3      18.111388      0.720206         0.203428        0.007259   \n",
       "4      17.459125      0.542578         0.207425        0.010007   \n",
       "5      17.724268      0.143219         0.213919        0.004526   \n",
       "6      31.343284      0.372472         0.309149        0.013456   \n",
       "7      28.360627      0.602937         0.269162        0.009007   \n",
       "8      26.170027      0.144076         0.258410        0.002062   \n",
       "\n",
       "  param_classifier__booster param_classifier__colsample_bytree  \\\n",
       "0                    gbtree                                0.8   \n",
       "1                    gbtree                                0.8   \n",
       "2                    gbtree                                0.8   \n",
       "3                    gbtree                                0.8   \n",
       "4                    gbtree                                0.8   \n",
       "5                    gbtree                                0.8   \n",
       "6                    gbtree                                0.8   \n",
       "7                    gbtree                                0.8   \n",
       "8                    gbtree                                0.8   \n",
       "\n",
       "  param_classifier__eval_metric param_classifier__gamma  \\\n",
       "0                      mlogloss                       0   \n",
       "1                      mlogloss                       0   \n",
       "2                      mlogloss                       0   \n",
       "3                      mlogloss                       0   \n",
       "4                      mlogloss                       0   \n",
       "5                      mlogloss                       0   \n",
       "6                      mlogloss                       0   \n",
       "7                      mlogloss                       0   \n",
       "8                      mlogloss                       0   \n",
       "\n",
       "  param_classifier__learning_rate param_classifier__max_depth  \\\n",
       "0                             0.1                           4   \n",
       "1                             0.1                           4   \n",
       "2                             0.1                           4   \n",
       "3                             0.1                           6   \n",
       "4                             0.1                           6   \n",
       "5                             0.1                           6   \n",
       "6                             0.1                           8   \n",
       "7                             0.1                           8   \n",
       "8                             0.1                           8   \n",
       "\n",
       "  param_classifier__min_child_weight param_classifier__n_estimators  \\\n",
       "0                                  1                            250   \n",
       "1                                  3                            250   \n",
       "2                                  5                            250   \n",
       "3                                  1                            250   \n",
       "4                                  3                            250   \n",
       "5                                  5                            250   \n",
       "6                                  1                            250   \n",
       "7                                  3                            250   \n",
       "8                                  5                            250   \n",
       "\n",
       "  param_classifier__objective param_classifier__random_state  \\\n",
       "0              multi:softprob                             42   \n",
       "1              multi:softprob                             42   \n",
       "2              multi:softprob                             42   \n",
       "3              multi:softprob                             42   \n",
       "4              multi:softprob                             42   \n",
       "5              multi:softprob                             42   \n",
       "6              multi:softprob                             42   \n",
       "7              multi:softprob                             42   \n",
       "8              multi:softprob                             42   \n",
       "\n",
       "  param_classifier__subsample param_classifier__tree_method  \\\n",
       "0                         0.8                      gpu_hist   \n",
       "1                         0.8                      gpu_hist   \n",
       "2                         0.8                      gpu_hist   \n",
       "3                         0.8                      gpu_hist   \n",
       "4                         0.8                      gpu_hist   \n",
       "5                         0.8                      gpu_hist   \n",
       "6                         0.8                      gpu_hist   \n",
       "7                         0.8                      gpu_hist   \n",
       "8                         0.8                      gpu_hist   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'classifier__booster': 'gbtree', 'classifier_...          -1.101976   \n",
       "1  {'classifier__booster': 'gbtree', 'classifier_...          -1.102508   \n",
       "2  {'classifier__booster': 'gbtree', 'classifier_...          -1.102353   \n",
       "3  {'classifier__booster': 'gbtree', 'classifier_...          -1.107873   \n",
       "4  {'classifier__booster': 'gbtree', 'classifier_...          -1.108702   \n",
       "5  {'classifier__booster': 'gbtree', 'classifier_...          -1.107057   \n",
       "6  {'classifier__booster': 'gbtree', 'classifier_...          -1.120757   \n",
       "7  {'classifier__booster': 'gbtree', 'classifier_...          -1.120763   \n",
       "8  {'classifier__booster': 'gbtree', 'classifier_...          -1.119422   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0          -1.105130          -1.102769          -1.099442        -1.102329   \n",
       "1          -1.105616          -1.102075          -1.099885        -1.102521   \n",
       "2          -1.105455          -1.102390          -1.099547        -1.102436   \n",
       "3          -1.109726          -1.107696          -1.105344        -1.107660   \n",
       "4          -1.109577          -1.106403          -1.104313        -1.107249   \n",
       "5          -1.109837          -1.106586          -1.104019        -1.106875   \n",
       "6          -1.119381          -1.117790          -1.114599        -1.118132   \n",
       "7          -1.119898          -1.116679          -1.113733        -1.117769   \n",
       "8          -1.119297          -1.115510          -1.114402        -1.117158   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.002031                1  \n",
       "1        0.002045                3  \n",
       "2        0.002090                2  \n",
       "3        0.001556                6  \n",
       "4        0.002054                5  \n",
       "5        0.002064                4  \n",
       "6        0.002294                9  \n",
       "7        0.002783                8  \n",
       "8        0.002237                7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b354682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'classifier__booster': 'gbtree', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'mlogloss', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 250, 'classifier__objective': 'multi:softprob', 'classifier__random_state': 42, 'classifier__subsample': 0.8, 'classifier__tree_method': 'gpu_hist'}\n",
      "Best score (Train SMOTE): -1.1022726359942556\n",
      "Test score (Test SMOTE): -1.098622963590622\n",
      "Train logloss (Train): 1.0608920244656006\n",
      "Test logloss (Test): 1.098622963590622\n"
     ]
    }
   ],
   "source": [
    "#checking around max_depth=4 and min_child_weight=1\n",
    "param_grid2={\"classifier__learning_rate\":[0.1],\n",
    "             \"classifier__n_estimators\":[250],\n",
    "             \"classifier__max_depth\":[3,4,5],\n",
    "             \"classifier__min_child_weight\":[0,1,2],\n",
    "             \"classifier__gamma\":[0],\n",
    "             \"classifier__subsample\":[0.8],\n",
    "             \"classifier__colsample_bytree\":[0.8],\n",
    "             \"classifier__objective\":[\"multi:softprob\"],\n",
    "             \"classifier__random_state\":[42],\n",
    "             \"classifier__tree_method\":[\"gpu_hist\"],\n",
    "             \"classifier__booster\":[\"gbtree\"],\n",
    "             \"classifier__eval_metric\":[\"mlogloss\"]}\n",
    "grid2=pipe_smote_gridsearchcv(pipe,param_grid2,X_train,y_train,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9ae60d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__booster</th>\n",
       "      <th>param_classifier__colsample_bytree</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_child_weight</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__objective</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__subsample</th>\n",
       "      <th>param_classifier__tree_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.801206</td>\n",
       "      <td>0.165972</td>\n",
       "      <td>0.146952</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.103036</td>\n",
       "      <td>-1.106568</td>\n",
       "      <td>-1.104330</td>\n",
       "      <td>-1.101328</td>\n",
       "      <td>-1.103816</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.640979</td>\n",
       "      <td>0.337246</td>\n",
       "      <td>0.144203</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.103269</td>\n",
       "      <td>-1.106419</td>\n",
       "      <td>-1.104283</td>\n",
       "      <td>-1.101030</td>\n",
       "      <td>-1.103750</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.790610</td>\n",
       "      <td>0.332160</td>\n",
       "      <td>0.138705</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.103140</td>\n",
       "      <td>-1.106445</td>\n",
       "      <td>-1.104229</td>\n",
       "      <td>-1.100713</td>\n",
       "      <td>-1.103632</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.126761</td>\n",
       "      <td>0.230563</td>\n",
       "      <td>0.157187</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102244</td>\n",
       "      <td>-1.105072</td>\n",
       "      <td>-1.102455</td>\n",
       "      <td>-1.099490</td>\n",
       "      <td>-1.102315</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.865850</td>\n",
       "      <td>0.153861</td>\n",
       "      <td>0.162947</td>\n",
       "      <td>0.009946</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101976</td>\n",
       "      <td>-1.105130</td>\n",
       "      <td>-1.102769</td>\n",
       "      <td>-1.099442</td>\n",
       "      <td>-1.102329</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.072333</td>\n",
       "      <td>0.275612</td>\n",
       "      <td>0.171183</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102055</td>\n",
       "      <td>-1.105256</td>\n",
       "      <td>-1.102256</td>\n",
       "      <td>-1.099524</td>\n",
       "      <td>-1.102273</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.979958</td>\n",
       "      <td>0.205251</td>\n",
       "      <td>0.179927</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.104678</td>\n",
       "      <td>-1.107031</td>\n",
       "      <td>-1.103863</td>\n",
       "      <td>-1.100296</td>\n",
       "      <td>-1.103967</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.846583</td>\n",
       "      <td>0.155381</td>\n",
       "      <td>0.184182</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.104230</td>\n",
       "      <td>-1.106829</td>\n",
       "      <td>-1.104070</td>\n",
       "      <td>-1.100106</td>\n",
       "      <td>-1.103809</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.620282</td>\n",
       "      <td>0.271522</td>\n",
       "      <td>0.191188</td>\n",
       "      <td>0.015590</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.104559</td>\n",
       "      <td>-1.107335</td>\n",
       "      <td>-1.104133</td>\n",
       "      <td>-1.100418</td>\n",
       "      <td>-1.104111</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      11.801206      0.165972         0.146952        0.008857   \n",
       "1      11.640979      0.337246         0.144203        0.009650   \n",
       "2      11.790610      0.332160         0.138705        0.001299   \n",
       "3      12.126761      0.230563         0.157187        0.006143   \n",
       "4      12.865850      0.153861         0.162947        0.009946   \n",
       "5      13.072333      0.275612         0.171183        0.006096   \n",
       "6      14.979958      0.205251         0.179927        0.007581   \n",
       "7      14.846583      0.155381         0.184182        0.002578   \n",
       "8      14.620282      0.271522         0.191188        0.015590   \n",
       "\n",
       "  param_classifier__booster param_classifier__colsample_bytree  \\\n",
       "0                    gbtree                                0.8   \n",
       "1                    gbtree                                0.8   \n",
       "2                    gbtree                                0.8   \n",
       "3                    gbtree                                0.8   \n",
       "4                    gbtree                                0.8   \n",
       "5                    gbtree                                0.8   \n",
       "6                    gbtree                                0.8   \n",
       "7                    gbtree                                0.8   \n",
       "8                    gbtree                                0.8   \n",
       "\n",
       "  param_classifier__eval_metric param_classifier__gamma  \\\n",
       "0                      mlogloss                       0   \n",
       "1                      mlogloss                       0   \n",
       "2                      mlogloss                       0   \n",
       "3                      mlogloss                       0   \n",
       "4                      mlogloss                       0   \n",
       "5                      mlogloss                       0   \n",
       "6                      mlogloss                       0   \n",
       "7                      mlogloss                       0   \n",
       "8                      mlogloss                       0   \n",
       "\n",
       "  param_classifier__learning_rate param_classifier__max_depth  \\\n",
       "0                             0.1                           3   \n",
       "1                             0.1                           3   \n",
       "2                             0.1                           3   \n",
       "3                             0.1                           4   \n",
       "4                             0.1                           4   \n",
       "5                             0.1                           4   \n",
       "6                             0.1                           5   \n",
       "7                             0.1                           5   \n",
       "8                             0.1                           5   \n",
       "\n",
       "  param_classifier__min_child_weight param_classifier__n_estimators  \\\n",
       "0                                  0                            250   \n",
       "1                                  1                            250   \n",
       "2                                  2                            250   \n",
       "3                                  0                            250   \n",
       "4                                  1                            250   \n",
       "5                                  2                            250   \n",
       "6                                  0                            250   \n",
       "7                                  1                            250   \n",
       "8                                  2                            250   \n",
       "\n",
       "  param_classifier__objective param_classifier__random_state  \\\n",
       "0              multi:softprob                             42   \n",
       "1              multi:softprob                             42   \n",
       "2              multi:softprob                             42   \n",
       "3              multi:softprob                             42   \n",
       "4              multi:softprob                             42   \n",
       "5              multi:softprob                             42   \n",
       "6              multi:softprob                             42   \n",
       "7              multi:softprob                             42   \n",
       "8              multi:softprob                             42   \n",
       "\n",
       "  param_classifier__subsample param_classifier__tree_method  \\\n",
       "0                         0.8                      gpu_hist   \n",
       "1                         0.8                      gpu_hist   \n",
       "2                         0.8                      gpu_hist   \n",
       "3                         0.8                      gpu_hist   \n",
       "4                         0.8                      gpu_hist   \n",
       "5                         0.8                      gpu_hist   \n",
       "6                         0.8                      gpu_hist   \n",
       "7                         0.8                      gpu_hist   \n",
       "8                         0.8                      gpu_hist   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'classifier__booster': 'gbtree', 'classifier_...          -1.103036   \n",
       "1  {'classifier__booster': 'gbtree', 'classifier_...          -1.103269   \n",
       "2  {'classifier__booster': 'gbtree', 'classifier_...          -1.103140   \n",
       "3  {'classifier__booster': 'gbtree', 'classifier_...          -1.102244   \n",
       "4  {'classifier__booster': 'gbtree', 'classifier_...          -1.101976   \n",
       "5  {'classifier__booster': 'gbtree', 'classifier_...          -1.102055   \n",
       "6  {'classifier__booster': 'gbtree', 'classifier_...          -1.104678   \n",
       "7  {'classifier__booster': 'gbtree', 'classifier_...          -1.104230   \n",
       "8  {'classifier__booster': 'gbtree', 'classifier_...          -1.104559   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0          -1.106568          -1.104330          -1.101328        -1.103816   \n",
       "1          -1.106419          -1.104283          -1.101030        -1.103750   \n",
       "2          -1.106445          -1.104229          -1.100713        -1.103632   \n",
       "3          -1.105072          -1.102455          -1.099490        -1.102315   \n",
       "4          -1.105130          -1.102769          -1.099442        -1.102329   \n",
       "5          -1.105256          -1.102256          -1.099524        -1.102273   \n",
       "6          -1.107031          -1.103863          -1.100296        -1.103967   \n",
       "7          -1.106829          -1.104070          -1.100106        -1.103809   \n",
       "8          -1.107335          -1.104133          -1.100418        -1.104111   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.001913                7  \n",
       "1        0.001939                5  \n",
       "2        0.002064                4  \n",
       "3        0.001975                2  \n",
       "4        0.002031                3  \n",
       "5        0.002031                1  \n",
       "6        0.002417                8  \n",
       "7        0.002402                6  \n",
       "8        0.002461                9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f95d578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'classifier__booster': 'gbtree', 'classifier__colsample_bytree': 0.8, 'classifier__eval_metric': 'mlogloss', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 250, 'classifier__objective': 'multi:softprob', 'classifier__random_state': 42, 'classifier__subsample': 0.8, 'classifier__tree_method': 'gpu_hist'}\n",
      "Best score (Train SMOTE): -1.1022726359942556\n",
      "Test score (Test SMOTE): -1.098622963590622\n",
      "Train logloss (Train): 1.0608920244656006\n",
      "Test logloss (Test): 1.098622963590622\n"
     ]
    }
   ],
   "source": [
    "#best max_depth=4 and min_child_weight=2\n",
    "#finding gamma\n",
    "param_grid3={\"classifier__learning_rate\":[0.1],\n",
    "             \"classifier__n_estimators\":[250],\n",
    "             \"classifier__max_depth\":[4],\n",
    "             \"classifier__min_child_weight\":[2],\n",
    "             \"classifier__gamma\":[0,0.1,0.2,0.3,0.5,0.7,0.9],\n",
    "             \"classifier__subsample\":[0.8],\n",
    "             \"classifier__colsample_bytree\":[0.8],\n",
    "             \"classifier__objective\":[\"multi:softprob\"],\n",
    "             \"classifier__random_state\":[42],\n",
    "             \"classifier__tree_method\":[\"gpu_hist\"],\n",
    "             \"classifier__booster\":[\"gbtree\"],\n",
    "             \"classifier__eval_metric\":[\"mlogloss\"]}\n",
    "grid3=pipe_smote_gridsearchcv(pipe,param_grid3,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abd7ab1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__booster</th>\n",
       "      <th>param_classifier__colsample_bytree</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_child_weight</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__objective</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__subsample</th>\n",
       "      <th>param_classifier__tree_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.450113</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.177192</td>\n",
       "      <td>0.016838</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102055</td>\n",
       "      <td>-1.105256</td>\n",
       "      <td>-1.102256</td>\n",
       "      <td>-1.099524</td>\n",
       "      <td>-1.102273</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.886141</td>\n",
       "      <td>0.128283</td>\n",
       "      <td>0.162697</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102046</td>\n",
       "      <td>-1.105366</td>\n",
       "      <td>-1.102328</td>\n",
       "      <td>-1.099437</td>\n",
       "      <td>-1.102294</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.874540</td>\n",
       "      <td>0.117230</td>\n",
       "      <td>0.164696</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101866</td>\n",
       "      <td>-1.105579</td>\n",
       "      <td>-1.102466</td>\n",
       "      <td>-1.099380</td>\n",
       "      <td>-1.102323</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.911158</td>\n",
       "      <td>0.110179</td>\n",
       "      <td>0.158948</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102582</td>\n",
       "      <td>-1.105406</td>\n",
       "      <td>-1.102225</td>\n",
       "      <td>-1.099635</td>\n",
       "      <td>-1.102462</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.887912</td>\n",
       "      <td>0.129476</td>\n",
       "      <td>0.162947</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102253</td>\n",
       "      <td>-1.105284</td>\n",
       "      <td>-1.102369</td>\n",
       "      <td>-1.099641</td>\n",
       "      <td>-1.102387</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.950054</td>\n",
       "      <td>0.199250</td>\n",
       "      <td>0.162697</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102263</td>\n",
       "      <td>-1.105692</td>\n",
       "      <td>-1.102193</td>\n",
       "      <td>-1.099810</td>\n",
       "      <td>-1.102490</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.904163</td>\n",
       "      <td>0.113288</td>\n",
       "      <td>0.159194</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102016</td>\n",
       "      <td>-1.105438</td>\n",
       "      <td>-1.102278</td>\n",
       "      <td>-1.099771</td>\n",
       "      <td>-1.102376</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      13.450113      0.081253         0.177192        0.016838   \n",
       "1      12.886141      0.128283         0.162697        0.001298   \n",
       "2      12.874540      0.117230         0.164696        0.002585   \n",
       "3      12.911158      0.110179         0.158948        0.007174   \n",
       "4      12.887912      0.129476         0.162947        0.001871   \n",
       "5      12.950054      0.199250         0.162697        0.003191   \n",
       "6      12.904163      0.113288         0.159194        0.006052   \n",
       "\n",
       "  param_classifier__booster param_classifier__colsample_bytree  \\\n",
       "0                    gbtree                                0.8   \n",
       "1                    gbtree                                0.8   \n",
       "2                    gbtree                                0.8   \n",
       "3                    gbtree                                0.8   \n",
       "4                    gbtree                                0.8   \n",
       "5                    gbtree                                0.8   \n",
       "6                    gbtree                                0.8   \n",
       "\n",
       "  param_classifier__eval_metric param_classifier__gamma  \\\n",
       "0                      mlogloss                       0   \n",
       "1                      mlogloss                     0.1   \n",
       "2                      mlogloss                     0.2   \n",
       "3                      mlogloss                     0.3   \n",
       "4                      mlogloss                     0.5   \n",
       "5                      mlogloss                     0.7   \n",
       "6                      mlogloss                     0.9   \n",
       "\n",
       "  param_classifier__learning_rate param_classifier__max_depth  \\\n",
       "0                             0.1                           4   \n",
       "1                             0.1                           4   \n",
       "2                             0.1                           4   \n",
       "3                             0.1                           4   \n",
       "4                             0.1                           4   \n",
       "5                             0.1                           4   \n",
       "6                             0.1                           4   \n",
       "\n",
       "  param_classifier__min_child_weight param_classifier__n_estimators  \\\n",
       "0                                  2                            250   \n",
       "1                                  2                            250   \n",
       "2                                  2                            250   \n",
       "3                                  2                            250   \n",
       "4                                  2                            250   \n",
       "5                                  2                            250   \n",
       "6                                  2                            250   \n",
       "\n",
       "  param_classifier__objective param_classifier__random_state  \\\n",
       "0              multi:softprob                             42   \n",
       "1              multi:softprob                             42   \n",
       "2              multi:softprob                             42   \n",
       "3              multi:softprob                             42   \n",
       "4              multi:softprob                             42   \n",
       "5              multi:softprob                             42   \n",
       "6              multi:softprob                             42   \n",
       "\n",
       "  param_classifier__subsample param_classifier__tree_method  \\\n",
       "0                         0.8                      gpu_hist   \n",
       "1                         0.8                      gpu_hist   \n",
       "2                         0.8                      gpu_hist   \n",
       "3                         0.8                      gpu_hist   \n",
       "4                         0.8                      gpu_hist   \n",
       "5                         0.8                      gpu_hist   \n",
       "6                         0.8                      gpu_hist   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'classifier__booster': 'gbtree', 'classifier_...          -1.102055   \n",
       "1  {'classifier__booster': 'gbtree', 'classifier_...          -1.102046   \n",
       "2  {'classifier__booster': 'gbtree', 'classifier_...          -1.101866   \n",
       "3  {'classifier__booster': 'gbtree', 'classifier_...          -1.102582   \n",
       "4  {'classifier__booster': 'gbtree', 'classifier_...          -1.102253   \n",
       "5  {'classifier__booster': 'gbtree', 'classifier_...          -1.102263   \n",
       "6  {'classifier__booster': 'gbtree', 'classifier_...          -1.102016   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0          -1.105256          -1.102256          -1.099524        -1.102273   \n",
       "1          -1.105366          -1.102328          -1.099437        -1.102294   \n",
       "2          -1.105579          -1.102466          -1.099380        -1.102323   \n",
       "3          -1.105406          -1.102225          -1.099635        -1.102462   \n",
       "4          -1.105284          -1.102369          -1.099641        -1.102387   \n",
       "5          -1.105692          -1.102193          -1.099810        -1.102490   \n",
       "6          -1.105438          -1.102278          -1.099771        -1.102376   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.002031                1  \n",
       "1        0.002101                2  \n",
       "2        0.002207                3  \n",
       "3        0.002045                6  \n",
       "4        0.001997                5  \n",
       "5        0.002096                7  \n",
       "6        0.002019                4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid3.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04510cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'classifier__booster': 'gbtree', 'classifier__colsample_bytree': 0.6, 'classifier__eval_metric': 'mlogloss', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 250, 'classifier__objective': 'multi:softprob', 'classifier__random_state': 42, 'classifier__subsample': 0.7, 'classifier__tree_method': 'gpu_hist'}\n",
      "Best score (Train SMOTE): -1.101574809829394\n",
      "Test score (Test SMOTE): -1.098478347530961\n",
      "Train logloss (Train): 1.0624740972808004\n",
      "Test logloss (Test): 1.098478347530961\n"
     ]
    }
   ],
   "source": [
    "#best gamma=0\n",
    "param_grid4={\"classifier__learning_rate\":[0.1],\n",
    "             \"classifier__n_estimators\":[250],\n",
    "             \"classifier__max_depth\":[4],\n",
    "             \"classifier__min_child_weight\":[2],\n",
    "             \"classifier__gamma\":[0],\n",
    "             \"classifier__subsample\":[0.6,0.7,0.8,0.9],\n",
    "             \"classifier__colsample_bytree\":[0.6,0.7,0.8,0.9],\n",
    "             \"classifier__objective\":[\"multi:softprob\"],\n",
    "             \"classifier__random_state\":[42],\n",
    "             \"classifier__tree_method\":[\"gpu_hist\"],\n",
    "             \"classifier__booster\":[\"gbtree\"],\n",
    "             \"classifier__eval_metric\":[\"mlogloss\"]}\n",
    "grid4=pipe_smote_gridsearchcv(pipe,param_grid4,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3e80383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__booster</th>\n",
       "      <th>param_classifier__colsample_bytree</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_child_weight</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__objective</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__subsample</th>\n",
       "      <th>param_classifier__tree_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.398376</td>\n",
       "      <td>0.249266</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.6</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101927</td>\n",
       "      <td>-1.105454</td>\n",
       "      <td>-1.102111</td>\n",
       "      <td>-1.098460</td>\n",
       "      <td>-1.101988</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.563323</td>\n",
       "      <td>0.133735</td>\n",
       "      <td>0.162697</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.6</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101036</td>\n",
       "      <td>-1.104235</td>\n",
       "      <td>-1.102296</td>\n",
       "      <td>-1.098732</td>\n",
       "      <td>-1.101575</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.760854</td>\n",
       "      <td>0.116870</td>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.6</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101560</td>\n",
       "      <td>-1.105028</td>\n",
       "      <td>-1.101733</td>\n",
       "      <td>-1.099192</td>\n",
       "      <td>-1.101878</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.947192</td>\n",
       "      <td>0.125517</td>\n",
       "      <td>0.159197</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.6</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101599</td>\n",
       "      <td>-1.104217</td>\n",
       "      <td>-1.101946</td>\n",
       "      <td>-1.099259</td>\n",
       "      <td>-1.101755</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.250566</td>\n",
       "      <td>0.126985</td>\n",
       "      <td>0.161197</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.7</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102105</td>\n",
       "      <td>-1.105394</td>\n",
       "      <td>-1.101618</td>\n",
       "      <td>-1.099203</td>\n",
       "      <td>-1.102080</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.502949</td>\n",
       "      <td>0.368539</td>\n",
       "      <td>0.174943</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.7</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102253</td>\n",
       "      <td>-1.105544</td>\n",
       "      <td>-1.101816</td>\n",
       "      <td>-1.098909</td>\n",
       "      <td>-1.102131</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.714876</td>\n",
       "      <td>0.245046</td>\n",
       "      <td>0.162697</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.7</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102193</td>\n",
       "      <td>-1.105130</td>\n",
       "      <td>-1.101982</td>\n",
       "      <td>-1.099186</td>\n",
       "      <td>-1.102123</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.465002</td>\n",
       "      <td>0.360292</td>\n",
       "      <td>0.157445</td>\n",
       "      <td>0.014737</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.7</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102042</td>\n",
       "      <td>-1.104578</td>\n",
       "      <td>-1.102018</td>\n",
       "      <td>-1.099685</td>\n",
       "      <td>-1.102081</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.122207</td>\n",
       "      <td>0.320221</td>\n",
       "      <td>0.166696</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102275</td>\n",
       "      <td>-1.105272</td>\n",
       "      <td>-1.102405</td>\n",
       "      <td>-1.098801</td>\n",
       "      <td>-1.102188</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.271694</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.162447</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102530</td>\n",
       "      <td>-1.105203</td>\n",
       "      <td>-1.102360</td>\n",
       "      <td>-1.098822</td>\n",
       "      <td>-1.102229</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.305591</td>\n",
       "      <td>0.332771</td>\n",
       "      <td>0.153191</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102055</td>\n",
       "      <td>-1.105256</td>\n",
       "      <td>-1.102256</td>\n",
       "      <td>-1.099524</td>\n",
       "      <td>-1.102273</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.567372</td>\n",
       "      <td>0.382754</td>\n",
       "      <td>0.153450</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101855</td>\n",
       "      <td>-1.105317</td>\n",
       "      <td>-1.103011</td>\n",
       "      <td>-1.099310</td>\n",
       "      <td>-1.102373</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.960130</td>\n",
       "      <td>0.368605</td>\n",
       "      <td>0.151946</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.9</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.6</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102649</td>\n",
       "      <td>-1.105313</td>\n",
       "      <td>-1.102047</td>\n",
       "      <td>-1.099677</td>\n",
       "      <td>-1.102421</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.776621</td>\n",
       "      <td>0.426383</td>\n",
       "      <td>0.169184</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.9</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102621</td>\n",
       "      <td>-1.105357</td>\n",
       "      <td>-1.102792</td>\n",
       "      <td>-1.099926</td>\n",
       "      <td>-1.102674</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.496706</td>\n",
       "      <td>0.078906</td>\n",
       "      <td>0.156949</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.9</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102986</td>\n",
       "      <td>-1.105623</td>\n",
       "      <td>-1.102360</td>\n",
       "      <td>-1.099191</td>\n",
       "      <td>-1.102540</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.367420</td>\n",
       "      <td>0.590991</td>\n",
       "      <td>0.166695</td>\n",
       "      <td>0.023881</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.9</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.9</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102590</td>\n",
       "      <td>-1.105186</td>\n",
       "      <td>-1.102854</td>\n",
       "      <td>-1.099395</td>\n",
       "      <td>-1.102506</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       12.398376      0.249266         0.161947        0.001414   \n",
       "1       12.563323      0.133735         0.162697        0.002585   \n",
       "2       12.760854      0.116870         0.157948        0.005786   \n",
       "3       12.947192      0.125517         0.159197        0.006416   \n",
       "4       12.250566      0.126985         0.161197        0.001479   \n",
       "5       12.502949      0.368539         0.174943        0.030763   \n",
       "6       12.714876      0.245046         0.162697        0.015282   \n",
       "7       12.465002      0.360292         0.157445        0.014737   \n",
       "8       12.122207      0.320221         0.166696        0.023277   \n",
       "9       12.271694      0.248627         0.162447        0.007397   \n",
       "10      12.305591      0.332771         0.153191        0.004806   \n",
       "11      12.567372      0.382754         0.153450        0.004152   \n",
       "12      11.960130      0.368605         0.151946        0.003081   \n",
       "13      12.776621      0.426383         0.169184        0.009091   \n",
       "14      12.496706      0.078906         0.156949        0.005521   \n",
       "15      13.367420      0.590991         0.166695        0.023881   \n",
       "\n",
       "   param_classifier__booster param_classifier__colsample_bytree  \\\n",
       "0                     gbtree                                0.6   \n",
       "1                     gbtree                                0.6   \n",
       "2                     gbtree                                0.6   \n",
       "3                     gbtree                                0.6   \n",
       "4                     gbtree                                0.7   \n",
       "5                     gbtree                                0.7   \n",
       "6                     gbtree                                0.7   \n",
       "7                     gbtree                                0.7   \n",
       "8                     gbtree                                0.8   \n",
       "9                     gbtree                                0.8   \n",
       "10                    gbtree                                0.8   \n",
       "11                    gbtree                                0.8   \n",
       "12                    gbtree                                0.9   \n",
       "13                    gbtree                                0.9   \n",
       "14                    gbtree                                0.9   \n",
       "15                    gbtree                                0.9   \n",
       "\n",
       "   param_classifier__eval_metric param_classifier__gamma  \\\n",
       "0                       mlogloss                       0   \n",
       "1                       mlogloss                       0   \n",
       "2                       mlogloss                       0   \n",
       "3                       mlogloss                       0   \n",
       "4                       mlogloss                       0   \n",
       "5                       mlogloss                       0   \n",
       "6                       mlogloss                       0   \n",
       "7                       mlogloss                       0   \n",
       "8                       mlogloss                       0   \n",
       "9                       mlogloss                       0   \n",
       "10                      mlogloss                       0   \n",
       "11                      mlogloss                       0   \n",
       "12                      mlogloss                       0   \n",
       "13                      mlogloss                       0   \n",
       "14                      mlogloss                       0   \n",
       "15                      mlogloss                       0   \n",
       "\n",
       "   param_classifier__learning_rate param_classifier__max_depth  \\\n",
       "0                              0.1                           4   \n",
       "1                              0.1                           4   \n",
       "2                              0.1                           4   \n",
       "3                              0.1                           4   \n",
       "4                              0.1                           4   \n",
       "5                              0.1                           4   \n",
       "6                              0.1                           4   \n",
       "7                              0.1                           4   \n",
       "8                              0.1                           4   \n",
       "9                              0.1                           4   \n",
       "10                             0.1                           4   \n",
       "11                             0.1                           4   \n",
       "12                             0.1                           4   \n",
       "13                             0.1                           4   \n",
       "14                             0.1                           4   \n",
       "15                             0.1                           4   \n",
       "\n",
       "   param_classifier__min_child_weight param_classifier__n_estimators  \\\n",
       "0                                   2                            250   \n",
       "1                                   2                            250   \n",
       "2                                   2                            250   \n",
       "3                                   2                            250   \n",
       "4                                   2                            250   \n",
       "5                                   2                            250   \n",
       "6                                   2                            250   \n",
       "7                                   2                            250   \n",
       "8                                   2                            250   \n",
       "9                                   2                            250   \n",
       "10                                  2                            250   \n",
       "11                                  2                            250   \n",
       "12                                  2                            250   \n",
       "13                                  2                            250   \n",
       "14                                  2                            250   \n",
       "15                                  2                            250   \n",
       "\n",
       "   param_classifier__objective param_classifier__random_state  \\\n",
       "0               multi:softprob                             42   \n",
       "1               multi:softprob                             42   \n",
       "2               multi:softprob                             42   \n",
       "3               multi:softprob                             42   \n",
       "4               multi:softprob                             42   \n",
       "5               multi:softprob                             42   \n",
       "6               multi:softprob                             42   \n",
       "7               multi:softprob                             42   \n",
       "8               multi:softprob                             42   \n",
       "9               multi:softprob                             42   \n",
       "10              multi:softprob                             42   \n",
       "11              multi:softprob                             42   \n",
       "12              multi:softprob                             42   \n",
       "13              multi:softprob                             42   \n",
       "14              multi:softprob                             42   \n",
       "15              multi:softprob                             42   \n",
       "\n",
       "   param_classifier__subsample param_classifier__tree_method  \\\n",
       "0                          0.6                      gpu_hist   \n",
       "1                          0.7                      gpu_hist   \n",
       "2                          0.8                      gpu_hist   \n",
       "3                          0.9                      gpu_hist   \n",
       "4                          0.6                      gpu_hist   \n",
       "5                          0.7                      gpu_hist   \n",
       "6                          0.8                      gpu_hist   \n",
       "7                          0.9                      gpu_hist   \n",
       "8                          0.6                      gpu_hist   \n",
       "9                          0.7                      gpu_hist   \n",
       "10                         0.8                      gpu_hist   \n",
       "11                         0.9                      gpu_hist   \n",
       "12                         0.6                      gpu_hist   \n",
       "13                         0.7                      gpu_hist   \n",
       "14                         0.8                      gpu_hist   \n",
       "15                         0.9                      gpu_hist   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classifier__booster': 'gbtree', 'classifier_...          -1.101927   \n",
       "1   {'classifier__booster': 'gbtree', 'classifier_...          -1.101036   \n",
       "2   {'classifier__booster': 'gbtree', 'classifier_...          -1.101560   \n",
       "3   {'classifier__booster': 'gbtree', 'classifier_...          -1.101599   \n",
       "4   {'classifier__booster': 'gbtree', 'classifier_...          -1.102105   \n",
       "5   {'classifier__booster': 'gbtree', 'classifier_...          -1.102253   \n",
       "6   {'classifier__booster': 'gbtree', 'classifier_...          -1.102193   \n",
       "7   {'classifier__booster': 'gbtree', 'classifier_...          -1.102042   \n",
       "8   {'classifier__booster': 'gbtree', 'classifier_...          -1.102275   \n",
       "9   {'classifier__booster': 'gbtree', 'classifier_...          -1.102530   \n",
       "10  {'classifier__booster': 'gbtree', 'classifier_...          -1.102055   \n",
       "11  {'classifier__booster': 'gbtree', 'classifier_...          -1.101855   \n",
       "12  {'classifier__booster': 'gbtree', 'classifier_...          -1.102649   \n",
       "13  {'classifier__booster': 'gbtree', 'classifier_...          -1.102621   \n",
       "14  {'classifier__booster': 'gbtree', 'classifier_...          -1.102986   \n",
       "15  {'classifier__booster': 'gbtree', 'classifier_...          -1.102590   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0           -1.105454          -1.102111          -1.098460        -1.101988   \n",
       "1           -1.104235          -1.102296          -1.098732        -1.101575   \n",
       "2           -1.105028          -1.101733          -1.099192        -1.101878   \n",
       "3           -1.104217          -1.101946          -1.099259        -1.101755   \n",
       "4           -1.105394          -1.101618          -1.099203        -1.102080   \n",
       "5           -1.105544          -1.101816          -1.098909        -1.102131   \n",
       "6           -1.105130          -1.101982          -1.099186        -1.102123   \n",
       "7           -1.104578          -1.102018          -1.099685        -1.102081   \n",
       "8           -1.105272          -1.102405          -1.098801        -1.102188   \n",
       "9           -1.105203          -1.102360          -1.098822        -1.102229   \n",
       "10          -1.105256          -1.102256          -1.099524        -1.102273   \n",
       "11          -1.105317          -1.103011          -1.099310        -1.102373   \n",
       "12          -1.105313          -1.102047          -1.099677        -1.102421   \n",
       "13          -1.105357          -1.102792          -1.099926        -1.102674   \n",
       "14          -1.105623          -1.102360          -1.099191        -1.102540   \n",
       "15          -1.105186          -1.102854          -1.099395        -1.102506   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.002474                4  \n",
       "1         0.001998                1  \n",
       "2         0.002077                3  \n",
       "3         0.001757                2  \n",
       "4         0.002207                5  \n",
       "5         0.002353                8  \n",
       "6         0.002103                7  \n",
       "7         0.001731                6  \n",
       "8         0.002293                9  \n",
       "9         0.002267               10  \n",
       "10        0.002031               11  \n",
       "11        0.002163               12  \n",
       "12        0.002005               13  \n",
       "13        0.001922               16  \n",
       "14        0.002289               15  \n",
       "15        0.002061               14  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid4.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a159e7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'classifier__booster': 'gbtree', 'classifier__colsample_bytree': 0.55, 'classifier__eval_metric': 'mlogloss', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 250, 'classifier__objective': 'multi:softprob', 'classifier__random_state': 42, 'classifier__subsample': 0.75, 'classifier__tree_method': 'gpu_hist'}\n",
      "Best score (Train SMOTE): -1.1014642712062597\n",
      "Test score (Test SMOTE): -1.097393063197136\n",
      "Train logloss (Train): 1.0630465105886757\n",
      "Test logloss (Test): 1.097393063197136\n"
     ]
    }
   ],
   "source": [
    "#checking around subsample=0.7 and colsample_bytree=0.6\n",
    "param_grid5={\"classifier__learning_rate\":[0.1],\n",
    "             \"classifier__n_estimators\":[250],\n",
    "             \"classifier__max_depth\":[4],\n",
    "             \"classifier__min_child_weight\":[2],\n",
    "             \"classifier__gamma\":[0],\n",
    "             \"classifier__subsample\":[0.65,0.7,0.75],\n",
    "             \"classifier__colsample_bytree\":[0.55,0.6,0.65],\n",
    "             \"classifier__objective\":[\"multi:softprob\"],\n",
    "             \"classifier__random_state\":[42],\n",
    "             \"classifier__tree_method\":[\"gpu_hist\"],\n",
    "             \"classifier__booster\":[\"gbtree\"],\n",
    "             \"classifier__eval_metric\":[\"mlogloss\"]}\n",
    "grid5=pipe_smote_gridsearchcv(pipe,param_grid5,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "698708bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__booster</th>\n",
       "      <th>param_classifier__colsample_bytree</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_child_weight</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__objective</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__subsample</th>\n",
       "      <th>param_classifier__tree_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.963247</td>\n",
       "      <td>0.397177</td>\n",
       "      <td>0.176938</td>\n",
       "      <td>0.024720</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.65</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101372</td>\n",
       "      <td>-1.104706</td>\n",
       "      <td>-1.101423</td>\n",
       "      <td>-1.098414</td>\n",
       "      <td>-1.101479</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.388786</td>\n",
       "      <td>0.672301</td>\n",
       "      <td>0.188938</td>\n",
       "      <td>0.037941</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101909</td>\n",
       "      <td>-1.103946</td>\n",
       "      <td>-1.101746</td>\n",
       "      <td>-1.098543</td>\n",
       "      <td>-1.101536</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.005736</td>\n",
       "      <td>0.519488</td>\n",
       "      <td>0.177946</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101610</td>\n",
       "      <td>-1.104739</td>\n",
       "      <td>-1.101589</td>\n",
       "      <td>-1.097919</td>\n",
       "      <td>-1.101464</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.676173</td>\n",
       "      <td>0.439034</td>\n",
       "      <td>0.179691</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.6</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.65</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101364</td>\n",
       "      <td>-1.105089</td>\n",
       "      <td>-1.102075</td>\n",
       "      <td>-1.098987</td>\n",
       "      <td>-1.101879</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.165131</td>\n",
       "      <td>0.278108</td>\n",
       "      <td>0.161688</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.6</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101036</td>\n",
       "      <td>-1.104235</td>\n",
       "      <td>-1.102296</td>\n",
       "      <td>-1.098732</td>\n",
       "      <td>-1.101575</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.176055</td>\n",
       "      <td>0.175738</td>\n",
       "      <td>0.158448</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.6</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102059</td>\n",
       "      <td>-1.105315</td>\n",
       "      <td>-1.101456</td>\n",
       "      <td>-1.098775</td>\n",
       "      <td>-1.101901</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.600992</td>\n",
       "      <td>0.150022</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.65</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.65</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101988</td>\n",
       "      <td>-1.104916</td>\n",
       "      <td>-1.102397</td>\n",
       "      <td>-1.099081</td>\n",
       "      <td>-1.102096</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.712705</td>\n",
       "      <td>0.159724</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.65</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.7</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101293</td>\n",
       "      <td>-1.106006</td>\n",
       "      <td>-1.102275</td>\n",
       "      <td>-1.098708</td>\n",
       "      <td>-1.102071</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.030103</td>\n",
       "      <td>0.479280</td>\n",
       "      <td>0.156199</td>\n",
       "      <td>0.009173</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.65</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101817</td>\n",
       "      <td>-1.105095</td>\n",
       "      <td>-1.102453</td>\n",
       "      <td>-1.099153</td>\n",
       "      <td>-1.102130</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      11.963247      0.397177         0.176938        0.024720   \n",
       "1      12.388786      0.672301         0.188938        0.037941   \n",
       "2      13.005736      0.519488         0.177946        0.006514   \n",
       "3      12.676173      0.439034         0.179691        0.018801   \n",
       "4      12.165131      0.278108         0.161688        0.008848   \n",
       "5      12.176055      0.175738         0.158448        0.007363   \n",
       "6      11.600992      0.150022         0.153700        0.001298   \n",
       "7      11.712705      0.159724         0.153700        0.004204   \n",
       "8      12.030103      0.479280         0.156199        0.009173   \n",
       "\n",
       "  param_classifier__booster param_classifier__colsample_bytree  \\\n",
       "0                    gbtree                               0.55   \n",
       "1                    gbtree                               0.55   \n",
       "2                    gbtree                               0.55   \n",
       "3                    gbtree                                0.6   \n",
       "4                    gbtree                                0.6   \n",
       "5                    gbtree                                0.6   \n",
       "6                    gbtree                               0.65   \n",
       "7                    gbtree                               0.65   \n",
       "8                    gbtree                               0.65   \n",
       "\n",
       "  param_classifier__eval_metric param_classifier__gamma  \\\n",
       "0                      mlogloss                       0   \n",
       "1                      mlogloss                       0   \n",
       "2                      mlogloss                       0   \n",
       "3                      mlogloss                       0   \n",
       "4                      mlogloss                       0   \n",
       "5                      mlogloss                       0   \n",
       "6                      mlogloss                       0   \n",
       "7                      mlogloss                       0   \n",
       "8                      mlogloss                       0   \n",
       "\n",
       "  param_classifier__learning_rate param_classifier__max_depth  \\\n",
       "0                             0.1                           4   \n",
       "1                             0.1                           4   \n",
       "2                             0.1                           4   \n",
       "3                             0.1                           4   \n",
       "4                             0.1                           4   \n",
       "5                             0.1                           4   \n",
       "6                             0.1                           4   \n",
       "7                             0.1                           4   \n",
       "8                             0.1                           4   \n",
       "\n",
       "  param_classifier__min_child_weight param_classifier__n_estimators  \\\n",
       "0                                  2                            250   \n",
       "1                                  2                            250   \n",
       "2                                  2                            250   \n",
       "3                                  2                            250   \n",
       "4                                  2                            250   \n",
       "5                                  2                            250   \n",
       "6                                  2                            250   \n",
       "7                                  2                            250   \n",
       "8                                  2                            250   \n",
       "\n",
       "  param_classifier__objective param_classifier__random_state  \\\n",
       "0              multi:softprob                             42   \n",
       "1              multi:softprob                             42   \n",
       "2              multi:softprob                             42   \n",
       "3              multi:softprob                             42   \n",
       "4              multi:softprob                             42   \n",
       "5              multi:softprob                             42   \n",
       "6              multi:softprob                             42   \n",
       "7              multi:softprob                             42   \n",
       "8              multi:softprob                             42   \n",
       "\n",
       "  param_classifier__subsample param_classifier__tree_method  \\\n",
       "0                        0.65                      gpu_hist   \n",
       "1                         0.7                      gpu_hist   \n",
       "2                        0.75                      gpu_hist   \n",
       "3                        0.65                      gpu_hist   \n",
       "4                         0.7                      gpu_hist   \n",
       "5                        0.75                      gpu_hist   \n",
       "6                        0.65                      gpu_hist   \n",
       "7                         0.7                      gpu_hist   \n",
       "8                        0.75                      gpu_hist   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'classifier__booster': 'gbtree', 'classifier_...          -1.101372   \n",
       "1  {'classifier__booster': 'gbtree', 'classifier_...          -1.101909   \n",
       "2  {'classifier__booster': 'gbtree', 'classifier_...          -1.101610   \n",
       "3  {'classifier__booster': 'gbtree', 'classifier_...          -1.101364   \n",
       "4  {'classifier__booster': 'gbtree', 'classifier_...          -1.101036   \n",
       "5  {'classifier__booster': 'gbtree', 'classifier_...          -1.102059   \n",
       "6  {'classifier__booster': 'gbtree', 'classifier_...          -1.101988   \n",
       "7  {'classifier__booster': 'gbtree', 'classifier_...          -1.101293   \n",
       "8  {'classifier__booster': 'gbtree', 'classifier_...          -1.101817   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0          -1.104706          -1.101423          -1.098414        -1.101479   \n",
       "1          -1.103946          -1.101746          -1.098543        -1.101536   \n",
       "2          -1.104739          -1.101589          -1.097919        -1.101464   \n",
       "3          -1.105089          -1.102075          -1.098987        -1.101879   \n",
       "4          -1.104235          -1.102296          -1.098732        -1.101575   \n",
       "5          -1.105315          -1.101456          -1.098775        -1.101901   \n",
       "6          -1.104916          -1.102397          -1.099081        -1.102096   \n",
       "7          -1.106006          -1.102275          -1.098708        -1.102071   \n",
       "8          -1.105095          -1.102453          -1.099153        -1.102130   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.002226                2  \n",
       "1        0.001933                3  \n",
       "2        0.002415                1  \n",
       "3        0.002178                5  \n",
       "4        0.001998                4  \n",
       "5        0.002326                6  \n",
       "6        0.002070                8  \n",
       "7        0.002619                7  \n",
       "8        0.002113                9  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid5.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6130c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'classifier__booster': 'gbtree', 'classifier__colsample_bytree': 0.5, 'classifier__eval_metric': 'mlogloss', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 250, 'classifier__objective': 'multi:softprob', 'classifier__random_state': 42, 'classifier__subsample': 0.75, 'classifier__tree_method': 'gpu_hist'}\n",
      "Best score (Train SMOTE): -1.1013222855420908\n",
      "Test score (Test SMOTE): -1.0980036335384846\n",
      "Train logloss (Train): 1.0637846160143614\n",
      "Test logloss (Test): 1.0980036335384846\n"
     ]
    }
   ],
   "source": [
    "#checking even lower values for colsample_bytree\n",
    "param_grid55={\"classifier__learning_rate\":[0.1],\n",
    "             \"classifier__n_estimators\":[250],\n",
    "             \"classifier__max_depth\":[4],\n",
    "             \"classifier__min_child_weight\":[2],\n",
    "             \"classifier__gamma\":[0],\n",
    "             \"classifier__subsample\":[0.75],\n",
    "             \"classifier__colsample_bytree\":[0.45,0.5,0.55],\n",
    "             \"classifier__objective\":[\"multi:softprob\"],\n",
    "             \"classifier__random_state\":[42],\n",
    "             \"classifier__tree_method\":[\"gpu_hist\"],\n",
    "             \"classifier__booster\":[\"gbtree\"],\n",
    "             \"classifier__eval_metric\":[\"mlogloss\"]}\n",
    "grid55=pipe_smote_gridsearchcv(pipe,param_grid55,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "197501a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__booster</th>\n",
       "      <th>param_classifier__colsample_bytree</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_child_weight</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__objective</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__subsample</th>\n",
       "      <th>param_classifier__tree_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.807592</td>\n",
       "      <td>0.302397</td>\n",
       "      <td>0.171439</td>\n",
       "      <td>0.020163</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.45</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101490</td>\n",
       "      <td>-1.104167</td>\n",
       "      <td>-1.101067</td>\n",
       "      <td>-1.098658</td>\n",
       "      <td>-1.101346</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.605982</td>\n",
       "      <td>0.128653</td>\n",
       "      <td>0.161192</td>\n",
       "      <td>0.007460</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101503</td>\n",
       "      <td>-1.104458</td>\n",
       "      <td>-1.101625</td>\n",
       "      <td>-1.097703</td>\n",
       "      <td>-1.101322</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.584693</td>\n",
       "      <td>0.103512</td>\n",
       "      <td>0.159943</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101610</td>\n",
       "      <td>-1.104739</td>\n",
       "      <td>-1.101589</td>\n",
       "      <td>-1.097919</td>\n",
       "      <td>-1.101464</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      12.807592      0.302397         0.171439        0.020163   \n",
       "1      12.605982      0.128653         0.161192        0.007460   \n",
       "2      12.584693      0.103512         0.159943        0.005517   \n",
       "\n",
       "  param_classifier__booster param_classifier__colsample_bytree  \\\n",
       "0                    gbtree                               0.45   \n",
       "1                    gbtree                                0.5   \n",
       "2                    gbtree                               0.55   \n",
       "\n",
       "  param_classifier__eval_metric param_classifier__gamma  \\\n",
       "0                      mlogloss                       0   \n",
       "1                      mlogloss                       0   \n",
       "2                      mlogloss                       0   \n",
       "\n",
       "  param_classifier__learning_rate param_classifier__max_depth  \\\n",
       "0                             0.1                           4   \n",
       "1                             0.1                           4   \n",
       "2                             0.1                           4   \n",
       "\n",
       "  param_classifier__min_child_weight param_classifier__n_estimators  \\\n",
       "0                                  2                            250   \n",
       "1                                  2                            250   \n",
       "2                                  2                            250   \n",
       "\n",
       "  param_classifier__objective param_classifier__random_state  \\\n",
       "0              multi:softprob                             42   \n",
       "1              multi:softprob                             42   \n",
       "2              multi:softprob                             42   \n",
       "\n",
       "  param_classifier__subsample param_classifier__tree_method  \\\n",
       "0                        0.75                      gpu_hist   \n",
       "1                        0.75                      gpu_hist   \n",
       "2                        0.75                      gpu_hist   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'classifier__booster': 'gbtree', 'classifier_...          -1.101490   \n",
       "1  {'classifier__booster': 'gbtree', 'classifier_...          -1.101503   \n",
       "2  {'classifier__booster': 'gbtree', 'classifier_...          -1.101610   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0          -1.104167          -1.101067          -1.098658        -1.101346   \n",
       "1          -1.104458          -1.101625          -1.097703        -1.101322   \n",
       "2          -1.104739          -1.101589          -1.097919        -1.101464   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.001955                2  \n",
       "1        0.002401                1  \n",
       "2        0.002415                3  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid55.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b821602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'classifier__booster': 'gbtree', 'classifier__colsample_bytree': 0.55, 'classifier__eval_metric': 'mlogloss', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 250, 'classifier__objective': 'multi:softprob', 'classifier__random_state': 42, 'classifier__reg_alpha': 10, 'classifier__reg_lambda': 10, 'classifier__subsample': 0.75, 'classifier__tree_method': 'gpu_hist'}\n",
      "Best score (Train SMOTE): -1.1001997400776546\n",
      "Test score (Test SMOTE): -1.097737533749342\n",
      "Train logloss (Train): 1.0725094157181183\n",
      "Test logloss (Test): 1.097737533749342\n"
     ]
    }
   ],
   "source": [
    "#best subsample=0.75 and colsample_bytree=0.5 but on test set better colsample_bytree=0.55\n",
    "#finging reg_alpha and reg_lambda\n",
    "param_grid6={\"classifier__learning_rate\":[0.1],\n",
    "             \"classifier__n_estimators\":[250],\n",
    "             \"classifier__max_depth\":[4],\n",
    "             \"classifier__min_child_weight\":[2],\n",
    "             \"classifier__gamma\":[0],\n",
    "             \"classifier__subsample\":[0.75],\n",
    "             \"classifier__colsample_bytree\":[0.55],\n",
    "             \"classifier__reg_alpha\":[0,1e-5,0.01,0.1,1,10],\n",
    "             \"classifier__reg_lambda\":[0,0.01,0.1,1,10],\n",
    "             \"classifier__objective\":[\"multi:softprob\"],\n",
    "             \"classifier__random_state\":[42],\n",
    "             \"classifier__tree_method\":[\"gpu_hist\"],\n",
    "             \"classifier__booster\":[\"gbtree\"],\n",
    "             \"classifier__eval_metric\":[\"mlogloss\"]}\n",
    "grid6=pipe_smote_gridsearchcv(pipe,param_grid6,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52f0d8f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__booster</th>\n",
       "      <th>param_classifier__colsample_bytree</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_child_weight</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__objective</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__reg_alpha</th>\n",
       "      <th>param_classifier__reg_lambda</th>\n",
       "      <th>param_classifier__subsample</th>\n",
       "      <th>param_classifier__tree_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.278624</td>\n",
       "      <td>0.360688</td>\n",
       "      <td>0.155190</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101046</td>\n",
       "      <td>-1.104136</td>\n",
       "      <td>-1.101780</td>\n",
       "      <td>-1.098368</td>\n",
       "      <td>-1.101333</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.014040</td>\n",
       "      <td>0.509999</td>\n",
       "      <td>0.160938</td>\n",
       "      <td>0.015699</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100873</td>\n",
       "      <td>-1.104091</td>\n",
       "      <td>-1.102050</td>\n",
       "      <td>-1.098571</td>\n",
       "      <td>-1.101396</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.478095</td>\n",
       "      <td>0.124171</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101621</td>\n",
       "      <td>-1.103987</td>\n",
       "      <td>-1.102012</td>\n",
       "      <td>-1.098190</td>\n",
       "      <td>-1.101453</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.450050</td>\n",
       "      <td>0.112668</td>\n",
       "      <td>0.153195</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101610</td>\n",
       "      <td>-1.104739</td>\n",
       "      <td>-1.101589</td>\n",
       "      <td>-1.097919</td>\n",
       "      <td>-1.101464</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.458075</td>\n",
       "      <td>0.157135</td>\n",
       "      <td>0.149446</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100580</td>\n",
       "      <td>-1.104177</td>\n",
       "      <td>-1.101540</td>\n",
       "      <td>-1.097669</td>\n",
       "      <td>-1.100991</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.504953</td>\n",
       "      <td>0.139113</td>\n",
       "      <td>0.148939</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100913</td>\n",
       "      <td>-1.104156</td>\n",
       "      <td>-1.101779</td>\n",
       "      <td>-1.098368</td>\n",
       "      <td>-1.101304</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.488075</td>\n",
       "      <td>0.134385</td>\n",
       "      <td>0.150193</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100873</td>\n",
       "      <td>-1.104090</td>\n",
       "      <td>-1.102050</td>\n",
       "      <td>-1.098520</td>\n",
       "      <td>-1.101383</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.479879</td>\n",
       "      <td>0.137480</td>\n",
       "      <td>0.150193</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101623</td>\n",
       "      <td>-1.103987</td>\n",
       "      <td>-1.102022</td>\n",
       "      <td>-1.098422</td>\n",
       "      <td>-1.101513</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.445717</td>\n",
       "      <td>0.105562</td>\n",
       "      <td>0.149445</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101406</td>\n",
       "      <td>-1.104594</td>\n",
       "      <td>-1.101589</td>\n",
       "      <td>-1.097919</td>\n",
       "      <td>-1.101377</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.447605</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>0.150451</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100579</td>\n",
       "      <td>-1.104177</td>\n",
       "      <td>-1.101540</td>\n",
       "      <td>-1.097669</td>\n",
       "      <td>-1.100991</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.466717</td>\n",
       "      <td>0.138477</td>\n",
       "      <td>0.148698</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101114</td>\n",
       "      <td>-1.104124</td>\n",
       "      <td>-1.101757</td>\n",
       "      <td>-1.098300</td>\n",
       "      <td>-1.101324</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.494026</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.150451</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101688</td>\n",
       "      <td>-1.104259</td>\n",
       "      <td>-1.101800</td>\n",
       "      <td>-1.098440</td>\n",
       "      <td>-1.101547</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.866056</td>\n",
       "      <td>0.273350</td>\n",
       "      <td>0.151446</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.102102</td>\n",
       "      <td>-1.104740</td>\n",
       "      <td>-1.101640</td>\n",
       "      <td>-1.098733</td>\n",
       "      <td>-1.101804</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.616396</td>\n",
       "      <td>0.247065</td>\n",
       "      <td>0.163193</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101301</td>\n",
       "      <td>-1.104229</td>\n",
       "      <td>-1.102111</td>\n",
       "      <td>-1.098249</td>\n",
       "      <td>-1.101473</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.475001</td>\n",
       "      <td>0.117480</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100874</td>\n",
       "      <td>-1.103978</td>\n",
       "      <td>-1.101605</td>\n",
       "      <td>-1.097638</td>\n",
       "      <td>-1.101024</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.611477</td>\n",
       "      <td>0.200878</td>\n",
       "      <td>0.150937</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101288</td>\n",
       "      <td>-1.104433</td>\n",
       "      <td>-1.101798</td>\n",
       "      <td>-1.097887</td>\n",
       "      <td>-1.101351</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.975115</td>\n",
       "      <td>0.160798</td>\n",
       "      <td>0.162697</td>\n",
       "      <td>0.007593</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101214</td>\n",
       "      <td>-1.104550</td>\n",
       "      <td>-1.101930</td>\n",
       "      <td>-1.098259</td>\n",
       "      <td>-1.101488</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.968622</td>\n",
       "      <td>0.451643</td>\n",
       "      <td>0.159198</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101694</td>\n",
       "      <td>-1.104556</td>\n",
       "      <td>-1.102070</td>\n",
       "      <td>-1.098384</td>\n",
       "      <td>-1.101676</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12.207545</td>\n",
       "      <td>0.661284</td>\n",
       "      <td>0.179691</td>\n",
       "      <td>0.021917</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.101247</td>\n",
       "      <td>-1.104172</td>\n",
       "      <td>-1.101779</td>\n",
       "      <td>-1.097672</td>\n",
       "      <td>-1.101218</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.520660</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.160943</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100856</td>\n",
       "      <td>-1.103753</td>\n",
       "      <td>-1.101513</td>\n",
       "      <td>-1.097257</td>\n",
       "      <td>-1.100845</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12.532513</td>\n",
       "      <td>0.124933</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100433</td>\n",
       "      <td>-1.104349</td>\n",
       "      <td>-1.101691</td>\n",
       "      <td>-1.098141</td>\n",
       "      <td>-1.101153</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.503704</td>\n",
       "      <td>0.121546</td>\n",
       "      <td>0.162942</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100875</td>\n",
       "      <td>-1.103780</td>\n",
       "      <td>-1.101825</td>\n",
       "      <td>-1.097884</td>\n",
       "      <td>-1.101091</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.501968</td>\n",
       "      <td>0.147214</td>\n",
       "      <td>0.161187</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100479</td>\n",
       "      <td>-1.104325</td>\n",
       "      <td>-1.101744</td>\n",
       "      <td>-1.098417</td>\n",
       "      <td>-1.101241</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.487938</td>\n",
       "      <td>0.127322</td>\n",
       "      <td>0.162442</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-1.104405</td>\n",
       "      <td>-1.101450</td>\n",
       "      <td>-1.098069</td>\n",
       "      <td>-1.101204</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.516982</td>\n",
       "      <td>0.121730</td>\n",
       "      <td>0.165941</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100799</td>\n",
       "      <td>-1.104090</td>\n",
       "      <td>-1.101454</td>\n",
       "      <td>-1.097747</td>\n",
       "      <td>-1.101022</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.691687</td>\n",
       "      <td>0.082217</td>\n",
       "      <td>0.164196</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100454</td>\n",
       "      <td>-1.102863</td>\n",
       "      <td>-1.100969</td>\n",
       "      <td>-1.097226</td>\n",
       "      <td>-1.100378</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.718750</td>\n",
       "      <td>0.174193</td>\n",
       "      <td>0.171934</td>\n",
       "      <td>0.030809</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100454</td>\n",
       "      <td>-1.102863</td>\n",
       "      <td>-1.100969</td>\n",
       "      <td>-1.097047</td>\n",
       "      <td>-1.100333</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.587805</td>\n",
       "      <td>0.152274</td>\n",
       "      <td>0.161443</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100968</td>\n",
       "      <td>-1.102923</td>\n",
       "      <td>-1.100989</td>\n",
       "      <td>-1.096978</td>\n",
       "      <td>-1.100464</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.595663</td>\n",
       "      <td>0.126693</td>\n",
       "      <td>0.161448</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100638</td>\n",
       "      <td>-1.103026</td>\n",
       "      <td>-1.100957</td>\n",
       "      <td>-1.097186</td>\n",
       "      <td>-1.100452</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.631657</td>\n",
       "      <td>0.161285</td>\n",
       "      <td>0.163197</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100536</td>\n",
       "      <td>-1.102621</td>\n",
       "      <td>-1.100570</td>\n",
       "      <td>-1.097072</td>\n",
       "      <td>-1.100200</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       12.278624      0.360688         0.155190        0.005799   \n",
       "1       12.014040      0.509999         0.160938        0.015699   \n",
       "2       11.478095      0.124171         0.148452        0.000866   \n",
       "3       11.450050      0.112668         0.153195        0.001293   \n",
       "4       11.458075      0.157135         0.149446        0.001662   \n",
       "5       11.504953      0.139113         0.148939        0.000709   \n",
       "6       11.488075      0.134385         0.150193        0.002270   \n",
       "7       11.479879      0.137480         0.150193        0.001299   \n",
       "8       11.445717      0.105562         0.149445        0.000862   \n",
       "9       11.447605      0.129337         0.150451        0.002290   \n",
       "10      11.466717      0.138477         0.148698        0.001301   \n",
       "11      11.494026      0.115972         0.150451        0.001500   \n",
       "12      11.866056      0.273350         0.151446        0.002493   \n",
       "13      11.616396      0.247065         0.163193        0.013272   \n",
       "14      11.475001      0.117480         0.148452        0.000500   \n",
       "15      11.611477      0.200878         0.150937        0.002237   \n",
       "16      11.975115      0.160798         0.162697        0.007593   \n",
       "17      11.968622      0.451643         0.159198        0.009467   \n",
       "18      12.207545      0.661284         0.179691        0.021917   \n",
       "19      12.520660      0.133475         0.160943        0.001005   \n",
       "20      12.532513      0.124933         0.161947        0.001000   \n",
       "21      12.503704      0.121546         0.162942        0.002913   \n",
       "22      12.501968      0.147214         0.161187        0.001082   \n",
       "23      12.487938      0.127322         0.162442        0.001501   \n",
       "24      12.516982      0.121730         0.165941        0.006402   \n",
       "25      12.691687      0.082217         0.164196        0.008951   \n",
       "26      12.718750      0.174193         0.171934        0.030809   \n",
       "27      12.587805      0.152274         0.161443        0.005585   \n",
       "28      12.595663      0.126693         0.161448        0.003904   \n",
       "29      12.631657      0.161285         0.163197        0.003112   \n",
       "\n",
       "   param_classifier__booster param_classifier__colsample_bytree  \\\n",
       "0                     gbtree                               0.55   \n",
       "1                     gbtree                               0.55   \n",
       "2                     gbtree                               0.55   \n",
       "3                     gbtree                               0.55   \n",
       "4                     gbtree                               0.55   \n",
       "5                     gbtree                               0.55   \n",
       "6                     gbtree                               0.55   \n",
       "7                     gbtree                               0.55   \n",
       "8                     gbtree                               0.55   \n",
       "9                     gbtree                               0.55   \n",
       "10                    gbtree                               0.55   \n",
       "11                    gbtree                               0.55   \n",
       "12                    gbtree                               0.55   \n",
       "13                    gbtree                               0.55   \n",
       "14                    gbtree                               0.55   \n",
       "15                    gbtree                               0.55   \n",
       "16                    gbtree                               0.55   \n",
       "17                    gbtree                               0.55   \n",
       "18                    gbtree                               0.55   \n",
       "19                    gbtree                               0.55   \n",
       "20                    gbtree                               0.55   \n",
       "21                    gbtree                               0.55   \n",
       "22                    gbtree                               0.55   \n",
       "23                    gbtree                               0.55   \n",
       "24                    gbtree                               0.55   \n",
       "25                    gbtree                               0.55   \n",
       "26                    gbtree                               0.55   \n",
       "27                    gbtree                               0.55   \n",
       "28                    gbtree                               0.55   \n",
       "29                    gbtree                               0.55   \n",
       "\n",
       "   param_classifier__eval_metric param_classifier__gamma  \\\n",
       "0                       mlogloss                       0   \n",
       "1                       mlogloss                       0   \n",
       "2                       mlogloss                       0   \n",
       "3                       mlogloss                       0   \n",
       "4                       mlogloss                       0   \n",
       "5                       mlogloss                       0   \n",
       "6                       mlogloss                       0   \n",
       "7                       mlogloss                       0   \n",
       "8                       mlogloss                       0   \n",
       "9                       mlogloss                       0   \n",
       "10                      mlogloss                       0   \n",
       "11                      mlogloss                       0   \n",
       "12                      mlogloss                       0   \n",
       "13                      mlogloss                       0   \n",
       "14                      mlogloss                       0   \n",
       "15                      mlogloss                       0   \n",
       "16                      mlogloss                       0   \n",
       "17                      mlogloss                       0   \n",
       "18                      mlogloss                       0   \n",
       "19                      mlogloss                       0   \n",
       "20                      mlogloss                       0   \n",
       "21                      mlogloss                       0   \n",
       "22                      mlogloss                       0   \n",
       "23                      mlogloss                       0   \n",
       "24                      mlogloss                       0   \n",
       "25                      mlogloss                       0   \n",
       "26                      mlogloss                       0   \n",
       "27                      mlogloss                       0   \n",
       "28                      mlogloss                       0   \n",
       "29                      mlogloss                       0   \n",
       "\n",
       "   param_classifier__learning_rate param_classifier__max_depth  \\\n",
       "0                              0.1                           4   \n",
       "1                              0.1                           4   \n",
       "2                              0.1                           4   \n",
       "3                              0.1                           4   \n",
       "4                              0.1                           4   \n",
       "5                              0.1                           4   \n",
       "6                              0.1                           4   \n",
       "7                              0.1                           4   \n",
       "8                              0.1                           4   \n",
       "9                              0.1                           4   \n",
       "10                             0.1                           4   \n",
       "11                             0.1                           4   \n",
       "12                             0.1                           4   \n",
       "13                             0.1                           4   \n",
       "14                             0.1                           4   \n",
       "15                             0.1                           4   \n",
       "16                             0.1                           4   \n",
       "17                             0.1                           4   \n",
       "18                             0.1                           4   \n",
       "19                             0.1                           4   \n",
       "20                             0.1                           4   \n",
       "21                             0.1                           4   \n",
       "22                             0.1                           4   \n",
       "23                             0.1                           4   \n",
       "24                             0.1                           4   \n",
       "25                             0.1                           4   \n",
       "26                             0.1                           4   \n",
       "27                             0.1                           4   \n",
       "28                             0.1                           4   \n",
       "29                             0.1                           4   \n",
       "\n",
       "   param_classifier__min_child_weight param_classifier__n_estimators  \\\n",
       "0                                   2                            250   \n",
       "1                                   2                            250   \n",
       "2                                   2                            250   \n",
       "3                                   2                            250   \n",
       "4                                   2                            250   \n",
       "5                                   2                            250   \n",
       "6                                   2                            250   \n",
       "7                                   2                            250   \n",
       "8                                   2                            250   \n",
       "9                                   2                            250   \n",
       "10                                  2                            250   \n",
       "11                                  2                            250   \n",
       "12                                  2                            250   \n",
       "13                                  2                            250   \n",
       "14                                  2                            250   \n",
       "15                                  2                            250   \n",
       "16                                  2                            250   \n",
       "17                                  2                            250   \n",
       "18                                  2                            250   \n",
       "19                                  2                            250   \n",
       "20                                  2                            250   \n",
       "21                                  2                            250   \n",
       "22                                  2                            250   \n",
       "23                                  2                            250   \n",
       "24                                  2                            250   \n",
       "25                                  2                            250   \n",
       "26                                  2                            250   \n",
       "27                                  2                            250   \n",
       "28                                  2                            250   \n",
       "29                                  2                            250   \n",
       "\n",
       "   param_classifier__objective param_classifier__random_state  \\\n",
       "0               multi:softprob                             42   \n",
       "1               multi:softprob                             42   \n",
       "2               multi:softprob                             42   \n",
       "3               multi:softprob                             42   \n",
       "4               multi:softprob                             42   \n",
       "5               multi:softprob                             42   \n",
       "6               multi:softprob                             42   \n",
       "7               multi:softprob                             42   \n",
       "8               multi:softprob                             42   \n",
       "9               multi:softprob                             42   \n",
       "10              multi:softprob                             42   \n",
       "11              multi:softprob                             42   \n",
       "12              multi:softprob                             42   \n",
       "13              multi:softprob                             42   \n",
       "14              multi:softprob                             42   \n",
       "15              multi:softprob                             42   \n",
       "16              multi:softprob                             42   \n",
       "17              multi:softprob                             42   \n",
       "18              multi:softprob                             42   \n",
       "19              multi:softprob                             42   \n",
       "20              multi:softprob                             42   \n",
       "21              multi:softprob                             42   \n",
       "22              multi:softprob                             42   \n",
       "23              multi:softprob                             42   \n",
       "24              multi:softprob                             42   \n",
       "25              multi:softprob                             42   \n",
       "26              multi:softprob                             42   \n",
       "27              multi:softprob                             42   \n",
       "28              multi:softprob                             42   \n",
       "29              multi:softprob                             42   \n",
       "\n",
       "   param_classifier__reg_alpha param_classifier__reg_lambda  \\\n",
       "0                            0                            0   \n",
       "1                            0                         0.01   \n",
       "2                            0                          0.1   \n",
       "3                            0                            1   \n",
       "4                            0                           10   \n",
       "5                        1e-05                            0   \n",
       "6                        1e-05                         0.01   \n",
       "7                        1e-05                          0.1   \n",
       "8                        1e-05                            1   \n",
       "9                        1e-05                           10   \n",
       "10                        0.01                            0   \n",
       "11                        0.01                         0.01   \n",
       "12                        0.01                          0.1   \n",
       "13                        0.01                            1   \n",
       "14                        0.01                           10   \n",
       "15                         0.1                            0   \n",
       "16                         0.1                         0.01   \n",
       "17                         0.1                          0.1   \n",
       "18                         0.1                            1   \n",
       "19                         0.1                           10   \n",
       "20                           1                            0   \n",
       "21                           1                         0.01   \n",
       "22                           1                          0.1   \n",
       "23                           1                            1   \n",
       "24                           1                           10   \n",
       "25                          10                            0   \n",
       "26                          10                         0.01   \n",
       "27                          10                          0.1   \n",
       "28                          10                            1   \n",
       "29                          10                           10   \n",
       "\n",
       "   param_classifier__subsample param_classifier__tree_method  \\\n",
       "0                         0.75                      gpu_hist   \n",
       "1                         0.75                      gpu_hist   \n",
       "2                         0.75                      gpu_hist   \n",
       "3                         0.75                      gpu_hist   \n",
       "4                         0.75                      gpu_hist   \n",
       "5                         0.75                      gpu_hist   \n",
       "6                         0.75                      gpu_hist   \n",
       "7                         0.75                      gpu_hist   \n",
       "8                         0.75                      gpu_hist   \n",
       "9                         0.75                      gpu_hist   \n",
       "10                        0.75                      gpu_hist   \n",
       "11                        0.75                      gpu_hist   \n",
       "12                        0.75                      gpu_hist   \n",
       "13                        0.75                      gpu_hist   \n",
       "14                        0.75                      gpu_hist   \n",
       "15                        0.75                      gpu_hist   \n",
       "16                        0.75                      gpu_hist   \n",
       "17                        0.75                      gpu_hist   \n",
       "18                        0.75                      gpu_hist   \n",
       "19                        0.75                      gpu_hist   \n",
       "20                        0.75                      gpu_hist   \n",
       "21                        0.75                      gpu_hist   \n",
       "22                        0.75                      gpu_hist   \n",
       "23                        0.75                      gpu_hist   \n",
       "24                        0.75                      gpu_hist   \n",
       "25                        0.75                      gpu_hist   \n",
       "26                        0.75                      gpu_hist   \n",
       "27                        0.75                      gpu_hist   \n",
       "28                        0.75                      gpu_hist   \n",
       "29                        0.75                      gpu_hist   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classifier__booster': 'gbtree', 'classifier_...          -1.101046   \n",
       "1   {'classifier__booster': 'gbtree', 'classifier_...          -1.100873   \n",
       "2   {'classifier__booster': 'gbtree', 'classifier_...          -1.101621   \n",
       "3   {'classifier__booster': 'gbtree', 'classifier_...          -1.101610   \n",
       "4   {'classifier__booster': 'gbtree', 'classifier_...          -1.100580   \n",
       "5   {'classifier__booster': 'gbtree', 'classifier_...          -1.100913   \n",
       "6   {'classifier__booster': 'gbtree', 'classifier_...          -1.100873   \n",
       "7   {'classifier__booster': 'gbtree', 'classifier_...          -1.101623   \n",
       "8   {'classifier__booster': 'gbtree', 'classifier_...          -1.101406   \n",
       "9   {'classifier__booster': 'gbtree', 'classifier_...          -1.100579   \n",
       "10  {'classifier__booster': 'gbtree', 'classifier_...          -1.101114   \n",
       "11  {'classifier__booster': 'gbtree', 'classifier_...          -1.101688   \n",
       "12  {'classifier__booster': 'gbtree', 'classifier_...          -1.102102   \n",
       "13  {'classifier__booster': 'gbtree', 'classifier_...          -1.101301   \n",
       "14  {'classifier__booster': 'gbtree', 'classifier_...          -1.100874   \n",
       "15  {'classifier__booster': 'gbtree', 'classifier_...          -1.101288   \n",
       "16  {'classifier__booster': 'gbtree', 'classifier_...          -1.101214   \n",
       "17  {'classifier__booster': 'gbtree', 'classifier_...          -1.101694   \n",
       "18  {'classifier__booster': 'gbtree', 'classifier_...          -1.101247   \n",
       "19  {'classifier__booster': 'gbtree', 'classifier_...          -1.100856   \n",
       "20  {'classifier__booster': 'gbtree', 'classifier_...          -1.100433   \n",
       "21  {'classifier__booster': 'gbtree', 'classifier_...          -1.100875   \n",
       "22  {'classifier__booster': 'gbtree', 'classifier_...          -1.100479   \n",
       "23  {'classifier__booster': 'gbtree', 'classifier_...          -1.100894   \n",
       "24  {'classifier__booster': 'gbtree', 'classifier_...          -1.100799   \n",
       "25  {'classifier__booster': 'gbtree', 'classifier_...          -1.100454   \n",
       "26  {'classifier__booster': 'gbtree', 'classifier_...          -1.100454   \n",
       "27  {'classifier__booster': 'gbtree', 'classifier_...          -1.100968   \n",
       "28  {'classifier__booster': 'gbtree', 'classifier_...          -1.100638   \n",
       "29  {'classifier__booster': 'gbtree', 'classifier_...          -1.100536   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0           -1.104136          -1.101780          -1.098368        -1.101333   \n",
       "1           -1.104091          -1.102050          -1.098571        -1.101396   \n",
       "2           -1.103987          -1.102012          -1.098190        -1.101453   \n",
       "3           -1.104739          -1.101589          -1.097919        -1.101464   \n",
       "4           -1.104177          -1.101540          -1.097669        -1.100991   \n",
       "5           -1.104156          -1.101779          -1.098368        -1.101304   \n",
       "6           -1.104090          -1.102050          -1.098520        -1.101383   \n",
       "7           -1.103987          -1.102022          -1.098422        -1.101513   \n",
       "8           -1.104594          -1.101589          -1.097919        -1.101377   \n",
       "9           -1.104177          -1.101540          -1.097669        -1.100991   \n",
       "10          -1.104124          -1.101757          -1.098300        -1.101324   \n",
       "11          -1.104259          -1.101800          -1.098440        -1.101547   \n",
       "12          -1.104740          -1.101640          -1.098733        -1.101804   \n",
       "13          -1.104229          -1.102111          -1.098249        -1.101473   \n",
       "14          -1.103978          -1.101605          -1.097638        -1.101024   \n",
       "15          -1.104433          -1.101798          -1.097887        -1.101351   \n",
       "16          -1.104550          -1.101930          -1.098259        -1.101488   \n",
       "17          -1.104556          -1.102070          -1.098384        -1.101676   \n",
       "18          -1.104172          -1.101779          -1.097672        -1.101218   \n",
       "19          -1.103753          -1.101513          -1.097257        -1.100845   \n",
       "20          -1.104349          -1.101691          -1.098141        -1.101153   \n",
       "21          -1.103780          -1.101825          -1.097884        -1.101091   \n",
       "22          -1.104325          -1.101744          -1.098417        -1.101241   \n",
       "23          -1.104405          -1.101450          -1.098069        -1.101204   \n",
       "24          -1.104090          -1.101454          -1.097747        -1.101022   \n",
       "25          -1.102863          -1.100969          -1.097226        -1.100378   \n",
       "26          -1.102863          -1.100969          -1.097047        -1.100333   \n",
       "27          -1.102923          -1.100989          -1.096978        -1.100464   \n",
       "28          -1.103026          -1.100957          -1.097186        -1.100452   \n",
       "29          -1.102621          -1.100570          -1.097072        -1.100200   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.002057               18  \n",
       "1         0.001997               22  \n",
       "2         0.002086               23  \n",
       "3         0.002415               24  \n",
       "4         0.002327                8  \n",
       "5         0.002069               16  \n",
       "6         0.002014               21  \n",
       "7         0.001996               27  \n",
       "8         0.002364               20  \n",
       "9         0.002327                7  \n",
       "10        0.002075               17  \n",
       "11        0.002067               28  \n",
       "12        0.002131               30  \n",
       "13        0.002146               25  \n",
       "14        0.002267               10  \n",
       "15        0.002329               19  \n",
       "16        0.002240               26  \n",
       "17        0.002196               29  \n",
       "18        0.002325               14  \n",
       "19        0.002333                6  \n",
       "20        0.002241               12  \n",
       "21        0.002127               11  \n",
       "22        0.002140               15  \n",
       "23        0.002249               13  \n",
       "24        0.002257                9  \n",
       "25        0.002029                3  \n",
       "26        0.002099                2  \n",
       "27        0.002164                5  \n",
       "28        0.002096                4  \n",
       "29        0.001993                1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid6.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef603ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'classifier__booster': 'gbtree', 'classifier__colsample_bytree': 0.55, 'classifier__eval_metric': 'mlogloss', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 250, 'classifier__objective': 'multi:softprob', 'classifier__random_state': 42, 'classifier__reg_alpha': 15, 'classifier__reg_lambda': 10, 'classifier__subsample': 0.75, 'classifier__tree_method': 'gpu_hist'}\n",
      "Best score (Train SMOTE): -1.0998426176375151\n",
      "Test score (Test SMOTE): -1.097658251903653\n",
      "Train logloss (Train): 1.0749073590741556\n",
      "Test logloss (Test): 1.097658251903653\n"
     ]
    }
   ],
   "source": [
    "#checking around alpha=10 and lambda=10\n",
    "param_grid7={\"classifier__learning_rate\":[0.1],\n",
    "             \"classifier__n_estimators\":[250],\n",
    "             \"classifier__max_depth\":[4],\n",
    "             \"classifier__min_child_weight\":[2],\n",
    "             \"classifier__gamma\":[0],\n",
    "             \"classifier__subsample\":[0.75],\n",
    "             \"classifier__colsample_bytree\":[0.55],\n",
    "             \"classifier__reg_alpha\":[8,10,15,30,100],\n",
    "             \"classifier__reg_lambda\":[5,8,10,15,30,100],\n",
    "             \"classifier__objective\":[\"multi:softprob\"],\n",
    "             \"classifier__random_state\":[42],\n",
    "             \"classifier__tree_method\":[\"gpu_hist\"],\n",
    "             \"classifier__booster\":[\"gbtree\"],\n",
    "             \"classifier__eval_metric\":[\"mlogloss\"]}\n",
    "grid7=pipe_smote_gridsearchcv(pipe,param_grid7,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76b21884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__booster</th>\n",
       "      <th>param_classifier__colsample_bytree</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_child_weight</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__objective</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__reg_alpha</th>\n",
       "      <th>param_classifier__reg_lambda</th>\n",
       "      <th>param_classifier__subsample</th>\n",
       "      <th>param_classifier__tree_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.291557</td>\n",
       "      <td>0.580178</td>\n",
       "      <td>0.160944</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100599</td>\n",
       "      <td>-1.103105</td>\n",
       "      <td>-1.101218</td>\n",
       "      <td>-1.097466</td>\n",
       "      <td>-1.100597</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.425400</td>\n",
       "      <td>0.839625</td>\n",
       "      <td>0.168940</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100949</td>\n",
       "      <td>-1.102869</td>\n",
       "      <td>-1.100631</td>\n",
       "      <td>-1.097338</td>\n",
       "      <td>-1.100447</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.162161</td>\n",
       "      <td>0.290983</td>\n",
       "      <td>0.161193</td>\n",
       "      <td>0.019040</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100283</td>\n",
       "      <td>-1.103248</td>\n",
       "      <td>-1.100843</td>\n",
       "      <td>-1.097364</td>\n",
       "      <td>-1.100435</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.409952</td>\n",
       "      <td>0.193932</td>\n",
       "      <td>0.181940</td>\n",
       "      <td>0.018675</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100712</td>\n",
       "      <td>-1.103026</td>\n",
       "      <td>-1.101160</td>\n",
       "      <td>-1.097128</td>\n",
       "      <td>-1.100507</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.609166</td>\n",
       "      <td>0.730352</td>\n",
       "      <td>0.182940</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100169</td>\n",
       "      <td>-1.102854</td>\n",
       "      <td>-1.100973</td>\n",
       "      <td>-1.097084</td>\n",
       "      <td>-1.100270</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.140170</td>\n",
       "      <td>0.395914</td>\n",
       "      <td>0.150697</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100139</td>\n",
       "      <td>-1.103270</td>\n",
       "      <td>-1.101001</td>\n",
       "      <td>-1.097207</td>\n",
       "      <td>-1.100404</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.154323</td>\n",
       "      <td>0.199582</td>\n",
       "      <td>0.171684</td>\n",
       "      <td>0.021275</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100635</td>\n",
       "      <td>-1.102983</td>\n",
       "      <td>-1.101306</td>\n",
       "      <td>-1.097323</td>\n",
       "      <td>-1.100562</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.416835</td>\n",
       "      <td>0.251990</td>\n",
       "      <td>0.159448</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100570</td>\n",
       "      <td>-1.102593</td>\n",
       "      <td>-1.100744</td>\n",
       "      <td>-1.097055</td>\n",
       "      <td>-1.100241</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.741201</td>\n",
       "      <td>0.199662</td>\n",
       "      <td>0.155694</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100536</td>\n",
       "      <td>-1.102621</td>\n",
       "      <td>-1.100570</td>\n",
       "      <td>-1.097072</td>\n",
       "      <td>-1.100200</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.192915</td>\n",
       "      <td>0.642988</td>\n",
       "      <td>0.157698</td>\n",
       "      <td>0.008434</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100286</td>\n",
       "      <td>-1.102923</td>\n",
       "      <td>-1.100902</td>\n",
       "      <td>-1.096668</td>\n",
       "      <td>-1.100195</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.328247</td>\n",
       "      <td>0.532829</td>\n",
       "      <td>0.159688</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100387</td>\n",
       "      <td>-1.102804</td>\n",
       "      <td>-1.100473</td>\n",
       "      <td>-1.097048</td>\n",
       "      <td>-1.100178</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.570645</td>\n",
       "      <td>0.112220</td>\n",
       "      <td>0.149951</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100406</td>\n",
       "      <td>-1.103181</td>\n",
       "      <td>-1.100896</td>\n",
       "      <td>-1.097459</td>\n",
       "      <td>-1.100485</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.732449</td>\n",
       "      <td>0.170201</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.099997</td>\n",
       "      <td>-1.102512</td>\n",
       "      <td>-1.100612</td>\n",
       "      <td>-1.097426</td>\n",
       "      <td>-1.100137</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.620709</td>\n",
       "      <td>0.111403</td>\n",
       "      <td>0.150201</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100229</td>\n",
       "      <td>-1.102512</td>\n",
       "      <td>-1.100555</td>\n",
       "      <td>-1.097559</td>\n",
       "      <td>-1.100214</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.812725</td>\n",
       "      <td>0.243086</td>\n",
       "      <td>0.159448</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.099950</td>\n",
       "      <td>-1.102429</td>\n",
       "      <td>-1.100305</td>\n",
       "      <td>-1.096687</td>\n",
       "      <td>-1.099843</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.709836</td>\n",
       "      <td>0.130386</td>\n",
       "      <td>0.149943</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100115</td>\n",
       "      <td>-1.102593</td>\n",
       "      <td>-1.100508</td>\n",
       "      <td>-1.097227</td>\n",
       "      <td>-1.100111</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.787686</td>\n",
       "      <td>0.252070</td>\n",
       "      <td>0.164192</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100473</td>\n",
       "      <td>-1.102581</td>\n",
       "      <td>-1.100502</td>\n",
       "      <td>-1.097213</td>\n",
       "      <td>-1.100192</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.788183</td>\n",
       "      <td>0.083450</td>\n",
       "      <td>0.156944</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100591</td>\n",
       "      <td>-1.103341</td>\n",
       "      <td>-1.101091</td>\n",
       "      <td>-1.097465</td>\n",
       "      <td>-1.100622</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.837272</td>\n",
       "      <td>0.162318</td>\n",
       "      <td>0.162192</td>\n",
       "      <td>0.015005</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100601</td>\n",
       "      <td>-1.102468</td>\n",
       "      <td>-1.100065</td>\n",
       "      <td>-1.097035</td>\n",
       "      <td>-1.100042</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.958449</td>\n",
       "      <td>0.146230</td>\n",
       "      <td>0.165696</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100451</td>\n",
       "      <td>-1.102561</td>\n",
       "      <td>-1.100134</td>\n",
       "      <td>-1.097117</td>\n",
       "      <td>-1.100066</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.917054</td>\n",
       "      <td>0.338849</td>\n",
       "      <td>0.167940</td>\n",
       "      <td>0.023565</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100558</td>\n",
       "      <td>-1.102510</td>\n",
       "      <td>-1.100198</td>\n",
       "      <td>-1.097230</td>\n",
       "      <td>-1.100124</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.406735</td>\n",
       "      <td>0.389466</td>\n",
       "      <td>0.166941</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100545</td>\n",
       "      <td>-1.102628</td>\n",
       "      <td>-1.100542</td>\n",
       "      <td>-1.097427</td>\n",
       "      <td>-1.100286</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.730131</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.151201</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100355</td>\n",
       "      <td>-1.102984</td>\n",
       "      <td>-1.100460</td>\n",
       "      <td>-1.097515</td>\n",
       "      <td>-1.100328</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.844791</td>\n",
       "      <td>0.176271</td>\n",
       "      <td>0.149193</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100864</td>\n",
       "      <td>-1.102873</td>\n",
       "      <td>-1.100695</td>\n",
       "      <td>-1.098012</td>\n",
       "      <td>-1.100611</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11.960152</td>\n",
       "      <td>0.146721</td>\n",
       "      <td>0.153950</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.103118</td>\n",
       "      <td>-1.105692</td>\n",
       "      <td>-1.103646</td>\n",
       "      <td>-1.100733</td>\n",
       "      <td>-1.103297</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.143465</td>\n",
       "      <td>0.586556</td>\n",
       "      <td>0.153441</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.103384</td>\n",
       "      <td>-1.106050</td>\n",
       "      <td>-1.103548</td>\n",
       "      <td>-1.100763</td>\n",
       "      <td>-1.103436</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.774412</td>\n",
       "      <td>0.130398</td>\n",
       "      <td>0.164937</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.103475</td>\n",
       "      <td>-1.105967</td>\n",
       "      <td>-1.103388</td>\n",
       "      <td>-1.100769</td>\n",
       "      <td>-1.103400</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.774330</td>\n",
       "      <td>0.155662</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.103377</td>\n",
       "      <td>-1.106106</td>\n",
       "      <td>-1.103667</td>\n",
       "      <td>-1.100719</td>\n",
       "      <td>-1.103467</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.802606</td>\n",
       "      <td>0.138849</td>\n",
       "      <td>0.161697</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.103474</td>\n",
       "      <td>-1.106086</td>\n",
       "      <td>-1.103640</td>\n",
       "      <td>-1.100855</td>\n",
       "      <td>-1.103514</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.802035</td>\n",
       "      <td>0.121022</td>\n",
       "      <td>0.159689</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.103852</td>\n",
       "      <td>-1.106840</td>\n",
       "      <td>-1.104167</td>\n",
       "      <td>-1.101409</td>\n",
       "      <td>-1.104067</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       13.291557      0.580178         0.160944        0.003670   \n",
       "1       13.425400      0.839625         0.168940        0.016545   \n",
       "2       12.162161      0.290983         0.161193        0.019040   \n",
       "3       12.409952      0.193932         0.181940        0.018675   \n",
       "4       12.609166      0.730352         0.182940        0.023100   \n",
       "5       12.140170      0.395914         0.150697        0.003112   \n",
       "6       12.154323      0.199582         0.171684        0.021275   \n",
       "7       12.416835      0.251990         0.159448        0.010159   \n",
       "8       11.741201      0.199662         0.155694        0.006836   \n",
       "9       12.192915      0.642988         0.157698        0.008434   \n",
       "10      12.328247      0.532829         0.159688        0.004716   \n",
       "11      11.570645      0.112220         0.149951        0.001414   \n",
       "12      11.732449      0.170201         0.150700        0.002046   \n",
       "13      11.620709      0.111403         0.150201        0.001920   \n",
       "14      11.812725      0.243086         0.159448        0.009066   \n",
       "15      11.709836      0.130386         0.149943        0.002920   \n",
       "16      11.787686      0.252070         0.164192        0.020761   \n",
       "17      11.788183      0.083450         0.156944        0.012175   \n",
       "18      11.837272      0.162318         0.162192        0.015005   \n",
       "19      11.958449      0.146230         0.165696        0.011341   \n",
       "20      11.917054      0.338849         0.167940        0.023565   \n",
       "21      12.406735      0.389466         0.166941        0.018772   \n",
       "22      11.730131      0.158691         0.151201        0.002277   \n",
       "23      11.844791      0.176271         0.149193        0.001478   \n",
       "24      11.960152      0.146721         0.153950        0.003534   \n",
       "25      12.143465      0.586556         0.153441        0.006645   \n",
       "26      12.774412      0.130398         0.164937        0.001420   \n",
       "27      12.774330      0.155662         0.161947        0.005611   \n",
       "28      12.802606      0.138849         0.161697        0.005213   \n",
       "29      12.802035      0.121022         0.159689        0.004609   \n",
       "\n",
       "   param_classifier__booster param_classifier__colsample_bytree  \\\n",
       "0                     gbtree                               0.55   \n",
       "1                     gbtree                               0.55   \n",
       "2                     gbtree                               0.55   \n",
       "3                     gbtree                               0.55   \n",
       "4                     gbtree                               0.55   \n",
       "5                     gbtree                               0.55   \n",
       "6                     gbtree                               0.55   \n",
       "7                     gbtree                               0.55   \n",
       "8                     gbtree                               0.55   \n",
       "9                     gbtree                               0.55   \n",
       "10                    gbtree                               0.55   \n",
       "11                    gbtree                               0.55   \n",
       "12                    gbtree                               0.55   \n",
       "13                    gbtree                               0.55   \n",
       "14                    gbtree                               0.55   \n",
       "15                    gbtree                               0.55   \n",
       "16                    gbtree                               0.55   \n",
       "17                    gbtree                               0.55   \n",
       "18                    gbtree                               0.55   \n",
       "19                    gbtree                               0.55   \n",
       "20                    gbtree                               0.55   \n",
       "21                    gbtree                               0.55   \n",
       "22                    gbtree                               0.55   \n",
       "23                    gbtree                               0.55   \n",
       "24                    gbtree                               0.55   \n",
       "25                    gbtree                               0.55   \n",
       "26                    gbtree                               0.55   \n",
       "27                    gbtree                               0.55   \n",
       "28                    gbtree                               0.55   \n",
       "29                    gbtree                               0.55   \n",
       "\n",
       "   param_classifier__eval_metric param_classifier__gamma  \\\n",
       "0                       mlogloss                       0   \n",
       "1                       mlogloss                       0   \n",
       "2                       mlogloss                       0   \n",
       "3                       mlogloss                       0   \n",
       "4                       mlogloss                       0   \n",
       "5                       mlogloss                       0   \n",
       "6                       mlogloss                       0   \n",
       "7                       mlogloss                       0   \n",
       "8                       mlogloss                       0   \n",
       "9                       mlogloss                       0   \n",
       "10                      mlogloss                       0   \n",
       "11                      mlogloss                       0   \n",
       "12                      mlogloss                       0   \n",
       "13                      mlogloss                       0   \n",
       "14                      mlogloss                       0   \n",
       "15                      mlogloss                       0   \n",
       "16                      mlogloss                       0   \n",
       "17                      mlogloss                       0   \n",
       "18                      mlogloss                       0   \n",
       "19                      mlogloss                       0   \n",
       "20                      mlogloss                       0   \n",
       "21                      mlogloss                       0   \n",
       "22                      mlogloss                       0   \n",
       "23                      mlogloss                       0   \n",
       "24                      mlogloss                       0   \n",
       "25                      mlogloss                       0   \n",
       "26                      mlogloss                       0   \n",
       "27                      mlogloss                       0   \n",
       "28                      mlogloss                       0   \n",
       "29                      mlogloss                       0   \n",
       "\n",
       "   param_classifier__learning_rate param_classifier__max_depth  \\\n",
       "0                              0.1                           4   \n",
       "1                              0.1                           4   \n",
       "2                              0.1                           4   \n",
       "3                              0.1                           4   \n",
       "4                              0.1                           4   \n",
       "5                              0.1                           4   \n",
       "6                              0.1                           4   \n",
       "7                              0.1                           4   \n",
       "8                              0.1                           4   \n",
       "9                              0.1                           4   \n",
       "10                             0.1                           4   \n",
       "11                             0.1                           4   \n",
       "12                             0.1                           4   \n",
       "13                             0.1                           4   \n",
       "14                             0.1                           4   \n",
       "15                             0.1                           4   \n",
       "16                             0.1                           4   \n",
       "17                             0.1                           4   \n",
       "18                             0.1                           4   \n",
       "19                             0.1                           4   \n",
       "20                             0.1                           4   \n",
       "21                             0.1                           4   \n",
       "22                             0.1                           4   \n",
       "23                             0.1                           4   \n",
       "24                             0.1                           4   \n",
       "25                             0.1                           4   \n",
       "26                             0.1                           4   \n",
       "27                             0.1                           4   \n",
       "28                             0.1                           4   \n",
       "29                             0.1                           4   \n",
       "\n",
       "   param_classifier__min_child_weight param_classifier__n_estimators  \\\n",
       "0                                   2                            250   \n",
       "1                                   2                            250   \n",
       "2                                   2                            250   \n",
       "3                                   2                            250   \n",
       "4                                   2                            250   \n",
       "5                                   2                            250   \n",
       "6                                   2                            250   \n",
       "7                                   2                            250   \n",
       "8                                   2                            250   \n",
       "9                                   2                            250   \n",
       "10                                  2                            250   \n",
       "11                                  2                            250   \n",
       "12                                  2                            250   \n",
       "13                                  2                            250   \n",
       "14                                  2                            250   \n",
       "15                                  2                            250   \n",
       "16                                  2                            250   \n",
       "17                                  2                            250   \n",
       "18                                  2                            250   \n",
       "19                                  2                            250   \n",
       "20                                  2                            250   \n",
       "21                                  2                            250   \n",
       "22                                  2                            250   \n",
       "23                                  2                            250   \n",
       "24                                  2                            250   \n",
       "25                                  2                            250   \n",
       "26                                  2                            250   \n",
       "27                                  2                            250   \n",
       "28                                  2                            250   \n",
       "29                                  2                            250   \n",
       "\n",
       "   param_classifier__objective param_classifier__random_state  \\\n",
       "0               multi:softprob                             42   \n",
       "1               multi:softprob                             42   \n",
       "2               multi:softprob                             42   \n",
       "3               multi:softprob                             42   \n",
       "4               multi:softprob                             42   \n",
       "5               multi:softprob                             42   \n",
       "6               multi:softprob                             42   \n",
       "7               multi:softprob                             42   \n",
       "8               multi:softprob                             42   \n",
       "9               multi:softprob                             42   \n",
       "10              multi:softprob                             42   \n",
       "11              multi:softprob                             42   \n",
       "12              multi:softprob                             42   \n",
       "13              multi:softprob                             42   \n",
       "14              multi:softprob                             42   \n",
       "15              multi:softprob                             42   \n",
       "16              multi:softprob                             42   \n",
       "17              multi:softprob                             42   \n",
       "18              multi:softprob                             42   \n",
       "19              multi:softprob                             42   \n",
       "20              multi:softprob                             42   \n",
       "21              multi:softprob                             42   \n",
       "22              multi:softprob                             42   \n",
       "23              multi:softprob                             42   \n",
       "24              multi:softprob                             42   \n",
       "25              multi:softprob                             42   \n",
       "26              multi:softprob                             42   \n",
       "27              multi:softprob                             42   \n",
       "28              multi:softprob                             42   \n",
       "29              multi:softprob                             42   \n",
       "\n",
       "   param_classifier__reg_alpha param_classifier__reg_lambda  \\\n",
       "0                            8                            5   \n",
       "1                            8                            8   \n",
       "2                            8                           10   \n",
       "3                            8                           15   \n",
       "4                            8                           30   \n",
       "5                            8                          100   \n",
       "6                           10                            5   \n",
       "7                           10                            8   \n",
       "8                           10                           10   \n",
       "9                           10                           15   \n",
       "10                          10                           30   \n",
       "11                          10                          100   \n",
       "12                          15                            5   \n",
       "13                          15                            8   \n",
       "14                          15                           10   \n",
       "15                          15                           15   \n",
       "16                          15                           30   \n",
       "17                          15                          100   \n",
       "18                          30                            5   \n",
       "19                          30                            8   \n",
       "20                          30                           10   \n",
       "21                          30                           15   \n",
       "22                          30                           30   \n",
       "23                          30                          100   \n",
       "24                         100                            5   \n",
       "25                         100                            8   \n",
       "26                         100                           10   \n",
       "27                         100                           15   \n",
       "28                         100                           30   \n",
       "29                         100                          100   \n",
       "\n",
       "   param_classifier__subsample param_classifier__tree_method  \\\n",
       "0                         0.75                      gpu_hist   \n",
       "1                         0.75                      gpu_hist   \n",
       "2                         0.75                      gpu_hist   \n",
       "3                         0.75                      gpu_hist   \n",
       "4                         0.75                      gpu_hist   \n",
       "5                         0.75                      gpu_hist   \n",
       "6                         0.75                      gpu_hist   \n",
       "7                         0.75                      gpu_hist   \n",
       "8                         0.75                      gpu_hist   \n",
       "9                         0.75                      gpu_hist   \n",
       "10                        0.75                      gpu_hist   \n",
       "11                        0.75                      gpu_hist   \n",
       "12                        0.75                      gpu_hist   \n",
       "13                        0.75                      gpu_hist   \n",
       "14                        0.75                      gpu_hist   \n",
       "15                        0.75                      gpu_hist   \n",
       "16                        0.75                      gpu_hist   \n",
       "17                        0.75                      gpu_hist   \n",
       "18                        0.75                      gpu_hist   \n",
       "19                        0.75                      gpu_hist   \n",
       "20                        0.75                      gpu_hist   \n",
       "21                        0.75                      gpu_hist   \n",
       "22                        0.75                      gpu_hist   \n",
       "23                        0.75                      gpu_hist   \n",
       "24                        0.75                      gpu_hist   \n",
       "25                        0.75                      gpu_hist   \n",
       "26                        0.75                      gpu_hist   \n",
       "27                        0.75                      gpu_hist   \n",
       "28                        0.75                      gpu_hist   \n",
       "29                        0.75                      gpu_hist   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classifier__booster': 'gbtree', 'classifier_...          -1.100599   \n",
       "1   {'classifier__booster': 'gbtree', 'classifier_...          -1.100949   \n",
       "2   {'classifier__booster': 'gbtree', 'classifier_...          -1.100283   \n",
       "3   {'classifier__booster': 'gbtree', 'classifier_...          -1.100712   \n",
       "4   {'classifier__booster': 'gbtree', 'classifier_...          -1.100169   \n",
       "5   {'classifier__booster': 'gbtree', 'classifier_...          -1.100139   \n",
       "6   {'classifier__booster': 'gbtree', 'classifier_...          -1.100635   \n",
       "7   {'classifier__booster': 'gbtree', 'classifier_...          -1.100570   \n",
       "8   {'classifier__booster': 'gbtree', 'classifier_...          -1.100536   \n",
       "9   {'classifier__booster': 'gbtree', 'classifier_...          -1.100286   \n",
       "10  {'classifier__booster': 'gbtree', 'classifier_...          -1.100387   \n",
       "11  {'classifier__booster': 'gbtree', 'classifier_...          -1.100406   \n",
       "12  {'classifier__booster': 'gbtree', 'classifier_...          -1.099997   \n",
       "13  {'classifier__booster': 'gbtree', 'classifier_...          -1.100229   \n",
       "14  {'classifier__booster': 'gbtree', 'classifier_...          -1.099950   \n",
       "15  {'classifier__booster': 'gbtree', 'classifier_...          -1.100115   \n",
       "16  {'classifier__booster': 'gbtree', 'classifier_...          -1.100473   \n",
       "17  {'classifier__booster': 'gbtree', 'classifier_...          -1.100591   \n",
       "18  {'classifier__booster': 'gbtree', 'classifier_...          -1.100601   \n",
       "19  {'classifier__booster': 'gbtree', 'classifier_...          -1.100451   \n",
       "20  {'classifier__booster': 'gbtree', 'classifier_...          -1.100558   \n",
       "21  {'classifier__booster': 'gbtree', 'classifier_...          -1.100545   \n",
       "22  {'classifier__booster': 'gbtree', 'classifier_...          -1.100355   \n",
       "23  {'classifier__booster': 'gbtree', 'classifier_...          -1.100864   \n",
       "24  {'classifier__booster': 'gbtree', 'classifier_...          -1.103118   \n",
       "25  {'classifier__booster': 'gbtree', 'classifier_...          -1.103384   \n",
       "26  {'classifier__booster': 'gbtree', 'classifier_...          -1.103475   \n",
       "27  {'classifier__booster': 'gbtree', 'classifier_...          -1.103377   \n",
       "28  {'classifier__booster': 'gbtree', 'classifier_...          -1.103474   \n",
       "29  {'classifier__booster': 'gbtree', 'classifier_...          -1.103852   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0           -1.103105          -1.101218          -1.097466        -1.100597   \n",
       "1           -1.102869          -1.100631          -1.097338        -1.100447   \n",
       "2           -1.103248          -1.100843          -1.097364        -1.100435   \n",
       "3           -1.103026          -1.101160          -1.097128        -1.100507   \n",
       "4           -1.102854          -1.100973          -1.097084        -1.100270   \n",
       "5           -1.103270          -1.101001          -1.097207        -1.100404   \n",
       "6           -1.102983          -1.101306          -1.097323        -1.100562   \n",
       "7           -1.102593          -1.100744          -1.097055        -1.100241   \n",
       "8           -1.102621          -1.100570          -1.097072        -1.100200   \n",
       "9           -1.102923          -1.100902          -1.096668        -1.100195   \n",
       "10          -1.102804          -1.100473          -1.097048        -1.100178   \n",
       "11          -1.103181          -1.100896          -1.097459        -1.100485   \n",
       "12          -1.102512          -1.100612          -1.097426        -1.100137   \n",
       "13          -1.102512          -1.100555          -1.097559        -1.100214   \n",
       "14          -1.102429          -1.100305          -1.096687        -1.099843   \n",
       "15          -1.102593          -1.100508          -1.097227        -1.100111   \n",
       "16          -1.102581          -1.100502          -1.097213        -1.100192   \n",
       "17          -1.103341          -1.101091          -1.097465        -1.100622   \n",
       "18          -1.102468          -1.100065          -1.097035        -1.100042   \n",
       "19          -1.102561          -1.100134          -1.097117        -1.100066   \n",
       "20          -1.102510          -1.100198          -1.097230        -1.100124   \n",
       "21          -1.102628          -1.100542          -1.097427        -1.100286   \n",
       "22          -1.102984          -1.100460          -1.097515        -1.100328   \n",
       "23          -1.102873          -1.100695          -1.098012        -1.100611   \n",
       "24          -1.105692          -1.103646          -1.100733        -1.103297   \n",
       "25          -1.106050          -1.103548          -1.100763        -1.103436   \n",
       "26          -1.105967          -1.103388          -1.100769        -1.103400   \n",
       "27          -1.106106          -1.103667          -1.100719        -1.103467   \n",
       "28          -1.106086          -1.103640          -1.100855        -1.103514   \n",
       "29          -1.106840          -1.104167          -1.101409        -1.104067   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.002030               22  \n",
       "1         0.001989               18  \n",
       "2         0.002094               17  \n",
       "3         0.002135               20  \n",
       "4         0.002082               13  \n",
       "5         0.002171               16  \n",
       "6         0.002056               21  \n",
       "7         0.002003               12  \n",
       "8         0.001993               10  \n",
       "9         0.002258                9  \n",
       "10        0.002051                7  \n",
       "11        0.002037               19  \n",
       "12        0.001819                6  \n",
       "13        0.001764               11  \n",
       "14        0.002054                1  \n",
       "15        0.001913                4  \n",
       "16        0.001921                8  \n",
       "17        0.002097               24  \n",
       "18        0.001952                2  \n",
       "19        0.001941                3  \n",
       "20        0.001889                5  \n",
       "21        0.001857               14  \n",
       "22        0.001936               15  \n",
       "23        0.001728               23  \n",
       "24        0.001765               25  \n",
       "25        0.001870               27  \n",
       "26        0.001838               26  \n",
       "27        0.001908               28  \n",
       "28        0.001851               29  \n",
       "29        0.001924               30  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid7.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efc7e6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'classifier__booster': 'gbtree', 'classifier__colsample_bytree': 0.55, 'classifier__eval_metric': 'mlogloss', 'classifier__gamma': 0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 250, 'classifier__objective': 'multi:softprob', 'classifier__random_state': 42, 'classifier__reg_alpha': 15, 'classifier__reg_lambda': 10, 'classifier__subsample': 0.75, 'classifier__tree_method': 'gpu_hist'}\n",
      "Best score (Train SMOTE): -1.0998426176375151\n",
      "Test score (Test SMOTE): -1.097658251903653\n",
      "Train logloss (Train): 1.0749073590741556\n",
      "Test logloss (Test): 1.097658251903653\n"
     ]
    }
   ],
   "source": [
    "#checking around alpha=15 and lambda=10\n",
    "param_grid8={\"classifier__learning_rate\":[0.1],\n",
    "             \"classifier__n_estimators\":[250],\n",
    "             \"classifier__max_depth\":[4],\n",
    "             \"classifier__min_child_weight\":[2],\n",
    "             \"classifier__gamma\":[0],\n",
    "             \"classifier__subsample\":[0.75],\n",
    "             \"classifier__colsample_bytree\":[0.55],\n",
    "             \"classifier__reg_alpha\":[14,15,16],\n",
    "             \"classifier__reg_lambda\":[9,10,11],\n",
    "             \"classifier__objective\":[\"multi:softprob\"],\n",
    "             \"classifier__random_state\":[42],\n",
    "             \"classifier__tree_method\":[\"gpu_hist\"],\n",
    "             \"classifier__booster\":[\"gbtree\"],\n",
    "             \"classifier__eval_metric\":[\"mlogloss\"]}\n",
    "grid8=pipe_smote_gridsearchcv(pipe,param_grid8,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bca82d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__booster</th>\n",
       "      <th>param_classifier__colsample_bytree</th>\n",
       "      <th>param_classifier__eval_metric</th>\n",
       "      <th>param_classifier__gamma</th>\n",
       "      <th>param_classifier__learning_rate</th>\n",
       "      <th>param_classifier__max_depth</th>\n",
       "      <th>param_classifier__min_child_weight</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_classifier__objective</th>\n",
       "      <th>param_classifier__random_state</th>\n",
       "      <th>param_classifier__reg_alpha</th>\n",
       "      <th>param_classifier__reg_lambda</th>\n",
       "      <th>param_classifier__subsample</th>\n",
       "      <th>param_classifier__tree_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.104482</td>\n",
       "      <td>0.398877</td>\n",
       "      <td>0.166446</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100136</td>\n",
       "      <td>-1.102875</td>\n",
       "      <td>-1.100640</td>\n",
       "      <td>-1.096911</td>\n",
       "      <td>-1.100140</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.777205</td>\n",
       "      <td>0.153189</td>\n",
       "      <td>0.160692</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.099936</td>\n",
       "      <td>-1.102618</td>\n",
       "      <td>-1.100687</td>\n",
       "      <td>-1.097008</td>\n",
       "      <td>-1.100062</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.645105</td>\n",
       "      <td>0.131761</td>\n",
       "      <td>0.160948</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100061</td>\n",
       "      <td>-1.102513</td>\n",
       "      <td>-1.100970</td>\n",
       "      <td>-1.096772</td>\n",
       "      <td>-1.100079</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.160818</td>\n",
       "      <td>0.430285</td>\n",
       "      <td>0.157444</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100478</td>\n",
       "      <td>-1.102664</td>\n",
       "      <td>-1.100252</td>\n",
       "      <td>-1.097154</td>\n",
       "      <td>-1.100137</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.600712</td>\n",
       "      <td>0.601025</td>\n",
       "      <td>0.164945</td>\n",
       "      <td>0.009483</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.099950</td>\n",
       "      <td>-1.102429</td>\n",
       "      <td>-1.100305</td>\n",
       "      <td>-1.096687</td>\n",
       "      <td>-1.099843</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.795393</td>\n",
       "      <td>0.221361</td>\n",
       "      <td>0.173194</td>\n",
       "      <td>0.016063</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100433</td>\n",
       "      <td>-1.102539</td>\n",
       "      <td>-1.100402</td>\n",
       "      <td>-1.097216</td>\n",
       "      <td>-1.100147</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.662563</td>\n",
       "      <td>0.109788</td>\n",
       "      <td>0.160447</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100013</td>\n",
       "      <td>-1.102743</td>\n",
       "      <td>-1.100678</td>\n",
       "      <td>-1.096686</td>\n",
       "      <td>-1.100030</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.627249</td>\n",
       "      <td>0.149661</td>\n",
       "      <td>0.164446</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100184</td>\n",
       "      <td>-1.102704</td>\n",
       "      <td>-1.100870</td>\n",
       "      <td>-1.096915</td>\n",
       "      <td>-1.100168</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.286860</td>\n",
       "      <td>0.358506</td>\n",
       "      <td>0.156944</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.55</td>\n",
       "      <td>mlogloss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>multi:softprob</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>0.75</td>\n",
       "      <td>gpu_hist</td>\n",
       "      <td>{'classifier__booster': 'gbtree', 'classifier_...</td>\n",
       "      <td>-1.100333</td>\n",
       "      <td>-1.102844</td>\n",
       "      <td>-1.100844</td>\n",
       "      <td>-1.097173</td>\n",
       "      <td>-1.100298</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      13.104482      0.398877         0.166446        0.007431   \n",
       "1      12.777205      0.153189         0.160692        0.005353   \n",
       "2      12.645105      0.131761         0.160948        0.007139   \n",
       "3      12.160818      0.430285         0.157444        0.007433   \n",
       "4      12.600712      0.601025         0.164945        0.009483   \n",
       "5      12.795393      0.221361         0.173194        0.016063   \n",
       "6      12.662563      0.109788         0.160447        0.006575   \n",
       "7      12.627249      0.149661         0.164446        0.004270   \n",
       "8      12.286860      0.358506         0.156944        0.006166   \n",
       "\n",
       "  param_classifier__booster param_classifier__colsample_bytree  \\\n",
       "0                    gbtree                               0.55   \n",
       "1                    gbtree                               0.55   \n",
       "2                    gbtree                               0.55   \n",
       "3                    gbtree                               0.55   \n",
       "4                    gbtree                               0.55   \n",
       "5                    gbtree                               0.55   \n",
       "6                    gbtree                               0.55   \n",
       "7                    gbtree                               0.55   \n",
       "8                    gbtree                               0.55   \n",
       "\n",
       "  param_classifier__eval_metric param_classifier__gamma  \\\n",
       "0                      mlogloss                       0   \n",
       "1                      mlogloss                       0   \n",
       "2                      mlogloss                       0   \n",
       "3                      mlogloss                       0   \n",
       "4                      mlogloss                       0   \n",
       "5                      mlogloss                       0   \n",
       "6                      mlogloss                       0   \n",
       "7                      mlogloss                       0   \n",
       "8                      mlogloss                       0   \n",
       "\n",
       "  param_classifier__learning_rate param_classifier__max_depth  \\\n",
       "0                             0.1                           4   \n",
       "1                             0.1                           4   \n",
       "2                             0.1                           4   \n",
       "3                             0.1                           4   \n",
       "4                             0.1                           4   \n",
       "5                             0.1                           4   \n",
       "6                             0.1                           4   \n",
       "7                             0.1                           4   \n",
       "8                             0.1                           4   \n",
       "\n",
       "  param_classifier__min_child_weight param_classifier__n_estimators  \\\n",
       "0                                  2                            250   \n",
       "1                                  2                            250   \n",
       "2                                  2                            250   \n",
       "3                                  2                            250   \n",
       "4                                  2                            250   \n",
       "5                                  2                            250   \n",
       "6                                  2                            250   \n",
       "7                                  2                            250   \n",
       "8                                  2                            250   \n",
       "\n",
       "  param_classifier__objective param_classifier__random_state  \\\n",
       "0              multi:softprob                             42   \n",
       "1              multi:softprob                             42   \n",
       "2              multi:softprob                             42   \n",
       "3              multi:softprob                             42   \n",
       "4              multi:softprob                             42   \n",
       "5              multi:softprob                             42   \n",
       "6              multi:softprob                             42   \n",
       "7              multi:softprob                             42   \n",
       "8              multi:softprob                             42   \n",
       "\n",
       "  param_classifier__reg_alpha param_classifier__reg_lambda  \\\n",
       "0                          14                            9   \n",
       "1                          14                           10   \n",
       "2                          14                           11   \n",
       "3                          15                            9   \n",
       "4                          15                           10   \n",
       "5                          15                           11   \n",
       "6                          16                            9   \n",
       "7                          16                           10   \n",
       "8                          16                           11   \n",
       "\n",
       "  param_classifier__subsample param_classifier__tree_method  \\\n",
       "0                        0.75                      gpu_hist   \n",
       "1                        0.75                      gpu_hist   \n",
       "2                        0.75                      gpu_hist   \n",
       "3                        0.75                      gpu_hist   \n",
       "4                        0.75                      gpu_hist   \n",
       "5                        0.75                      gpu_hist   \n",
       "6                        0.75                      gpu_hist   \n",
       "7                        0.75                      gpu_hist   \n",
       "8                        0.75                      gpu_hist   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'classifier__booster': 'gbtree', 'classifier_...          -1.100136   \n",
       "1  {'classifier__booster': 'gbtree', 'classifier_...          -1.099936   \n",
       "2  {'classifier__booster': 'gbtree', 'classifier_...          -1.100061   \n",
       "3  {'classifier__booster': 'gbtree', 'classifier_...          -1.100478   \n",
       "4  {'classifier__booster': 'gbtree', 'classifier_...          -1.099950   \n",
       "5  {'classifier__booster': 'gbtree', 'classifier_...          -1.100433   \n",
       "6  {'classifier__booster': 'gbtree', 'classifier_...          -1.100013   \n",
       "7  {'classifier__booster': 'gbtree', 'classifier_...          -1.100184   \n",
       "8  {'classifier__booster': 'gbtree', 'classifier_...          -1.100333   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0          -1.102875          -1.100640          -1.096911        -1.100140   \n",
       "1          -1.102618          -1.100687          -1.097008        -1.100062   \n",
       "2          -1.102513          -1.100970          -1.096772        -1.100079   \n",
       "3          -1.102664          -1.100252          -1.097154        -1.100137   \n",
       "4          -1.102429          -1.100305          -1.096687        -1.099843   \n",
       "5          -1.102539          -1.100402          -1.097216        -1.100147   \n",
       "6          -1.102743          -1.100678          -1.096686        -1.100030   \n",
       "7          -1.102704          -1.100870          -1.096915        -1.100168   \n",
       "8          -1.102844          -1.100844          -1.097173        -1.100298   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.002131                6  \n",
       "1        0.002017                3  \n",
       "2        0.002101                4  \n",
       "3        0.001963                5  \n",
       "4        0.002054                1  \n",
       "5        0.001901                7  \n",
       "6        0.002177                2  \n",
       "7        0.002092                8  \n",
       "8        0.002034                9  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid8.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63acb9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "New n_estimators: 5000\n",
      "log loss (Train): 1.001395\n",
      "log loss (Train SMOTE): 0.903774\n",
      "log loss (Test): 1.106756\n",
      "log loss (Test SMOTE): 1.091902\n"
     ]
    }
   ],
   "source": [
    "#best alpha=15 and lambda=10\n",
    "#decreasing learning rate and increasing boosting rounds\n",
    "ordenc=OrdinalEncoder().fit(y_train)\n",
    "y_train_ord=ordenc.transform(y_train)\n",
    "y_test_ord=ordenc.transform(y_test)\n",
    "predictors=newdf_train.columns[:-1]\n",
    "xgb2=XGBClassifier(learning_rate=0.03, n_estimators=5000, max_depth=4,\n",
    "                  min_child_weight=2, gamma=0, subsample=0.75, colsample_bytree=0.55,\n",
    "                  reg_alpha=15,reg_lambda=10,\n",
    "                  objective=\"multi:softprob\", random_state=42,tree_method=\"gpu_hist\",booster=\"gbtree\")\n",
    "cvresult_2=modelfit(xgb2, X_train, y_train_ord, X_test, y_test_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28329e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.983853</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>3.984070</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.768595</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>3.769022</td>\n",
       "      <td>0.001683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.593656</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>3.594413</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.448994</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>3.449871</td>\n",
       "      <td>0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.323844</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>3.324790</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.901331</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.975252</td>\n",
       "      <td>0.002187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.901307</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.975237</td>\n",
       "      <td>0.002185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.901284</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.975225</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.901263</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.975213</td>\n",
       "      <td>0.002183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.901240</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.975202</td>\n",
       "      <td>0.002182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      train-mlogloss-mean  train-mlogloss-std  test-mlogloss-mean  \\\n",
       "0                3.983853            0.000231            3.984070   \n",
       "1                3.768595            0.001353            3.769022   \n",
       "2                3.593656            0.000864            3.594413   \n",
       "3                3.448994            0.000803            3.449871   \n",
       "4                3.323844            0.001350            3.324790   \n",
       "...                   ...                 ...                 ...   \n",
       "4995             0.901331            0.000502            0.975252   \n",
       "4996             0.901307            0.000503            0.975237   \n",
       "4997             0.901284            0.000503            0.975225   \n",
       "4998             0.901263            0.000504            0.975213   \n",
       "4999             0.901240            0.000504            0.975202   \n",
       "\n",
       "      test-mlogloss-std  \n",
       "0              0.000345  \n",
       "1              0.001683  \n",
       "2              0.000682  \n",
       "3              0.000761  \n",
       "4              0.000298  \n",
       "...                 ...  \n",
       "4995           0.002187  \n",
       "4996           0.002185  \n",
       "4997           0.002184  \n",
       "4998           0.002183  \n",
       "4999           0.002182  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresult_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b5376c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'logloss')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(range(len(cvresult_2[\"train-mlogloss-mean\"])),cvresult_2[\"train-mlogloss-mean\"].values,\n",
    "        label=\"Train\")\n",
    "plt.plot(range(len(cvresult_2[\"test-mlogloss-mean\"])),cvresult_2[\"test-mlogloss-mean\"].values,\n",
    "        label=\"Test\")\n",
    "plt.ylabel(\"logloss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31b14342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('SMOTE', SMOTE(random_state=42)),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.55, eval_metric='mlogloss',\n",
       "                               gamma=0, gpu_id=0, importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.05,\n",
       "                               max_delta_step=0, max_depth=4,\n",
       "                               min_child_weight=2, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=3000,\n",
       "                               n_jobs=4, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', random_state=42,\n",
       "                               reg_alpha=15, reg_lambda=10,\n",
       "                               scale_pos_weight=None, subsample=0.75,\n",
       "                               tree_method='gpu_hist', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_fin=XGBClassifier(learning_rate=0.05, n_estimators=3000, max_depth=4,\n",
    "                  min_child_weight=2, gamma=0, subsample=0.75, colsample_bytree=0.55,\n",
    "                  reg_alpha=15,reg_lambda=10,eval_metric=\"mlogloss\",\n",
    "                  objective=\"multi:softprob\", random_state=42,tree_method=\"gpu_hist\",booster=\"gbtree\",\n",
    "                     )\n",
    "pipe_fin=Pipeline([(\"scaler\",StandardScaler()),(\"SMOTE\", SMOTE(random_state=42)),\n",
    "               (\"classifier\",xgb_fin)])\n",
    "pipe_fin.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d44c96b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss : 1.0175424924348295\n"
     ]
    }
   ],
   "source": [
    "print(\"logloss : {}\".format(log_loss(y,pipe_fin.predict_proba(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c2a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
