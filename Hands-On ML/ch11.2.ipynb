{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd47bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c58f10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full,y_train_full), (X_test,y_test)=keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train_full,X_test=X_train_full/255.0, X_test/255.0\n",
    "\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(X_train_full,y_train_full,\n",
    "                                                 test_size=0.1,stratify=y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de4166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden,learning_rate):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "    for hidden in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(100,activation=\"elu\",kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.Dense(10,activation=\"softmax\",kernel_initializer=\"glorot_normal\"))\n",
    "    \n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef2213f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1407 [..............................] - ETA: 0s - loss: 3.4913 - accuracy: 0.1562WARNING:tensorflow:From C:\\Users\\Daniel\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1407 [..............................] - ETA: 3:20 - loss: 27.4735 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.2765s). Check your callbacks.\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.5099 - accuracy: 0.1486 - val_loss: 2.2952 - val_accuracy: 0.1446\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 17547564.0000 - accuracy: 0.1145 - val_loss: 2.3117 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 2.3086 - accuracy: 0.1007 - val_loss: 2.3217 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 2.3100 - accuracy: 0.1003 - val_loss: 2.3147 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 2.3117 - accuracy: 0.0993 - val_loss: 2.3218 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3126 - accuracy: 0.1007 - val_loss: 2.3161 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3139 - accuracy: 0.1005 - val_loss: 2.3100 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3146 - accuracy: 0.0986 - val_loss: 2.3215 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3157 - accuracy: 0.0992 - val_loss: 2.3166 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3191 - accuracy: 0.0981 - val_loss: 2.3114 - val_accuracy: 0.1000\n",
      "Epoch 1/10\n",
      "   2/1407 [..............................] - ETA: 4:28 - loss: 4.5525 - accuracy: 0.0625  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.3760s). Check your callbacks.\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.1909 - accuracy: 0.2069 - val_loss: 2.0641 - val_accuracy: 0.2464\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9665 - accuracy: 0.2610 - val_loss: 2.1316 - val_accuracy: 0.2484\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9573 - accuracy: 0.2596 - val_loss: 2.2590 - val_accuracy: 0.1416\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.2308 - accuracy: 0.1443 - val_loss: 2.3245 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3271 - accuracy: 0.0998 - val_loss: 2.3299 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3280 - accuracy: 0.1001 - val_loss: 2.3284 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3274 - accuracy: 0.1015 - val_loss: 2.3388 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3277 - accuracy: 0.0997 - val_loss: 2.3253 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3286 - accuracy: 0.1016 - val_loss: 2.3685 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3282 - accuracy: 0.1014 - val_loss: 2.3156 - val_accuracy: 0.1000\n",
      "Epoch 1/10\n",
      "   2/1407 [..............................] - ETA: 4:46 - loss: 6.7842 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.4003s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.0847 - accuracy: 0.2415 - val_loss: 2.1160 - val_accuracy: 0.2562\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8472 - accuracy: 0.3279 - val_loss: 1.8354 - val_accuracy: 0.3322\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7774 - accuracy: 0.3579 - val_loss: 1.7510 - val_accuracy: 0.3736\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7318 - accuracy: 0.3738 - val_loss: 1.7350 - val_accuracy: 0.3686\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8186 - accuracy: 0.3257 - val_loss: 1.8032 - val_accuracy: 0.3460\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7170 - accuracy: 0.3785 - val_loss: 1.7043 - val_accuracy: 0.3912\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6675 - accuracy: 0.4032 - val_loss: 1.6969 - val_accuracy: 0.4028\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8075 - accuracy: 0.3352 - val_loss: 1.7600 - val_accuracy: 0.3390\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7139 - accuracy: 0.3754 - val_loss: 1.7607 - val_accuracy: 0.3536\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6698 - accuracy: 0.3948 - val_loss: 1.7307 - val_accuracy: 0.3746\n",
      "Epoch 1/10\n",
      "   2/1407 [..............................] - ETA: 4:20 - loss: 4.0795 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.3621s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9863 - accuracy: 0.2790 - val_loss: 1.9528 - val_accuracy: 0.3088\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7711 - accuracy: 0.3592 - val_loss: 1.8352 - val_accuracy: 0.3452\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6817 - accuracy: 0.3939 - val_loss: 1.7449 - val_accuracy: 0.3838\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6117 - accuracy: 0.4221 - val_loss: 1.6470 - val_accuracy: 0.4016\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5610 - accuracy: 0.4392 - val_loss: 1.6228 - val_accuracy: 0.4060\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5178 - accuracy: 0.4589 - val_loss: 1.5717 - val_accuracy: 0.4336\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4785 - accuracy: 0.4702 - val_loss: 1.5282 - val_accuracy: 0.4552\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4463 - accuracy: 0.4840 - val_loss: 1.5128 - val_accuracy: 0.4718\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4180 - accuracy: 0.4921 - val_loss: 1.5285 - val_accuracy: 0.4656\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3891 - accuracy: 0.5005 - val_loss: 1.4923 - val_accuracy: 0.4806\n",
      "Epoch 1/10\n",
      "   2/1407 [..............................] - ETA: 4:53 - loss: 3.3254 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.4075s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9026 - accuracy: 0.3087 - val_loss: 1.7759 - val_accuracy: 0.3482\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6978 - accuracy: 0.3852 - val_loss: 1.9094 - val_accuracy: 0.3120\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6092 - accuracy: 0.4188 - val_loss: 1.6014 - val_accuracy: 0.4220\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5480 - accuracy: 0.4424 - val_loss: 1.7493 - val_accuracy: 0.3790\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4992 - accuracy: 0.4608 - val_loss: 1.6018 - val_accuracy: 0.4268\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4634 - accuracy: 0.4753 - val_loss: 1.5553 - val_accuracy: 0.4414\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4295 - accuracy: 0.4887 - val_loss: 1.5014 - val_accuracy: 0.4596\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3980 - accuracy: 0.4957 - val_loss: 1.4958 - val_accuracy: 0.4686\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3726 - accuracy: 0.5048 - val_loss: 1.4471 - val_accuracy: 0.4842\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3487 - accuracy: 0.5146 - val_loss: 1.4381 - val_accuracy: 0.4904\n",
      "Epoch 1/10\n",
      "   2/1407 [..............................] - ETA: 5:08 - loss: 4.1198 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.4317s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9769 - accuracy: 0.2879 - val_loss: 1.8081 - val_accuracy: 0.3390\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7533 - accuracy: 0.3679 - val_loss: 1.7138 - val_accuracy: 0.3830\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6622 - accuracy: 0.4009 - val_loss: 1.6783 - val_accuracy: 0.4052\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5981 - accuracy: 0.4228 - val_loss: 1.6259 - val_accuracy: 0.4156\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5538 - accuracy: 0.4414 - val_loss: 1.6180 - val_accuracy: 0.4182\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5204 - accuracy: 0.4528 - val_loss: 1.5652 - val_accuracy: 0.4316\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4933 - accuracy: 0.4631 - val_loss: 1.5344 - val_accuracy: 0.4530\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4689 - accuracy: 0.4758 - val_loss: 1.5400 - val_accuracy: 0.4458\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4474 - accuracy: 0.4805 - val_loss: 1.5130 - val_accuracy: 0.4592\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4288 - accuracy: 0.4869 - val_loss: 1.5162 - val_accuracy: 0.4578\n",
      "Epoch 1/10\n",
      "   2/1407 [..............................] - ETA: 5:20 - loss: 5.3124 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.4487s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.1340 - accuracy: 0.2481 - val_loss: 1.9214 - val_accuracy: 0.2992\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8567 - accuracy: 0.3337 - val_loss: 1.8170 - val_accuracy: 0.3434\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7727 - accuracy: 0.3637 - val_loss: 1.7406 - val_accuracy: 0.3760\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7153 - accuracy: 0.3875 - val_loss: 1.6936 - val_accuracy: 0.3878\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6717 - accuracy: 0.4014 - val_loss: 1.6809 - val_accuracy: 0.4008\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6349 - accuracy: 0.4162 - val_loss: 1.6548 - val_accuracy: 0.4110\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6068 - accuracy: 0.4264 - val_loss: 1.6170 - val_accuracy: 0.4182\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5830 - accuracy: 0.4349 - val_loss: 1.6040 - val_accuracy: 0.4232\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5618 - accuracy: 0.4419 - val_loss: 1.5866 - val_accuracy: 0.4320s: 1.5612 - accuracy\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5450 - accuracy: 0.4467 - val_loss: 1.5853 - val_accuracy: 0.4374\n"
     ]
    }
   ],
   "source": [
    "log_dir=os.path.join(os.curdir,\"my_logs\",\"ch11_ex8\")\n",
    "tb_cb=keras.callbacks.TensorBoard(log_dir)\n",
    "\n",
    "lr_rates=[1e-2,3e-3,1e-3,3e-4,1e-4,3e-5,1e-5]\n",
    "\n",
    "for lr_rate, n in lr_rates, range(len(lr_rates)):\n",
    "    model=build_model(20,lr_rate)\n",
    "    history=model.fit(X_train,y_train,epochs=10,\n",
    "                     validation_data=(X_valid,y_valid),\n",
    "                     callbacks=[tb_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45a8de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLR(keras.callbacks.Callback):\n",
    "    def __init__(self,factor):\n",
    "        self.factor=factor\n",
    "        self.rates=[]\n",
    "        self.losses=[]\n",
    "    def on_batch_end(self,batch,logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr,self.model.optimizer.lr*self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df266a1f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1928937363412229317264932864.0000 - accuracy: 0.1404 - val_loss: 41416825772501724378519568384.0000 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "exp_lr_cb=ExponentialLR(1.007)\n",
    "\n",
    "model=build_model(20,3e-5)\n",
    "history=model.fit(X_train,y_train,epochs=1, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[exp_lr_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8be89187",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.204674005508423\n",
      "0.00035444554\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp_lr_cb.rates,exp_lr_cb.losses)\n",
    "plt.xlabel(\"learning rate\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "print(min(exp_lr_cb.losses))\n",
    "print(exp_lr_cb.rates[exp_lr_cb.losses.index(min(exp_lr_cb.losses))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cba8ec44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x1d2f5e84fc8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#wyglada na to Å¼e loss zaczyna wzrastac przy lr=0.00035 wiec  lr=1.5e-4 powinno byc ok\n",
    "plt.plot(exp_lr_cb.rates,exp_lr_cb.losses)\n",
    "plt.xlabel(\"learning rate\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(1e-4,2e-2)\n",
    "plt.ylim(0,10)\n",
    "plt.vlines(0.00035,0,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "384681b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9545 - accuracy: 0.2927 - val_loss: 1.7913 - val_accuracy: 0.3604\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7290 - accuracy: 0.3718 - val_loss: 1.7284 - val_accuracy: 0.3892\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6490 - accuracy: 0.4024 - val_loss: 1.7038 - val_accuracy: 0.3894\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5933 - accuracy: 0.4268 - val_loss: 1.6728 - val_accuracy: 0.3980\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5511 - accuracy: 0.4414 - val_loss: 1.5669 - val_accuracy: 0.4314\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5164 - accuracy: 0.4546 - val_loss: 1.5399 - val_accuracy: 0.4436\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4872 - accuracy: 0.4660 - val_loss: 1.5253 - val_accuracy: 0.4524\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4626 - accuracy: 0.4744 - val_loss: 1.5452 - val_accuracy: 0.4422\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4426 - accuracy: 0.4841 - val_loss: 1.5021 - val_accuracy: 0.4582\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4211 - accuracy: 0.4890 - val_loss: 1.5281 - val_accuracy: 0.4556\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4034 - accuracy: 0.4969 - val_loss: 1.4788 - val_accuracy: 0.4656\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3859 - accuracy: 0.5049 - val_loss: 1.4872 - val_accuracy: 0.4720\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3685 - accuracy: 0.5113 - val_loss: 1.4613 - val_accuracy: 0.4742\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3520 - accuracy: 0.5160 - val_loss: 1.4699 - val_accuracy: 0.4702\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3378 - accuracy: 0.5202 - val_loss: 1.4750 - val_accuracy: 0.4724\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3239 - accuracy: 0.5247 - val_loss: 1.4592 - val_accuracy: 0.4856\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3078 - accuracy: 0.5334 - val_loss: 1.5400 - val_accuracy: 0.4458\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2954 - accuracy: 0.5374 - val_loss: 1.4519 - val_accuracy: 0.4852\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2850 - accuracy: 0.5420 - val_loss: 1.4463 - val_accuracy: 0.4912\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2704 - accuracy: 0.5470 - val_loss: 1.4570 - val_accuracy: 0.4848\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2615 - accuracy: 0.5503 - val_loss: 1.4531 - val_accuracy: 0.4880\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2471 - accuracy: 0.5552 - val_loss: 1.4583 - val_accuracy: 0.4848\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2355 - accuracy: 0.5587 - val_loss: 1.4361 - val_accuracy: 0.4970\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2252 - accuracy: 0.5626 - val_loss: 1.4612 - val_accuracy: 0.4946\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2134 - accuracy: 0.5665 - val_loss: 1.4766 - val_accuracy: 0.4890\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2028 - accuracy: 0.5701 - val_loss: 1.4443 - val_accuracy: 0.4902\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1935 - accuracy: 0.5718 - val_loss: 1.4316 - val_accuracy: 0.4948\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1816 - accuracy: 0.5779 - val_loss: 1.4298 - val_accuracy: 0.4990\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1694 - accuracy: 0.5834 - val_loss: 1.4378 - val_accuracy: 0.5020\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1613 - accuracy: 0.5838 - val_loss: 1.4393 - val_accuracy: 0.4994\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1492 - accuracy: 0.5890 - val_loss: 1.4588 - val_accuracy: 0.4950\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1409 - accuracy: 0.5919 - val_loss: 1.4520 - val_accuracy: 0.4978\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1319 - accuracy: 0.5941 - val_loss: 1.4633 - val_accuracy: 0.5032\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1234 - accuracy: 0.5971 - val_loss: 1.4590 - val_accuracy: 0.4950\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1133 - accuracy: 0.6030 - val_loss: 1.4566 - val_accuracy: 0.5026\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1030 - accuracy: 0.6057 - val_loss: 1.4531 - val_accuracy: 0.5014\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0927 - accuracy: 0.6082 - val_loss: 1.4825 - val_accuracy: 0.4936\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0855 - accuracy: 0.6124 - val_loss: 1.5050 - val_accuracy: 0.4864\n"
     ]
    }
   ],
   "source": [
    "model=build_model(20,1.5e-4)\n",
    "es_cb=keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "model=build_model(20,3e-5)\n",
    "history=model.fit(X_train,y_train,epochs=100, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b7f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ee444b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d2f13338c8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26cebd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_BN(n_hidden,learning_rate):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    for hidden in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(100,kernel_initializer=\"he_normal\"))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Activation(\"elu\"))\n",
    "    model.add(keras.layers.Dense(10,activation=\"softmax\",kernel_initializer=\"glorot_normal\"))\n",
    "    \n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8933543",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 23s 16ms/step - loss: 10.5151 - accuracy: 0.2296 - val_loss: 8600.2842 - val_accuracy: 0.1090\n",
      "2.0875725746154785\n",
      "0.096656956\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_lr_cb=ExponentialLR(1.007)\n",
    "\n",
    "model=build_model_BN(20,3e-5)\n",
    "history=model.fit(X_train,y_train,epochs=1, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[exp_lr_cb])\n",
    "plt.plot(exp_lr_cb.rates,exp_lr_cb.losses)\n",
    "plt.xlabel(\"learning rate\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "print(min(exp_lr_cb.losses))\n",
    "print(exp_lr_cb.rates[exp_lr_cb.losses.index(min(exp_lr_cb.losses))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a23aadf2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 2.0219 - accuracy: 0.2255 - val_loss: 2.4487 - val_accuracy: 0.2016\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.8740 - accuracy: 0.2781 - val_loss: 2.2674 - val_accuracy: 0.1962\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.8006 - accuracy: 0.3216 - val_loss: 3.3018 - val_accuracy: 0.1896\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.7536 - accuracy: 0.3503 - val_loss: 3.9071 - val_accuracy: 0.1770\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.7071 - accuracy: 0.3717 - val_loss: 3.8304 - val_accuracy: 0.1824\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6744 - accuracy: 0.3882 - val_loss: 2.1606 - val_accuracy: 0.2396\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6416 - accuracy: 0.3996 - val_loss: 3.6097 - val_accuracy: 0.1302\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6235 - accuracy: 0.4122 - val_loss: 1.8816 - val_accuracy: 0.2970\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 20s 15ms/step - loss: 1.6001 - accuracy: 0.4224 - val_loss: 4.6555 - val_accuracy: 0.1776\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5842 - accuracy: 0.4288 - val_loss: 1.8967 - val_accuracy: 0.3348\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5703 - accuracy: 0.4353 - val_loss: 3.3604 - val_accuracy: 0.1500\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5465 - accuracy: 0.4498 - val_loss: 2.4505 - val_accuracy: 0.2324\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.5300 - accuracy: 0.4544 - val_loss: 5.4862 - val_accuracy: 0.2102\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5241 - accuracy: 0.4560 - val_loss: 1.8255 - val_accuracy: 0.3494\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5142 - accuracy: 0.4597 - val_loss: 2.0007 - val_accuracy: 0.3530\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5032 - accuracy: 0.4639 - val_loss: 4.4085 - val_accuracy: 0.2246\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4933 - accuracy: 0.4680 - val_loss: 1.6304 - val_accuracy: 0.4112\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4872 - accuracy: 0.4699 - val_loss: 1.8516 - val_accuracy: 0.3392\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4720 - accuracy: 0.4768 - val_loss: 1.7318 - val_accuracy: 0.4118\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4688 - accuracy: 0.4759 - val_loss: 1.8679 - val_accuracy: 0.3814\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4606 - accuracy: 0.4805 - val_loss: 3.3145 - val_accuracy: 0.1892\n",
      "Epoch 22/100\n",
      "1260/1407 [=========================>....] - ETA: 2s - loss: 1.4479 - accuracy: 0.4829"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-e458c57b8a2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m history=model.fit(X_train,y_train,epochs=100, validation_data=(X_valid,y_valid),\n\u001b[1;32m----> 6\u001b[1;33m                  callbacks=[es_cb])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loss zaczal isc w gore dla lr=0.09 wiec ustawie lr=0.04 \n",
    "#okazuje sie ze ta metoda szukania lr nie jest zbyt dobra poniewaz loss i accuracy strasznie skacze\n",
    "model=build_model_BN(20,4e-2)\n",
    "es_cb=keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "\n",
    "history=model.fit(X_train,y_train,epochs=100, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b704d82",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 46:55 - loss: 3.3450 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 3.9875s). Check your callbacks.\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 2.0188 - accuracy: 0.2310 - val_loss: 2.7873 - val_accuracy: 0.2358\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.8580 - accuracy: 0.2961 - val_loss: 2.9601 - val_accuracy: 0.1562\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.7722 - accuracy: 0.3398 - val_loss: 1.9842 - val_accuracy: 0.3258\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.7232 - accuracy: 0.3682 - val_loss: 3.8904 - val_accuracy: 0.1918\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6929 - accuracy: 0.3824 - val_loss: 4.8003 - val_accuracy: 0.1624\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6658 - accuracy: 0.3927 - val_loss: 5.1996 - val_accuracy: 0.1782\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6375 - accuracy: 0.4066 - val_loss: 5.2253 - val_accuracy: 0.1934\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6137 - accuracy: 0.4173 - val_loss: 3.9797 - val_accuracy: 0.2236\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5972 - accuracy: 0.4283 - val_loss: 7.4022 - val_accuracy: 0.1752\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.5785 - accuracy: 0.4375 - val_loss: 5.4181 - val_accuracy: 0.1262\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.5634 - accuracy: 0.4442 - val_loss: 4.9673 - val_accuracy: 0.2102\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5512 - accuracy: 0.4466 - val_loss: 2.5824 - val_accuracy: 0.2398\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.5245 - accuracy: 0.4574 - val_loss: 8.3099 - val_accuracy: 0.1064\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5195 - accuracy: 0.4615 - val_loss: 4.7530 - val_accuracy: 0.1828\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.5068 - accuracy: 0.4633 - val_loss: 2.9141 - val_accuracy: 0.2746\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.4958 - accuracy: 0.4697 - val_loss: 1.5700 - val_accuracy: 0.4446\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.4839 - accuracy: 0.4746 - val_loss: 3.2986 - val_accuracy: 0.2060\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4740 - accuracy: 0.4761 - val_loss: 2.4076 - val_accuracy: 0.2464\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.4672 - accuracy: 0.4783 - val_loss: 1.6911 - val_accuracy: 0.4306\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4614 - accuracy: 0.4819 - val_loss: 1.5520 - val_accuracy: 0.4568\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 10:22 - loss: 3.0842 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.8662s). Check your callbacks.\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 2.0126 - accuracy: 0.2322 - val_loss: 2.7848 - val_accuracy: 0.1860\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.8751 - accuracy: 0.2817 - val_loss: 3.0346 - val_accuracy: 0.1688\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.7986 - accuracy: 0.3207 - val_loss: 2.0243 - val_accuracy: 0.3042\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.7485 - accuracy: 0.3535 - val_loss: 2.6825 - val_accuracy: 0.2198\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.7084 - accuracy: 0.3717 - val_loss: 5.7499 - val_accuracy: 0.1412\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.6768 - accuracy: 0.3852 - val_loss: 2.7936 - val_accuracy: 0.2656\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6511 - accuracy: 0.3986 - val_loss: 2.4865 - val_accuracy: 0.1976\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6280 - accuracy: 0.4058 - val_loss: 3.7751 - val_accuracy: 0.1902\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6134 - accuracy: 0.4151 - val_loss: 4.5734 - val_accuracy: 0.1512\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5976 - accuracy: 0.4199 - val_loss: 3.4524 - val_accuracy: 0.2454\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5810 - accuracy: 0.4311 - val_loss: 1.8583 - val_accuracy: 0.3336\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5662 - accuracy: 0.4354 - val_loss: 4.7946 - val_accuracy: 0.1962\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5548 - accuracy: 0.4406 - val_loss: 2.5768 - val_accuracy: 0.2718\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.5380 - accuracy: 0.4461 - val_loss: 2.7746 - val_accuracy: 0.2842\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.5384 - accuracy: 0.4513 - val_loss: 1.8213 - val_accuracy: 0.3552\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5206 - accuracy: 0.4537 - val_loss: 3.8814 - val_accuracy: 0.1864\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 1.5129 - accuracy: 0.4600 - val_loss: 2.3973 - val_accuracy: 0.2474\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4953 - accuracy: 0.4670 - val_loss: 1.6611 - val_accuracy: 0.4076\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4955 - accuracy: 0.4626 - val_loss: 1.5593 - val_accuracy: 0.4704\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4808 - accuracy: 0.4708 - val_loss: 1.8383 - val_accuracy: 0.3732\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 9:25 - loss: 3.1071 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.7835s). Check your callbacks.\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 2.0125 - accuracy: 0.2350 - val_loss: 3.1648 - val_accuracy: 0.2126\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.8607 - accuracy: 0.3012 - val_loss: 2.6353 - val_accuracy: 0.2702\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.7807 - accuracy: 0.3440 - val_loss: 1.9413 - val_accuracy: 0.3102\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.7340 - accuracy: 0.3636 - val_loss: 3.7624 - val_accuracy: 0.1832\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6953 - accuracy: 0.3782 - val_loss: 4.0816 - val_accuracy: 0.1308\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6747 - accuracy: 0.3922 - val_loss: 1.8949 - val_accuracy: 0.3398\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6480 - accuracy: 0.3969 - val_loss: 3.1102 - val_accuracy: 0.2684\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6193 - accuracy: 0.4117 - val_loss: 2.5217 - val_accuracy: 0.2578\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6043 - accuracy: 0.4260 - val_loss: 1.9960 - val_accuracy: 0.2978\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.5840 - accuracy: 0.4303 - val_loss: 3.9118 - val_accuracy: 0.2048\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5713 - accuracy: 0.4387 - val_loss: 2.8202 - val_accuracy: 0.2358\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.5518 - accuracy: 0.4454 - val_loss: 3.9858 - val_accuracy: 0.2394\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5393 - accuracy: 0.4543 - val_loss: 1.7621 - val_accuracy: 0.3854\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.5248 - accuracy: 0.4604 - val_loss: 1.7292 - val_accuracy: 0.3818\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5053 - accuracy: 0.4657 - val_loss: 1.8227 - val_accuracy: 0.3768\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4970 - accuracy: 0.4727 - val_loss: 3.6758 - val_accuracy: 0.2538\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4877 - accuracy: 0.4749 - val_loss: 1.8302 - val_accuracy: 0.3812\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4766 - accuracy: 0.4794 - val_loss: 1.8490 - val_accuracy: 0.3726\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4666 - accuracy: 0.4829 - val_loss: 1.9047 - val_accuracy: 0.3472\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.4501 - accuracy: 0.4883 - val_loss: 2.1580 - val_accuracy: 0.3114\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 9:20 - loss: 2.8215 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.7774s). Check your callbacks.\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 2.0148 - accuracy: 0.2354 - val_loss: 2.9652 - val_accuracy: 0.1582\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.8747 - accuracy: 0.2861 - val_loss: 5.0627 - val_accuracy: 0.1648\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.7923 - accuracy: 0.3339 - val_loss: 3.5253 - val_accuracy: 0.1846\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.7372 - accuracy: 0.3637 - val_loss: 3.6235 - val_accuracy: 0.2210\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.7011 - accuracy: 0.3789 - val_loss: 4.0469 - val_accuracy: 0.2064\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6702 - accuracy: 0.3899 - val_loss: 3.3605 - val_accuracy: 0.2292\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6495 - accuracy: 0.3999 - val_loss: 4.0777 - val_accuracy: 0.1384\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6266 - accuracy: 0.4143 - val_loss: 2.7762 - val_accuracy: 0.2054\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6025 - accuracy: 0.4198 - val_loss: 2.1994 - val_accuracy: 0.3278\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5826 - accuracy: 0.4320 - val_loss: 1.8495 - val_accuracy: 0.3296\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5757 - accuracy: 0.4371 - val_loss: 2.4572 - val_accuracy: 0.2144\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5560 - accuracy: 0.4464 - val_loss: 1.9613 - val_accuracy: 0.3218\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5365 - accuracy: 0.4522 - val_loss: 1.9723 - val_accuracy: 0.2694\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5284 - accuracy: 0.4565 - val_loss: 1.9058 - val_accuracy: 0.3320\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5118 - accuracy: 0.4612 - val_loss: 2.1998 - val_accuracy: 0.2034\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5024 - accuracy: 0.4669 - val_loss: 2.8354 - val_accuracy: 0.2448- accuracy: \n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4945 - accuracy: 0.4721 - val_loss: 1.6344 - val_accuracy: 0.4170\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4873 - accuracy: 0.4740 - val_loss: 1.6197 - val_accuracy: 0.4246\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4787 - accuracy: 0.4747 - val_loss: 3.7359 - val_accuracy: 0.2406\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4728 - accuracy: 0.4775 - val_loss: 1.7609 - val_accuracy: 0.3618\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 10:08 - loss: 3.1423 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.8468s). Check your callbacks.\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 2.0153 - accuracy: 0.2317 - val_loss: 2.1660 - val_accuracy: 0.2550\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.8526 - accuracy: 0.2925 - val_loss: 2.1475 - val_accuracy: 0.2710\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.7796 - accuracy: 0.3343 - val_loss: 2.4748 - val_accuracy: 0.2180\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.7291 - accuracy: 0.3571 - val_loss: 2.9427 - val_accuracy: 0.1314\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6966 - accuracy: 0.3697 - val_loss: 3.6405 - val_accuracy: 0.1996\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6663 - accuracy: 0.3843 - val_loss: 1.9733 - val_accuracy: 0.3358\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6434 - accuracy: 0.3968 - val_loss: 2.6370 - val_accuracy: 0.2210\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.6222 - accuracy: 0.4061 - val_loss: 1.7624 - val_accuracy: 0.3668\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5935 - accuracy: 0.4227 - val_loss: 3.1838 - val_accuracy: 0.2896\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5827 - accuracy: 0.4293 - val_loss: 2.2588 - val_accuracy: 0.2430\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5595 - accuracy: 0.4398 - val_loss: 3.5895 - val_accuracy: 0.1586\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5429 - accuracy: 0.4494 - val_loss: 2.8956 - val_accuracy: 0.2620\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5187 - accuracy: 0.4551 - val_loss: 1.7033 - val_accuracy: 0.4084\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5126 - accuracy: 0.4562 - val_loss: 1.7969 - val_accuracy: 0.3784\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4980 - accuracy: 0.4632 - val_loss: 1.8984 - val_accuracy: 0.3520\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4884 - accuracy: 0.4684 - val_loss: 2.9677 - val_accuracy: 0.3218\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4731 - accuracy: 0.4750 - val_loss: 1.8966 - val_accuracy: 0.3810\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4729 - accuracy: 0.4736 - val_loss: 1.6502 - val_accuracy: 0.3966\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4614 - accuracy: 0.4758 - val_loss: 2.6701 - val_accuracy: 0.3190\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4455 - accuracy: 0.4833 - val_loss: 1.6536 - val_accuracy: 0.4268\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 9:07 - loss: 3.2951 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0170s vs `on_train_batch_end` time: 0.7618s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 21s 15ms/step - loss: 2.0042 - accuracy: 0.2501 - val_loss: 2.3869 - val_accuracy: 0.2290\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.8153 - accuracy: 0.3202 - val_loss: 3.7106 - val_accuracy: 0.1578\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.7227 - accuracy: 0.3618 - val_loss: 1.9631 - val_accuracy: 0.3430\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6701 - accuracy: 0.3900 - val_loss: 2.1958 - val_accuracy: 0.2670\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6224 - accuracy: 0.4121 - val_loss: 2.1796 - val_accuracy: 0.3240\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5908 - accuracy: 0.4250 - val_loss: 2.3407 - val_accuracy: 0.2390\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5564 - accuracy: 0.4385 - val_loss: 1.9490 - val_accuracy: 0.3314\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5314 - accuracy: 0.4497 - val_loss: 2.3678 - val_accuracy: 0.2834\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4994 - accuracy: 0.4628 - val_loss: 1.7619 - val_accuracy: 0.3898\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4816 - accuracy: 0.4694 - val_loss: 3.3602 - val_accuracy: 0.1890\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4579 - accuracy: 0.4784 - val_loss: 2.2612 - val_accuracy: 0.3420\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4361 - accuracy: 0.4886 - val_loss: 2.3257 - val_accuracy: 0.3016\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4192 - accuracy: 0.4918 - val_loss: 2.6923 - val_accuracy: 0.3064\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4051 - accuracy: 0.4981 - val_loss: 2.1715 - val_accuracy: 0.3444\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3910 - accuracy: 0.5050 - val_loss: 2.0602 - val_accuracy: 0.3352\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3749 - accuracy: 0.5105 - val_loss: 1.7108 - val_accuracy: 0.3850\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3627 - accuracy: 0.5159 - val_loss: 3.7235 - val_accuracy: 0.3082\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3526 - accuracy: 0.5184 - val_loss: 2.1944 - val_accuracy: 0.3042\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3361 - accuracy: 0.5257 - val_loss: 1.4284 - val_accuracy: 0.4972\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3258 - accuracy: 0.5315 - val_loss: 2.3396 - val_accuracy: 0.3104\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 8:59 - loss: 3.3510 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.7475s). Check your callbacks.\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 2.0257 - accuracy: 0.2248 - val_loss: 2.3661 - val_accuracy: 0.2338\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.8673 - accuracy: 0.2861 - val_loss: 2.2871 - val_accuracy: 0.2342\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.7929 - accuracy: 0.3294 - val_loss: 5.1978 - val_accuracy: 0.1844\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.7408 - accuracy: 0.3579 - val_loss: 3.1988 - val_accuracy: 0.2190\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6966 - accuracy: 0.3752 - val_loss: 2.3351 - val_accuracy: 0.2722\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6722 - accuracy: 0.3886 - val_loss: 3.0774 - val_accuracy: 0.2760\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6518 - accuracy: 0.3961 - val_loss: 2.6881 - val_accuracy: 0.2112\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6358 - accuracy: 0.4055 - val_loss: 2.4375 - val_accuracy: 0.2260\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6158 - accuracy: 0.4121 - val_loss: 2.1890 - val_accuracy: 0.3096\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6077 - accuracy: 0.4127 - val_loss: 2.3729 - val_accuracy: 0.2294\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5885 - accuracy: 0.4234 - val_loss: 2.2759 - val_accuracy: 0.2654\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5709 - accuracy: 0.4294 - val_loss: 2.3190 - val_accuracy: 0.1648\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5688 - accuracy: 0.4307 - val_loss: 1.8804 - val_accuracy: 0.2906\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5521 - accuracy: 0.4402 - val_loss: 2.1402 - val_accuracy: 0.3590\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5374 - accuracy: 0.4434 - val_loss: 1.8129 - val_accuracy: 0.3530\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5389 - accuracy: 0.4456 - val_loss: 1.9454 - val_accuracy: 0.2852\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5377 - accuracy: 0.4468 - val_loss: 2.1341 - val_accuracy: 0.2716\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5219 - accuracy: 0.4527 - val_loss: 2.0805 - val_accuracy: 0.3092\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5214 - accuracy: 0.4542 - val_loss: 3.3131 - val_accuracy: 0.1876\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5074 - accuracy: 0.4613 - val_loss: 1.5744 - val_accuracy: 0.4442\n"
     ]
    }
   ],
   "source": [
    "lr_rates=[1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3]\n",
    "run_number=0\n",
    "for lr_rate in lr_rates:\n",
    "    run_number+=1\n",
    "    model=build_model_BN(20,lr_rate)\n",
    "    log_dir=os.path.join(os.curdir,\"my_logs\",\"ch11_ex8\",\"run_bn_{:03d}\".format(run_number))\n",
    "    tb_cb=keras.callbacks.TensorBoard(log_dir)\n",
    "    history=model.fit(X_train,y_train,epochs=20, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c2c1805",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.8377 - accuracy: 0.3415 - val_loss: 1.7110 - val_accuracy: 0.3888\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.6760 - accuracy: 0.4032 - val_loss: 1.6051 - val_accuracy: 0.4228\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.6077 - accuracy: 0.4274 - val_loss: 1.5206 - val_accuracy: 0.4592\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.5563 - accuracy: 0.4491 - val_loss: 1.4782 - val_accuracy: 0.4728\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5151 - accuracy: 0.4617 - val_loss: 1.4722 - val_accuracy: 0.4850\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4790 - accuracy: 0.4763 - val_loss: 1.4660 - val_accuracy: 0.4808\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.4444 - accuracy: 0.4867 - val_loss: 1.4170 - val_accuracy: 0.4950\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.4162 - accuracy: 0.4998 - val_loss: 1.3710 - val_accuracy: 0.5102\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3846 - accuracy: 0.5099 - val_loss: 1.4037 - val_accuracy: 0.5044\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3677 - accuracy: 0.5179 - val_loss: 1.3331 - val_accuracy: 0.5328\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3408 - accuracy: 0.5286 - val_loss: 1.3609 - val_accuracy: 0.5198\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3163 - accuracy: 0.5361 - val_loss: 1.3909 - val_accuracy: 0.5132\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 20s 15ms/step - loss: 1.2967 - accuracy: 0.5435 - val_loss: 1.3924 - val_accuracy: 0.5154\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2808 - accuracy: 0.5482 - val_loss: 1.3461 - val_accuracy: 0.5340\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2640 - accuracy: 0.5537 - val_loss: 1.3459 - val_accuracy: 0.5310\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2440 - accuracy: 0.5626 - val_loss: 1.3205 - val_accuracy: 0.5342\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2262 - accuracy: 0.5681 - val_loss: 1.3487 - val_accuracy: 0.5314\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2105 - accuracy: 0.5772 - val_loss: 1.3215 - val_accuracy: 0.5462\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1931 - accuracy: 0.5811 - val_loss: 1.3182 - val_accuracy: 0.5372\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1830 - accuracy: 0.5845 - val_loss: 1.3216 - val_accuracy: 0.5412\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1655 - accuracy: 0.5926 - val_loss: 1.3466 - val_accuracy: 0.5328\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1552 - accuracy: 0.5953 - val_loss: 1.3328 - val_accuracy: 0.5392\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1386 - accuracy: 0.6003 - val_loss: 1.3305 - val_accuracy: 0.5396\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1231 - accuracy: 0.6068 - val_loss: 1.3237 - val_accuracy: 0.5410\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1113 - accuracy: 0.6105 - val_loss: 1.3455 - val_accuracy: 0.5410\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0962 - accuracy: 0.6174 - val_loss: 1.3358 - val_accuracy: 0.5414\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0820 - accuracy: 0.6211 - val_loss: 1.3272 - val_accuracy: 0.5430\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0704 - accuracy: 0.6244 - val_loss: 1.3564 - val_accuracy: 0.5406\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0534 - accuracy: 0.6310 - val_loss: 1.3564 - val_accuracy: 0.5418\n"
     ]
    }
   ],
   "source": [
    "#po sprawdzeniu tensorboard lr=1e-3 wyglada dobrze\n",
    "model=build_model_BN(20,1e-3)\n",
    "es_cb=keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "history=model.fit(X_train,y_train,epochs=100, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91f69e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3426 - accuracy: 0.5281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.342589020729065, 0.5281000137329102]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba8fd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_SELU(n_hidden,learning_rate):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "    \n",
    "    for hidden in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(100,activation=\"selu\",kernel_initializer=\"lecun_normal\"))\n",
    "        \n",
    "    model.add(keras.layers.Dense(10,activation=\"softmax\",kernel_initializer=\"glorot_normal\"))\n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de2ae9c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 5:46 - loss: 3.0947 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.4847s). Check your callbacks.\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.0057 - accuracy: 0.2698 - val_loss: 1.8821 - val_accuracy: 0.3094\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7977 - accuracy: 0.3549 - val_loss: 1.7344 - val_accuracy: 0.3764\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7186 - accuracy: 0.3822 - val_loss: 1.6913 - val_accuracy: 0.3896\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6690 - accuracy: 0.4001 - val_loss: 1.6802 - val_accuracy: 0.3998\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6305 - accuracy: 0.4159 - val_loss: 1.6246 - val_accuracy: 0.4152\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6000 - accuracy: 0.4262 - val_loss: 1.6187 - val_accuracy: 0.4184\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5749 - accuracy: 0.4360 - val_loss: 1.5888 - val_accuracy: 0.4278\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5526 - accuracy: 0.4439 - val_loss: 1.5669 - val_accuracy: 0.4352\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5348 - accuracy: 0.4486 - val_loss: 1.5536 - val_accuracy: 0.4340\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5199 - accuracy: 0.4554 - val_loss: 1.5592 - val_accuracy: 0.4444\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5038 - accuracy: 0.4626 - val_loss: 1.5356 - val_accuracy: 0.4456\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4893 - accuracy: 0.4688 - val_loss: 1.5514 - val_accuracy: 0.4434\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4759 - accuracy: 0.4719 - val_loss: 1.5201 - val_accuracy: 0.4564\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4619 - accuracy: 0.4764 - val_loss: 1.5230 - val_accuracy: 0.4468\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4526 - accuracy: 0.4820 - val_loss: 1.5163 - val_accuracy: 0.4524\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4402 - accuracy: 0.4845 - val_loss: 1.5272 - val_accuracy: 0.4530\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4300 - accuracy: 0.4888 - val_loss: 1.5001 - val_accuracy: 0.4590\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4208 - accuracy: 0.4907 - val_loss: 1.5134 - val_accuracy: 0.4536\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4107 - accuracy: 0.4950 - val_loss: 1.5011 - val_accuracy: 0.4630\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4012 - accuracy: 0.4985 - val_loss: 1.4866 - val_accuracy: 0.4694\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 4:47 - loss: 2.7352 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.4011s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9061 - accuracy: 0.3076 - val_loss: 1.8550 - val_accuracy: 0.3320\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7247 - accuracy: 0.3772 - val_loss: 1.6664 - val_accuracy: 0.4016 loss: 1.7303 - accu\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6425 - accuracy: 0.4101 - val_loss: 1.6427 - val_accuracy: 0.4136\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5889 - accuracy: 0.4304 - val_loss: 1.5974 - val_accuracy: 0.4294\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5466 - accuracy: 0.4448 - val_loss: 1.6077 - val_accuracy: 0.4270\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5147 - accuracy: 0.4558 - val_loss: 1.5362 - val_accuracy: 0.4454\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4858 - accuracy: 0.4652 - val_loss: 1.5223 - val_accuracy: 0.4612\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4626 - accuracy: 0.4774 - val_loss: 1.6019 - val_accuracy: 0.4358\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4446 - accuracy: 0.4813 - val_loss: 1.5353 - val_accuracy: 0.4534\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4229 - accuracy: 0.4895 - val_loss: 1.4894 - val_accuracy: 0.4722\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4060 - accuracy: 0.4956 - val_loss: 1.4870 - val_accuracy: 0.4698\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3899 - accuracy: 0.5038 - val_loss: 1.4809 - val_accuracy: 0.4686\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3742 - accuracy: 0.5102 - val_loss: 1.4739 - val_accuracy: 0.4712\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3569 - accuracy: 0.5117 - val_loss: 1.5450 - val_accuracy: 0.4544\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3460 - accuracy: 0.5173 - val_loss: 1.4625 - val_accuracy: 0.4788\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3323 - accuracy: 0.5249 - val_loss: 1.4640 - val_accuracy: 0.4780\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3176 - accuracy: 0.5270 - val_loss: 1.4534 - val_accuracy: 0.4834\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3043 - accuracy: 0.5317 - val_loss: 1.4599 - val_accuracy: 0.4862\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2934 - accuracy: 0.5378 - val_loss: 1.4525 - val_accuracy: 0.4892\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2805 - accuracy: 0.5420 - val_loss: 1.4701 - val_accuracy: 0.4770\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 5:13 - loss: 3.2894 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.4369s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8897 - accuracy: 0.3162 - val_loss: 1.8271 - val_accuracy: 0.3254\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7128 - accuracy: 0.3828 - val_loss: 1.7067 - val_accuracy: 0.3836\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6373 - accuracy: 0.4099 - val_loss: 1.6579 - val_accuracy: 0.3970\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5808 - accuracy: 0.4321 - val_loss: 1.6415 - val_accuracy: 0.4120\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5383 - accuracy: 0.4486 - val_loss: 1.5426 - val_accuracy: 0.4468\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5026 - accuracy: 0.4601 - val_loss: 1.5284 - val_accuracy: 0.4472\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4741 - accuracy: 0.4727 - val_loss: 1.4987 - val_accuracy: 0.4656\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4470 - accuracy: 0.4798 - val_loss: 1.4939 - val_accuracy: 0.4602\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4189 - accuracy: 0.4906 - val_loss: 1.5245 - val_accuracy: 0.4486\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4015 - accuracy: 0.4977 - val_loss: 1.4676 - val_accuracy: 0.4676\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3812 - accuracy: 0.5053 - val_loss: 1.4618 - val_accuracy: 0.4766\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3621 - accuracy: 0.5100 - val_loss: 1.4448 - val_accuracy: 0.4802\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3412 - accuracy: 0.5202 - val_loss: 1.4678 - val_accuracy: 0.4766\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3267 - accuracy: 0.5224 - val_loss: 1.4522 - val_accuracy: 0.4864\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3098 - accuracy: 0.5325 - val_loss: 1.4374 - val_accuracy: 0.4876\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2923 - accuracy: 0.5375 - val_loss: 1.4336 - val_accuracy: 0.4872\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2784 - accuracy: 0.5403 - val_loss: 1.4685 - val_accuracy: 0.4800\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2633 - accuracy: 0.5465 - val_loss: 1.4245 - val_accuracy: 0.4938\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2495 - accuracy: 0.5518 - val_loss: 1.4167 - val_accuracy: 0.4970\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2345 - accuracy: 0.5564 - val_loss: 1.4194 - val_accuracy: 0.4998\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 5:37 - loss: 2.7735 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.4707s). Check your callbacks.\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8927 - accuracy: 0.3127 - val_loss: 1.7333 - val_accuracy: 0.3626\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7105 - accuracy: 0.3823 - val_loss: 1.7995 - val_accuracy: 0.3556\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6310 - accuracy: 0.4121 - val_loss: 1.6034 - val_accuracy: 0.4102\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5737 - accuracy: 0.4338 - val_loss: 1.6122 - val_accuracy: 0.4210\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5277 - accuracy: 0.4528 - val_loss: 1.5179 - val_accuracy: 0.4512\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4951 - accuracy: 0.4619 - val_loss: 1.5901 - val_accuracy: 0.4320\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4621 - accuracy: 0.4773 - val_loss: 1.4854 - val_accuracy: 0.4698\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4338 - accuracy: 0.4849 - val_loss: 1.4984 - val_accuracy: 0.4606\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4126 - accuracy: 0.4934 - val_loss: 1.5229 - val_accuracy: 0.4620\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3897 - accuracy: 0.5007 - val_loss: 1.4668 - val_accuracy: 0.4748\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3645 - accuracy: 0.5110 - val_loss: 1.4636 - val_accuracy: 0.4802\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3466 - accuracy: 0.5176 - val_loss: 1.4709 - val_accuracy: 0.4828\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3270 - accuracy: 0.5226 - val_loss: 1.5392 - val_accuracy: 0.4666\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3111 - accuracy: 0.5296 - val_loss: 1.5007 - val_accuracy: 0.4670\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2913 - accuracy: 0.5347 - val_loss: 1.4293 - val_accuracy: 0.4900\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2690 - accuracy: 0.5440 - val_loss: 1.4703 - val_accuracy: 0.4792\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2577 - accuracy: 0.5462 - val_loss: 1.4640 - val_accuracy: 0.4898\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2364 - accuracy: 0.5563 - val_loss: 1.4245 - val_accuracy: 0.5032\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2266 - accuracy: 0.5580 - val_loss: 1.4121 - val_accuracy: 0.4976\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2049 - accuracy: 0.5650 - val_loss: 1.4604 - val_accuracy: 0.4940\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 4:58 - loss: 3.0575 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.4165s). Check your callbacks.\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9818 - accuracy: 0.2745 - val_loss: 1.9123 - val_accuracy: 0.2966\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7845 - accuracy: 0.3522 - val_loss: 2.0780 - val_accuracy: 0.2906\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.7008 - accuracy: 0.3871 - val_loss: 1.7941 - val_accuracy: 0.3610\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6350 - accuracy: 0.4138 - val_loss: 1.6451 - val_accuracy: 0.4030\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5853 - accuracy: 0.4295 - val_loss: 1.5784 - val_accuracy: 0.4292\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5397 - accuracy: 0.4483 - val_loss: 1.6042 - val_accuracy: 0.4296\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5090 - accuracy: 0.4581 - val_loss: 1.5915 - val_accuracy: 0.4306\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4827 - accuracy: 0.4688 - val_loss: 1.5387 - val_accuracy: 0.4466\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4559 - accuracy: 0.4802 - val_loss: 1.6040 - val_accuracy: 0.4334\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4309 - accuracy: 0.4869 - val_loss: 1.4944 - val_accuracy: 0.4638\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4114 - accuracy: 0.4952 - val_loss: 1.4865 - val_accuracy: 0.4758\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3878 - accuracy: 0.5035 - val_loss: 1.4783 - val_accuracy: 0.4696\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3696 - accuracy: 0.5116 - val_loss: 1.4812 - val_accuracy: 0.4782\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3469 - accuracy: 0.5162 - val_loss: 1.4493 - val_accuracy: 0.4800\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3273 - accuracy: 0.5240 - val_loss: 1.4614 - val_accuracy: 0.4848\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3064 - accuracy: 0.5323 - val_loss: 1.5056 - val_accuracy: 0.4822\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2903 - accuracy: 0.5368 - val_loss: 1.4523 - val_accuracy: 0.4948\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2703 - accuracy: 0.5427 - val_loss: 1.4163 - val_accuracy: 0.5164\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2516 - accuracy: 0.5521 - val_loss: 1.4494 - val_accuracy: 0.4958\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2376 - accuracy: 0.5584 - val_loss: 1.4619 - val_accuracy: 0.5016\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 4:31 - loss: 3.6485 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.3780s). Check your callbacks.\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.0303 - accuracy: 0.2512 - val_loss: 1.9040 - val_accuracy: 0.2966\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8321 - accuracy: 0.3340 - val_loss: 1.8172 - val_accuracy: 0.3374\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7476 - accuracy: 0.3684 - val_loss: 1.9257 - val_accuracy: 0.3170\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6842 - accuracy: 0.3958 - val_loss: 1.6652 - val_accuracy: 0.4040\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6329 - accuracy: 0.4169 - val_loss: 1.6319 - val_accuracy: 0.4050\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5969 - accuracy: 0.4273 - val_loss: 1.7660 - val_accuracy: 0.3872\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5595 - accuracy: 0.4470 - val_loss: 1.6581 - val_accuracy: 0.4256\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5305 - accuracy: 0.4561 - val_loss: 1.5406 - val_accuracy: 0.4476\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5024 - accuracy: 0.4668 - val_loss: 1.5750 - val_accuracy: 0.4434\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4873 - accuracy: 0.4732 - val_loss: 1.5293 - val_accuracy: 0.4616\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4649 - accuracy: 0.4769 - val_loss: 1.5068 - val_accuracy: 0.4610\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4466 - accuracy: 0.4866 - val_loss: 1.5335 - val_accuracy: 0.4576\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4245 - accuracy: 0.4939 - val_loss: 1.5687 - val_accuracy: 0.4448\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4062 - accuracy: 0.5019 - val_loss: 1.5315 - val_accuracy: 0.4484\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3904 - accuracy: 0.5068 - val_loss: 1.4707 - val_accuracy: 0.4922\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3719 - accuracy: 0.5134 - val_loss: 1.6347 - val_accuracy: 0.4258\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3488 - accuracy: 0.5242 - val_loss: 1.5784 - val_accuracy: 0.4646\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3374 - accuracy: 0.5274 - val_loss: 1.4499 - val_accuracy: 0.4932\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3227 - accuracy: 0.5330 - val_loss: 1.4973 - val_accuracy: 0.4774\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3062 - accuracy: 0.5383 - val_loss: 1.4693 - val_accuracy: 0.4854\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 4:38 - loss: 2.8326 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.3882s). Check your callbacks.\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.1665 - accuracy: 0.1795 - val_loss: 2.0097 - val_accuracy: 0.2156\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9615 - accuracy: 0.2606 - val_loss: 2.1200 - val_accuracy: 0.2458\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8897 - accuracy: 0.2908 - val_loss: 1.9315 - val_accuracy: 0.2756\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8882 - accuracy: 0.2829 - val_loss: 1.8445 - val_accuracy: 0.3016\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8261 - accuracy: 0.3156 - val_loss: 1.7800 - val_accuracy: 0.3356\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7976 - accuracy: 0.3265 - val_loss: 1.8269 - val_accuracy: 0.3112\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7776 - accuracy: 0.3345 - val_loss: 1.7432 - val_accuracy: 0.3510\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7502 - accuracy: 0.3520 - val_loss: 2.1060 - val_accuracy: 0.2260\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8162 - accuracy: 0.3165 - val_loss: 1.7633 - val_accuracy: 0.3448\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7169 - accuracy: 0.3614 - val_loss: 1.7250 - val_accuracy: 0.3302\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8716 - accuracy: 0.2899 - val_loss: 1.8088 - val_accuracy: 0.3270\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7559 - accuracy: 0.3393 - val_loss: 1.7022 - val_accuracy: 0.3648\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7116 - accuracy: 0.3642 - val_loss: 1.7101 - val_accuracy: 0.3534\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6769 - accuracy: 0.3824 - val_loss: 1.6719 - val_accuracy: 0.3764\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7755 - accuracy: 0.3614 - val_loss: 1.7185 - val_accuracy: 0.3654\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6933 - accuracy: 0.3769 - val_loss: 1.6969 - val_accuracy: 0.3766\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6605 - accuracy: 0.3882 - val_loss: 1.7290 - val_accuracy: 0.3784\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6347 - accuracy: 0.3997 - val_loss: 1.6664 - val_accuracy: 0.3786\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6165 - accuracy: 0.4080 - val_loss: 1.6387 - val_accuracy: 0.4062\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6140 - accuracy: 0.4098 - val_loss: 1.6925 - val_accuracy: 0.3888\n"
     ]
    }
   ],
   "source": [
    "lr_rates=[1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3]\n",
    "run_number=0\n",
    "for lr_rate in lr_rates:\n",
    "    run_number+=1\n",
    "    model=build_model_SELU(20,lr_rate)\n",
    "    log_dir=os.path.join(os.curdir,\"my_logs\",\"ch11_ex8\",\"run_selu_{:03d}\".format(run_number))\n",
    "    tb_cb=keras.callbacks.TensorBoard(log_dir)\n",
    "    history=model.fit(X_train,y_train,epochs=20, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "efbe83d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9805 - accuracy: 0.2735 - val_loss: 1.8337 - val_accuracy: 0.3408\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7781 - accuracy: 0.3601 - val_loss: 1.7082 - val_accuracy: 0.3766\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6952 - accuracy: 0.3911 - val_loss: 1.7329 - val_accuracy: 0.3822\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6347 - accuracy: 0.4144 - val_loss: 1.6335 - val_accuracy: 0.4146\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5894 - accuracy: 0.4309 - val_loss: 1.6697 - val_accuracy: 0.3972\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5500 - accuracy: 0.4449 - val_loss: 1.6478 - val_accuracy: 0.4124\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5126 - accuracy: 0.4590 - val_loss: 1.5867 - val_accuracy: 0.4304\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4833 - accuracy: 0.4701 - val_loss: 1.5254 - val_accuracy: 0.4634\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4553 - accuracy: 0.4792 - val_loss: 1.4948 - val_accuracy: 0.4710\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4292 - accuracy: 0.4928 - val_loss: 1.5096 - val_accuracy: 0.4542\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4071 - accuracy: 0.4976 - val_loss: 1.4620 - val_accuracy: 0.4806\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3895 - accuracy: 0.5071 - val_loss: 1.4804 - val_accuracy: 0.4780\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3630 - accuracy: 0.5124 - val_loss: 1.4845 - val_accuracy: 0.4796\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3436 - accuracy: 0.5212 - val_loss: 1.4369 - val_accuracy: 0.4946\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3266 - accuracy: 0.5274 - val_loss: 1.4568 - val_accuracy: 0.4820\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3080 - accuracy: 0.5339 - val_loss: 1.4930 - val_accuracy: 0.4782\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2833 - accuracy: 0.5406 - val_loss: 1.4497 - val_accuracy: 0.4946\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2700 - accuracy: 0.5481 - val_loss: 1.5034 - val_accuracy: 0.4854\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2553 - accuracy: 0.5536 - val_loss: 1.4266 - val_accuracy: 0.5094\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2356 - accuracy: 0.5616 - val_loss: 1.4668 - val_accuracy: 0.5026\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2159 - accuracy: 0.5671 - val_loss: 1.4314 - val_accuracy: 0.5106\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2001 - accuracy: 0.5713 - val_loss: 1.4260 - val_accuracy: 0.5212\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1834 - accuracy: 0.5818 - val_loss: 1.4695 - val_accuracy: 0.4966\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1669 - accuracy: 0.5850 - val_loss: 1.4623 - val_accuracy: 0.5126\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1484 - accuracy: 0.5906 - val_loss: 1.4298 - val_accuracy: 0.5068\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1315 - accuracy: 0.5976 - val_loss: 1.4672 - val_accuracy: 0.5032\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1186 - accuracy: 0.6000 - val_loss: 1.4365 - val_accuracy: 0.5130\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1022 - accuracy: 0.6071 - val_loss: 1.4254 - val_accuracy: 0.5166\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0922 - accuracy: 0.6102 - val_loss: 1.4674 - val_accuracy: 0.5108\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0730 - accuracy: 0.6173 - val_loss: 1.4604 - val_accuracy: 0.5176\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0574 - accuracy: 0.6220 - val_loss: 1.4667 - val_accuracy: 0.5202\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0443 - accuracy: 0.6264 - val_loss: 1.4368 - val_accuracy: 0.5146\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0302 - accuracy: 0.6333 - val_loss: 1.4718 - val_accuracy: 0.5230\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0160 - accuracy: 0.6384 - val_loss: 1.4906 - val_accuracy: 0.5146\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9995 - accuracy: 0.6432 - val_loss: 1.5150 - val_accuracy: 0.5188\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.9932 - accuracy: 0.6453 - val_loss: 1.5177 - val_accuracy: 0.5138\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 0.9721 - accuracy: 0.6542 - val_loss: 1.5128 - val_accuracy: 0.5148\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9631 - accuracy: 0.6565 - val_loss: 1.5452 - val_accuracy: 0.5046\n"
     ]
    }
   ],
   "source": [
    "#l4=3e-4 wyglada dobrze\n",
    "model=build_model_SELU(20,3e-4)\n",
    "es_cb=keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "history=model.fit(X_train,y_train,epochs=100, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9dc94e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4409 - accuracy: 0.5131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4408578872680664, 0.5131000280380249]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16270a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_SELU_AD(n_hidden,learning_rate):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "    \n",
    "    for hidden in range(n_hidden-3):\n",
    "        model.add(keras.layers.Dense(100,activation=\"selu\",kernel_initializer=\"lecun_normal\"))\n",
    "    for hidden in range(3):\n",
    "        model.add(keras.layers.Dense(100,activation=\"selu\",kernel_initializer=\"lecun_normal\"))\n",
    "        model.add(keras.layers.AlphaDropout(0.2))\n",
    "        \n",
    "    model.add(keras.layers.Dense(10,activation=\"softmax\",kernel_initializer=\"glorot_normal\"))\n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac1b03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/1407 [..............................] - ETA: 0s - loss: 2.8078 - accuracy: 0.0312WARNING:tensorflow:From C:\\Users\\Daniel\\anaconda3\\envs\\py37ml\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1407 [..............................] - ETA: 3:22 - loss: 2.9794 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.2798s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.6282 - accuracy: 0.1537 - val_loss: 2.0624 - val_accuracy: 0.2962\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3495 - accuracy: 0.2093 - val_loss: 2.1328 - val_accuracy: 0.3148\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.2227 - accuracy: 0.2395 - val_loss: 2.1291 - val_accuracy: 0.3312\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.1255 - accuracy: 0.2606 - val_loss: 1.9780 - val_accuracy: 0.3466\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.0612 - accuracy: 0.2730 - val_loss: 2.0106 - val_accuracy: 0.3566\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9956 - accuracy: 0.2928 - val_loss: 1.9233 - val_accuracy: 0.3602\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.9376 - accuracy: 0.3076 - val_loss: 1.8929 - val_accuracy: 0.3848\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8996 - accuracy: 0.3204 - val_loss: 1.8391 - val_accuracy: 0.3976\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8497 - accuracy: 0.3385 - val_loss: 1.8716 - val_accuracy: 0.3832\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8228 - accuracy: 0.3466 - val_loss: 1.8134 - val_accuracy: 0.4078\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7913 - accuracy: 0.3550 - val_loss: 1.7923 - val_accuracy: 0.4168\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7592 - accuracy: 0.3695 - val_loss: 1.7861 - val_accuracy: 0.4162\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7365 - accuracy: 0.3741 - val_loss: 1.8385 - val_accuracy: 0.4178\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7076 - accuracy: 0.3836 - val_loss: 1.8115 - val_accuracy: 0.4230\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6849 - accuracy: 0.3912 - val_loss: 1.8000 - val_accuracy: 0.4184\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6783 - accuracy: 0.3937 - val_loss: 1.7649 - val_accuracy: 0.4176\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6537 - accuracy: 0.4056 - val_loss: 1.7388 - val_accuracy: 0.4262\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6435 - accuracy: 0.4106 - val_loss: 1.8546 - val_accuracy: 0.4306\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6309 - accuracy: 0.4132 - val_loss: 1.7760 - val_accuracy: 0.4324\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6141 - accuracy: 0.4212 - val_loss: 1.7399 - val_accuracy: 0.4346\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 5:41 - loss: 3.1620 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0080s vs `on_train_batch_end` time: 0.4742s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 2.4702 - accuracy: 0.1848 - val_loss: 2.0825 - val_accuracy: 0.3298\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.1148 - accuracy: 0.2646 - val_loss: 2.1301 - val_accuracy: 0.3546\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.9653 - accuracy: 0.3020 - val_loss: 1.9102 - val_accuracy: 0.3716\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8708 - accuracy: 0.3316 - val_loss: 1.8875 - val_accuracy: 0.3806\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7978 - accuracy: 0.3556 - val_loss: 1.8371 - val_accuracy: 0.3920\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.7463 - accuracy: 0.3740 - val_loss: 1.7739 - val_accuracy: 0.4106\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6991 - accuracy: 0.3916 - val_loss: 1.7669 - val_accuracy: 0.4098\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6620 - accuracy: 0.4058 - val_loss: 1.7722 - val_accuracy: 0.4280\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6383 - accuracy: 0.4112 - val_loss: 1.7849 - val_accuracy: 0.4318\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6100 - accuracy: 0.4242 - val_loss: 1.6976 - val_accuracy: 0.4296\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5907 - accuracy: 0.4310 - val_loss: 1.6697 - val_accuracy: 0.4362\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5685 - accuracy: 0.4390 - val_loss: 1.6733 - val_accuracy: 0.4556\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5431 - accuracy: 0.4506 - val_loss: 1.7239 - val_accuracy: 0.4506\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5276 - accuracy: 0.4547 - val_loss: 1.7407 - val_accuracy: 0.4536\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5153 - accuracy: 0.4580 - val_loss: 1.7652 - val_accuracy: 0.4530\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4966 - accuracy: 0.4656 - val_loss: 1.6581 - val_accuracy: 0.4522\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4848 - accuracy: 0.4723 - val_loss: 1.6930 - val_accuracy: 0.4504\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4715 - accuracy: 0.4750 - val_loss: 1.6274 - val_accuracy: 0.4554\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4598 - accuracy: 0.4805 - val_loss: 1.7244 - val_accuracy: 0.4582\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4532 - accuracy: 0.4854 - val_loss: 1.7217 - val_accuracy: 0.4538\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 5:13 - loss: 2.9030 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.4385s). Check your callbacks.\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.3437 - accuracy: 0.1998 - val_loss: 2.0876 - val_accuracy: 0.3228\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 2.0037 - accuracy: 0.2823 - val_loss: 1.9759 - val_accuracy: 0.3474\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8650 - accuracy: 0.3254 - val_loss: 1.9291 - val_accuracy: 0.3676\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7775 - accuracy: 0.3571 - val_loss: 1.8669 - val_accuracy: 0.3844\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7224 - accuracy: 0.3752 - val_loss: 1.7092 - val_accuracy: 0.4140\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6781 - accuracy: 0.3932 - val_loss: 1.8817 - val_accuracy: 0.3988\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6386 - accuracy: 0.4107 - val_loss: 1.7339 - val_accuracy: 0.4294\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6101 - accuracy: 0.4253 - val_loss: 1.6612 - val_accuracy: 0.4274\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5812 - accuracy: 0.4346 - val_loss: 1.7894 - val_accuracy: 0.4390\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5551 - accuracy: 0.4456 - val_loss: 1.6559 - val_accuracy: 0.4476\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5317 - accuracy: 0.4546 - val_loss: 1.6638 - val_accuracy: 0.4532\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5139 - accuracy: 0.4610 - val_loss: 1.5992 - val_accuracy: 0.4498\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4931 - accuracy: 0.4672 - val_loss: 1.6283 - val_accuracy: 0.4644\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4729 - accuracy: 0.4764 - val_loss: 1.7207 - val_accuracy: 0.4692\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4558 - accuracy: 0.4815 - val_loss: 1.6339 - val_accuracy: 0.4604\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4406 - accuracy: 0.4882 - val_loss: 1.6800 - val_accuracy: 0.4536\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4236 - accuracy: 0.4945 - val_loss: 1.7406 - val_accuracy: 0.4682\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4110 - accuracy: 0.4977 - val_loss: 1.5776 - val_accuracy: 0.4812\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3952 - accuracy: 0.5039 - val_loss: 1.7611 - val_accuracy: 0.4714\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3840 - accuracy: 0.5049 - val_loss: 1.7351 - val_accuracy: 0.4756\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 4:49 - loss: 3.1606 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.4043s). Check your callbacks.\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.2592 - accuracy: 0.2056 - val_loss: 2.1186 - val_accuracy: 0.2696\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9254 - accuracy: 0.2953 - val_loss: 1.9304 - val_accuracy: 0.3648\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8044 - accuracy: 0.3493 - val_loss: 1.8303 - val_accuracy: 0.3826\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7291 - accuracy: 0.3809 - val_loss: 1.8894 - val_accuracy: 0.3900\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6728 - accuracy: 0.4026 - val_loss: 1.7790 - val_accuracy: 0.4160\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6302 - accuracy: 0.4207 - val_loss: 1.7604 - val_accuracy: 0.4164\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5968 - accuracy: 0.4302 - val_loss: 1.7543 - val_accuracy: 0.4304\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5679 - accuracy: 0.4428 - val_loss: 1.6971 - val_accuracy: 0.4252\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5398 - accuracy: 0.4540 - val_loss: 1.6692 - val_accuracy: 0.4412\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5178 - accuracy: 0.4626 - val_loss: 1.6687 - val_accuracy: 0.4462\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4927 - accuracy: 0.4699 - val_loss: 1.7786 - val_accuracy: 0.4486\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4713 - accuracy: 0.4769 - val_loss: 1.6652 - val_accuracy: 0.4720\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4480 - accuracy: 0.4876 - val_loss: 1.8283 - val_accuracy: 0.4308\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4362 - accuracy: 0.4909 - val_loss: 1.7189 - val_accuracy: 0.4630\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4187 - accuracy: 0.4966 - val_loss: 1.6163 - val_accuracy: 0.4800\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4038 - accuracy: 0.5047 - val_loss: 1.6531 - val_accuracy: 0.4740\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3875 - accuracy: 0.5070 - val_loss: 1.5970 - val_accuracy: 0.4736\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3668 - accuracy: 0.5146 - val_loss: 1.6980 - val_accuracy: 0.4700\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3534 - accuracy: 0.5191 - val_loss: 1.6665 - val_accuracy: 0.4734\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3404 - accuracy: 0.5270 - val_loss: 1.6870 - val_accuracy: 0.4804\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 4:51 - loss: 2.9355 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.4048s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.1830 - accuracy: 0.1945 - val_loss: 2.0060 - val_accuracy: 0.2566\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9151 - accuracy: 0.2855 - val_loss: 1.9297 - val_accuracy: 0.3148\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8340 - accuracy: 0.3228 - val_loss: 1.9327 - val_accuracy: 0.3408\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7647 - accuracy: 0.3589 - val_loss: 1.9057 - val_accuracy: 0.3702\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7066 - accuracy: 0.3876 - val_loss: 1.8856 - val_accuracy: 0.3758\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6591 - accuracy: 0.4087 - val_loss: 1.8055 - val_accuracy: 0.4066\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6224 - accuracy: 0.4234 - val_loss: 1.8308 - val_accuracy: 0.4036\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5976 - accuracy: 0.4347 - val_loss: 1.8834 - val_accuracy: 0.4204\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5657 - accuracy: 0.4461 - val_loss: 1.7897 - val_accuracy: 0.4430\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5352 - accuracy: 0.4587 - val_loss: 1.7917 - val_accuracy: 0.4598\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5186 - accuracy: 0.4650 - val_loss: 1.8547 - val_accuracy: 0.4484\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4921 - accuracy: 0.4736 - val_loss: 1.7922 - val_accuracy: 0.4622\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4721 - accuracy: 0.4800 - val_loss: 1.7377 - val_accuracy: 0.4584\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4556 - accuracy: 0.4860 - val_loss: 1.7498 - val_accuracy: 0.4730\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4345 - accuracy: 0.4918 - val_loss: 1.8424 - val_accuracy: 0.4642\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4147 - accuracy: 0.4998 - val_loss: 1.6768 - val_accuracy: 0.4694\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3929 - accuracy: 0.5079 - val_loss: 1.7452 - val_accuracy: 0.4750\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3786 - accuracy: 0.5145 - val_loss: 1.6951 - val_accuracy: 0.4798\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3598 - accuracy: 0.5224 - val_loss: 1.8298 - val_accuracy: 0.4836\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3475 - accuracy: 0.5246 - val_loss: 1.8265 - val_accuracy: 0.4812\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 4:55 - loss: 3.0336 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.4129s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.1585 - accuracy: 0.1943 - val_loss: 2.1377 - val_accuracy: 0.2318\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9610 - accuracy: 0.2546 - val_loss: 1.9948 - val_accuracy: 0.2578\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8904 - accuracy: 0.2872 - val_loss: 1.9010 - val_accuracy: 0.3056\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8437 - accuracy: 0.3113 - val_loss: 1.9376 - val_accuracy: 0.3274\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8016 - accuracy: 0.3302 - val_loss: 1.8901 - val_accuracy: 0.3216\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7536 - accuracy: 0.3508 - val_loss: 1.9435 - val_accuracy: 0.3610\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7140 - accuracy: 0.3667 - val_loss: 1.8356 - val_accuracy: 0.3784\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6860 - accuracy: 0.3826 - val_loss: 1.8634 - val_accuracy: 0.3998\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6525 - accuracy: 0.3931 - val_loss: 1.8275 - val_accuracy: 0.3862\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6297 - accuracy: 0.4034 - val_loss: 1.9368 - val_accuracy: 0.3878\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6141 - accuracy: 0.4108 - val_loss: 1.8104 - val_accuracy: 0.4158\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5882 - accuracy: 0.4240 - val_loss: 2.0284 - val_accuracy: 0.4048\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5682 - accuracy: 0.4313 - val_loss: 1.8903 - val_accuracy: 0.3938\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5579 - accuracy: 0.4402 - val_loss: 1.8289 - val_accuracy: 0.4286\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5393 - accuracy: 0.4452 - val_loss: 1.9832 - val_accuracy: 0.4244\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5190 - accuracy: 0.4584 - val_loss: 1.7790 - val_accuracy: 0.4504\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5101 - accuracy: 0.4578 - val_loss: 1.8943 - val_accuracy: 0.4338\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4967 - accuracy: 0.4674 - val_loss: 1.9182 - val_accuracy: 0.4482\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4787 - accuracy: 0.4745 - val_loss: 1.8196 - val_accuracy: 0.4506\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.0183 - accuracy: 0.2874 - val_loss: 1.9717 - val_accuracy: 0.3242\n",
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 5:07 - loss: 3.1099 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.4294s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.2713 - accuracy: 0.1387 - val_loss: 2.2070 - val_accuracy: 0.1552\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 2.2606 - accuracy: 0.1253 - val_loss: 2.2138 - val_accuracy: 0.1652\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.0902 - accuracy: 0.1779 - val_loss: 2.2004 - val_accuracy: 0.1856\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.1136 - accuracy: 0.1711 - val_loss: 2.1243 - val_accuracy: 0.1694\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.0580 - accuracy: 0.1851 - val_loss: 2.1537 - val_accuracy: 0.1948\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.0156 - accuracy: 0.2058 - val_loss: 2.1571 - val_accuracy: 0.2156\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9671 - accuracy: 0.2312 - val_loss: 2.1140 - val_accuracy: 0.2278\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.9532 - accuracy: 0.2353 - val_loss: 2.0210 - val_accuracy: 0.2480\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9671 - accuracy: 0.2352 - val_loss: 2.1851 - val_accuracy: 0.1994\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9148 - accuracy: 0.2575 - val_loss: 2.0593 - val_accuracy: 0.2686\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9115 - accuracy: 0.2640 - val_loss: 2.1331 - val_accuracy: 0.1862\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 2.0017 - accuracy: 0.1979 - val_loss: 2.0622 - val_accuracy: 0.2066\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9781 - accuracy: 0.2218 - val_loss: 2.0867 - val_accuracy: 0.1970\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9748 - accuracy: 0.2288 - val_loss: 2.0854 - val_accuracy: 0.2612\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9205 - accuracy: 0.2563 - val_loss: 2.2082 - val_accuracy: 0.2542\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9368 - accuracy: 0.2567 - val_loss: 2.1180 - val_accuracy: 0.2316\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9102 - accuracy: 0.2588 - val_loss: 2.0683 - val_accuracy: 0.2538\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.8688 - accuracy: 0.2746 - val_loss: 2.1012 - val_accuracy: 0.2792\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8566 - accuracy: 0.2854 - val_loss: 2.1848 - val_accuracy: 0.2932\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8411 - accuracy: 0.2899 - val_loss: 2.0438 - val_accuracy: 0.2980\n"
     ]
    }
   ],
   "source": [
    "lr_rates=[1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3]\n",
    "run_number=0\n",
    "for lr_rate in lr_rates:\n",
    "    run_number+=1\n",
    "    model=build_model_SELU_AD(20,lr_rate)\n",
    "    log_dir=os.path.join(os.curdir,\"my_logs\",\"ch11_ex8\",\"run_selu_AD{:03d}\".format(run_number))\n",
    "    tb_cb=keras.callbacks.TensorBoard(log_dir)\n",
    "    history=model.fit(X_train,y_train,epochs=20, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b37a2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.1903 - accuracy: 0.2191 - val_loss: 2.0117 - val_accuracy: 0.3172\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8863 - accuracy: 0.3138 - val_loss: 1.9878 - val_accuracy: 0.2998\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.7877 - accuracy: 0.3574 - val_loss: 1.7687 - val_accuracy: 0.3986\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7202 - accuracy: 0.3837 - val_loss: 1.7220 - val_accuracy: 0.4108\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6639 - accuracy: 0.4056 - val_loss: 1.8143 - val_accuracy: 0.4130\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6249 - accuracy: 0.4230 - val_loss: 1.7841 - val_accuracy: 0.4326\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5887 - accuracy: 0.4386 - val_loss: 1.6828 - val_accuracy: 0.4498\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5615 - accuracy: 0.4454 - val_loss: 1.6853 - val_accuracy: 0.4336\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5340 - accuracy: 0.4573 - val_loss: 1.7440 - val_accuracy: 0.4376\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5096 - accuracy: 0.4632 - val_loss: 1.8394 - val_accuracy: 0.4508\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4913 - accuracy: 0.4738 - val_loss: 1.8199 - val_accuracy: 0.4586\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4676 - accuracy: 0.4815 - val_loss: 1.7157 - val_accuracy: 0.4664\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4479 - accuracy: 0.4876 - val_loss: 1.7507 - val_accuracy: 0.4530\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4308 - accuracy: 0.4930 - val_loss: 1.7240 - val_accuracy: 0.4762\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4103 - accuracy: 0.5030 - val_loss: 1.6353 - val_accuracy: 0.4776\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3942 - accuracy: 0.5076 - val_loss: 1.7737 - val_accuracy: 0.4730\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3735 - accuracy: 0.5128 - val_loss: 1.7208 - val_accuracy: 0.4896\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3561 - accuracy: 0.5213 - val_loss: 1.6853 - val_accuracy: 0.4738\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3414 - accuracy: 0.5268 - val_loss: 1.8323 - val_accuracy: 0.4782\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3274 - accuracy: 0.5318 - val_loss: 1.7056 - val_accuracy: 0.4844\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3144 - accuracy: 0.5350 - val_loss: 1.7645 - val_accuracy: 0.4994\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2983 - accuracy: 0.5438 - val_loss: 1.7016 - val_accuracy: 0.4932\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2800 - accuracy: 0.5486 - val_loss: 1.9260 - val_accuracy: 0.4838\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2634 - accuracy: 0.5523 - val_loss: 1.7874 - val_accuracy: 0.4976\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2509 - accuracy: 0.5573 - val_loss: 1.8523 - val_accuracy: 0.4980\n"
     ]
    }
   ],
   "source": [
    "#lr wyglada dobrze pomiedzy 1e-4 i 3e-4\n",
    "model=build_model_SELU_AD(20,2e-4)\n",
    "es_cb=keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "history=model.fit(X_train,y_train,epochs=100, validation_data=(X_valid,y_valid),\n",
    "                 callbacks=[es_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09208e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5844 - accuracy: 0.4807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5843769311904907, 0.48069998621940613]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lol\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d510816",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas=np.array([model(X_test,training=True) for sample in range(20)])\n",
    "y_proba=np.mean(y_probas,axis=0)\n",
    "y_pred=np.argmax(y_proba,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5542a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.484"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.004 wiecej\n",
    "accuracy=np.sum(y_pred==y_test.reshape(-1))/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1840f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
